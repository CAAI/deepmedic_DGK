2022-3-24 8:29:14.58: =============================== logger created =======================================
2022-3-24 8:29:14.59: 
2022-3-24 8:29:14.59: ======================== Starting new session ============================
2022-3-24 8:29:14.59: Command line arguments given: 
Namespace(device='cuda1', model_cfg='./examples/configFiles/tinyCnn/model/modelConfig.cfg', reset_trainer=False, saved_model=None, test_cfg=None, train_cfg='examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg')
2022-3-24 8:29:17.28: Available devices to Tensorflow:
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 14775681959801253155
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 12625854856137332438
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 5382792315064905881
physical_device_desc: "device: XLA_CPU device"
]
2022-3-24 8:29:17.28: CONFIG: The configuration file for the [model] given is: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/configFiles/tinyCnn/model/modelConfig.cfg
2022-3-24 8:29:17.28: =============================================================
2022-3-24 8:29:17.28: ========== PARAMETERS FOR MAKING THE ARCHITECTURE ===========
2022-3-24 8:29:17.29: =============================================================
2022-3-24 8:29:17.29: CNN model's name = tinyCnn
2022-3-24 8:29:17.29: ~~~~~~~~~~~~~~~~~~Model parameters~~~~~~~~~~~~~~~~
2022-3-24 8:29:17.29: Number of Classes (including background) = 5
2022-3-24 8:29:17.29: ~~Normal Pathway~~
2022-3-24 8:29:17.29: Number of Input Channels = 2
2022-3-24 8:29:17.29: Number of Layers = 3
2022-3-24 8:29:17.29: Number of Feature Maps per layer = [4, 5, 6]
2022-3-24 8:29:17.29: Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]
2022-3-24 8:29:17.29: Padding mode of convs per layer = ['VALID', 'VALID', 'VALID']
2022-3-24 8:29:17.29: Residual connections added at the output of layers (indices from 0) = []
2022-3-24 8:29:17.29: Layers that will be made of Lower Rank (indices from 0) = []
2022-3-24 8:29:17.29: Lower Rank layers will be made of rank = []
2022-3-24 8:29:17.29: ~~Subsampled Pathway~~
2022-3-24 8:29:17.29: Use subsampled Pathway = True
2022-3-24 8:29:17.29: Number of subsampled pathways that will be built = 1
2022-3-24 8:29:17.30: Number of Layers (per sub-pathway) = [3]
2022-3-24 8:29:17.30: Number of Feature Maps per layer (per sub-pathway) = [[4, 5, 6]]
2022-3-24 8:29:17.30: Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]
2022-3-24 8:29:17.30: Padding mode of convs per layer = ['VALID', 'VALID', 'VALID']
2022-3-24 8:29:17.30: Subsampling Factor per dimension (per sub-pathway) = [[3, 3, 3]]
2022-3-24 8:29:17.30: Residual connections added at the output of layers (indices from 0) = []
2022-3-24 8:29:17.30: Layers that will be made of Lower Rank (indices from 0) = []
2022-3-24 8:29:17.30: Lower Rank layers will be made of rank = []
2022-3-24 8:29:17.30: ~~Fully Connected Pathway~~
2022-3-24 8:29:17.30: Number of additional FC layers (Excluding the Classif. Layer) = 0
2022-3-24 8:29:17.30: Number of Feature Maps in the additional FC layers = []
2022-3-24 8:29:17.30: Padding mode of convs per layer = ['VALID']
2022-3-24 8:29:17.30: Residual connections added at the output of layers (indices from 0) = []
2022-3-24 8:29:17.30: Layers that will be made of Lower Rank (indices from 0) = []
2022-3-24 8:29:17.30: Dimensions of Kernels in final FC path before classification = [[1, 1, 1]]
2022-3-24 8:29:17.30: ~~Size Of Image Segments~~
2022-3-24 8:29:17.31: Size of Segments for Training = [25, 25, 25]
2022-3-24 8:29:17.31: Size of Segments for Validation = [7, 7, 7]
2022-3-24 8:29:17.31: Size of Segments for Testing = [45, 45, 45]
2022-3-24 8:29:17.31: ~~Dropout Rates~~
2022-3-24 8:29:17.31: Drop.R. for each layer in Normal Pathway = []
2022-3-24 8:29:17.31: Drop.R. for each layer in Subsampled Pathway = []
2022-3-24 8:29:17.31: Drop.R. for each layer in FC Pathway (additional FC layers + Classific.Layer at end) = [0.5]
2022-3-24 8:29:17.31: ~~Weight Initialization~~
2022-3-24 8:29:17.31: Initialization method and params for the conv kernel weights = ['fanIn', 2]
2022-3-24 8:29:17.31: ~~Activation Function~~
2022-3-24 8:29:17.31: Activation function to use = prelu
2022-3-24 8:29:17.31: ~~Batch Normalization~~
2022-3-24 8:29:17.31: Apply BN straight on pathways' inputs (eg straight on segments) = [False, False, True]
2022-3-24 8:29:17.31: Batch Normalization uses a rolling average for inference, over this many batches = 60
2022-3-24 8:29:17.31: ========== Done with printing session's parameters ==========
2022-3-24 8:29:17.31: =============================================================
2022-3-24 8:29:17.31: CONFIG: The configuration file for the [session] was loaded from: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg
2022-3-24 8:29:17.34: 
2022-3-24 8:29:17.34: =============    NEW TRAINING SESSION    ==============

2022-3-24 8:29:17.35: 
2022-3-24 8:29:17.35: =============================================================
2022-3-24 8:29:17.35: ========= PARAMETERS FOR THIS TRAINING SESSION ==============
2022-3-24 8:29:17.35: =============================================================
2022-3-24 8:29:17.35: Session's name = trainSessionWithValidTiny
2022-3-24 8:29:17.35: Model will be loaded from save = None
2022-3-24 8:29:17.35: ~~Output~~
2022-3-24 8:29:17.35: Main output folder = /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output
2022-3-24 8:29:17.35: Log performance metrics for tensorboard = True
2022-3-24 8:29:17.35: Path and filename to save trained models = /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny
2022-3-24 8:29:17.35: ~~~~~~~~~~~~~~~~~~Generic Information~~~~~~~~~~~~~~~~
2022-3-24 8:29:17.35: Number of Cases for Training = 2
2022-3-24 8:29:17.35: Number of Cases for Validation = 2
2022-3-24 8:29:17.35: ~~~~~~~~~~~~~~~~~~Training parameters~~~~~~~~~~~~~~~~
2022-3-24 8:29:17.35: Dataframe (csv) filename = None
2022-3-24 8:29:17.35: Filepaths to Channels of the Training Cases = [['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/T1c_subtrMeanDivStd.nii.gz'], ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/T1c_subtrMeanDivStd.nii.gz']]
2022-3-24 8:29:17.36: Filepaths to Ground-Truth labels of the Training Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/OTMultiClass.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/OTMultiClass.nii.gz']
2022-3-24 8:29:17.36: Filepaths to ROI Masks of the Training Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/brainmask.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/brainmask.nii.gz']
2022-3-24 8:29:17.36: ~~ Sampling (train) ~~
2022-3-24 8:29:17.36: Type of Sampling = Fore/Background (0)
2022-3-24 8:29:17.36: Sampling Categories = ['Foreground', 'Background']
2022-3-24 8:29:17.36: Percent of Samples to extract per Sampling Category = [0.5 0.5]
2022-3-24 8:29:17.36: Paths to weight-Maps for sampling of each category = None
2022-3-24 8:29:17.36: ~~Training Cycle~~
2022-3-24 8:29:17.36: Number of Epochs = 2
2022-3-24 8:29:17.36: Number of Subepochs per epoch = 2
2022-3-24 8:29:17.36: Number of cases to load per Subepoch (for extracting the samples for this subepoch) = 50
2022-3-24 8:29:17.36: Number of Segments loaded per subepoch for Training = 1000. NOTE: This number of segments divided by the batch-size defines the number of optimization-iterations that will be performed every subepoch!
2022-3-24 8:29:17.36: Batch size (train) = 10
2022-3-24 8:29:17.36: Number of parallel processes for sampling = 0
2022-3-24 8:29:17.36: ~~Learning Rate Schedule~~
2022-3-24 8:29:17.36: Type of schedule = poly
2022-3-24 8:29:17.37: [Predef] Predefined schedule of epochs when the LR will be lowered = None
2022-3-24 8:29:17.37: [Predef] When decreasing Learning Rate, divide LR by = 2.0
2022-3-24 8:29:17.37: [Poly] Initial epochs to wait before lowering LR = 0.6666666666666666
2022-3-24 8:29:17.37: [Poly] Final epoch for the schedule = 2
2022-3-24 8:29:17.37: [Auto] Initial epochs to wait before lowering LR = 5
2022-3-24 8:29:17.37: [Auto] When decreasing Learning Rate, divide LR by = 2.0
2022-3-24 8:29:17.37: [Auto] Minimum increase in validation accuracy (0. to 1.) that resets the waiting counter = 0.0
2022-3-24 8:29:17.37: [Expon] (Deprecated) parameters = {'epochs_wait_before_decr': 0.6666666666666666, 'final_ep_for_sch': 2, 'lr_to_reach_at_last_ep': 0.00390625, 'mom_to_reach_at_last_ep': 0.9}
2022-3-24 8:29:17.37: ~~Data Augmentation During Training~~
2022-3-24 8:29:17.37: Image level augmentation:
2022-3-24 8:29:17.37: Parameters for image-level augmentation: {'affine': <deepmedic.dataManagement.augmentImage.AugmenterAffineParams object at 0x7f7dc7834710>}
2022-3-24 8:29:17.37: 	 affine: OrderedDict([('prob', 0.7), ('max_rot_xyz', (45.0, 45.0, 45.0)), ('max_scaling', 0.1), ('seed', None), ('interp_order_imgs', 1), ('interp_order_lbls', 0), ('interp_order_roi', 0), ('interp_order_wmaps', 1), ('boundary_mode', 'nearest'), ('cval', 0.0)])
2022-3-24 8:29:17.37: Patch level augmentation:
2022-3-24 8:29:17.37: Mu and std for shift and scale of histograms = {'shift': {'mu': 0.0, 'std': 0.05}, 'scale': {'mu': 1.0, 'std': 0.01}}
2022-3-24 8:29:17.37: Probabilities of reflecting each axis = (0.5, 0.0, 0.0)
2022-3-24 8:29:17.37: Probabilities of rotating planes 0/90/180/270 degrees = {'xy': {'0': 0.8, '90': 0.1, '180': 0.0, '270': 0.1}, 'yz': {'0': 0.0, '90': 0.0, '180': 0.0, '270': 0.0}, 'xz': {'0': 0.0, '90': 0.0, '180': 0.0, '270': 0.0}}
2022-3-24 8:29:17.38: ~~~~~~~~~~~~~~~~~~Validation parameters~~~~~~~~~~~~~~~~
2022-3-24 8:29:17.38: Perform Validation on Samples throughout training? = True
2022-3-24 8:29:17.38: Perform Full Inference on validation cases every few epochs? = True
2022-3-24 8:29:17.38: Dataframe (csv) filename = None
2022-3-24 8:29:17.38: Filepaths to Channels of Validation Cases = [['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/T1c_subtrMeanDivStd.nii.gz'], ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/T1c_subtrMeanDivStd.nii.gz']]
2022-3-24 8:29:17.38: Filepaths to Ground-Truth labels of the Validation Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/OTMultiClass.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/OTMultiClass.nii.gz']
2022-3-24 8:29:17.38: Filepaths to ROI masks for Validation Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/brainmask.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/brainmask.nii.gz']
2022-3-24 8:29:17.38: ~~~~~~~Validation on Samples throughout Training~~~~~~~
2022-3-24 8:29:17.38: Number of Segments loaded per subepoch for Validation = 5000
2022-3-24 8:29:17.38: Batch size (val on samples) = 50
2022-3-24 8:29:17.38: ~~ Sampling (val) ~~
2022-3-24 8:29:17.38: Type of Sampling = Uniform (1)
2022-3-24 8:29:17.38: Sampling Categories = ['Uniform']
2022-3-24 8:29:17.38: Percent of Samples to extract per Sampling Category = [1.0]
2022-3-24 8:29:17.38: Paths to weight-maps for sampling of each category = None
2022-3-24 8:29:17.38: ~~~~~Validation with Full Inference on Validation Cases~~~~~
2022-3-24 8:29:17.38: Perform Full-Inference on Val. cases every that many epochs = 1
2022-3-24 8:29:17.38: Batch size (val on whole volumes) = 10
2022-3-24 8:29:17.39: ~~Predictions (segmentations and prob maps on val. cases)~~
2022-3-24 8:29:17.39: Save Segmentations = True
2022-3-24 8:29:17.39: Save Probability Maps for each class = [True, True, True, True, True]
2022-3-24 8:29:17.39: Filepaths to save results per case = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions//pred_brats_2013_pat0003_1.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions//pred_brats_2013_pat0004_1.nii.gz']
2022-3-24 8:29:17.39: Suffixes with which to save segmentations and probability maps = {'segm': 'Segm', 'prob': 'ProbMapClass'}
2022-3-24 8:29:17.39: ~~Feature Maps~~
2022-3-24 8:29:17.39: Save Feature Maps = False
2022-3-24 8:29:17.39: Min/Max Indices of FMs to visualise per pathway-type and per layer = None
2022-3-24 8:29:17.39: Filepaths to save FMs per case = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features//pred_brats_2013_pat0003_1.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features//pred_brats_2013_pat0004_1.nii.gz']
2022-3-24 8:29:17.39: ~~Optimization~~
2022-3-24 8:29:17.39: Initial Learning rate = 0.001
2022-3-24 8:29:17.39: Optimizer to use: SGD(0), Adam(1), RmsProp(2) = 2
2022-3-24 8:29:17.39: Parameters for Adam: b1= placeholder, b2=placeholder, e= placeholder
2022-3-24 8:29:17.39: Parameters for RmsProp: rho= 0.9, e= 0.0001
2022-3-24 8:29:17.39: Momentum Type: Classic (0) or Nesterov (1) = 1
2022-3-24 8:29:17.40: Momentum Non-Normalized (0) or Normalized (1) = 1
2022-3-24 8:29:17.40: Momentum Value = 0.6
2022-3-24 8:29:17.40: ~~Costs~~
2022-3-24 8:29:17.40: Loss functions and their weights = {'xentr': 1.0, 'iou': None, 'dsc': None}
2022-3-24 8:29:17.40: Reweight samples in cost on a per-class basis = {'type': None, 'prms': None, 'schedule': [0, 2]}
2022-3-24 8:29:17.40: L1 Regularization term = 1e-06
2022-3-24 8:29:17.40: L2 Regularization term = 0.0001
2022-3-24 8:29:17.40: ~~Freeze Weights of Certain Layers~~
2022-3-24 8:29:17.40: Indices of layers from each type of pathway that will be kept fixed (first layer is 0):
2022-3-24 8:29:17.40: Normal pathway's layers to freeze = []
2022-3-24 8:29:17.40: Subsampled pathway's layers to freeze = []
2022-3-24 8:29:17.40: FC pathway's layers to freeze = []
2022-3-24 8:29:17.40: ~~~~~~~~~~~~~~~~~~ PRE-PROCESSING ~~~~~~~~~~~~~~~~
2022-3-24 8:29:17.40: ~~Data Compabitibility Checks~~
2022-3-24 8:29:17.41: Check whether input data has correct format (can slow down process) = True
2022-3-24 8:29:17.41: ~~Padding~~
2022-3-24 8:29:17.41: Pad Input Images = True
2022-3-24 8:29:17.41: ~~Intensity Normalization~~
2022-3-24 8:29:17.41: Verbosity level = 0
2022-3-24 8:29:17.41: Z-Score parameters = {'apply_to_all_channels': False, 'apply_per_channel': None, 'cutoff_percents': None, 'cutoff_times_std': None, 'cutoff_below_mean': False}
2022-3-24 8:29:17.41: ========== Done with printing session's parameters ==========
2022-3-24 8:29:17.41: =============================================================

2022-3-24 8:29:17.41: =======================================================

2022-3-24 8:29:17.45: =========== Making the CNN graph... ===============
2022-3-24 8:29:17.45: ...Building the CNN model...
2022-3-24 8:29:17.45: [Pathway_NORMAL] is being built...
2022-3-24 8:29:17.45: 	Block [0], FMs-In: 2, FMs-Out: 4, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:29:17.51: 	Block [1], FMs-In: 4, FMs-Out: 5, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:29:17.56: 	Block [2], FMs-In: 5, FMs-Out: 6, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:29:17.59: [Pathway_SUBSAMPLED[3, 3, 3]] is being built...
2022-3-24 8:29:17.60: 	Block [0], FMs-In: 2, FMs-Out: 4, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:29:17.61: 	Block [1], FMs-In: 4, FMs-Out: 5, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:29:17.65: 	Block [2], FMs-In: 5, FMs-Out: 6, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:29:17.68: [Pathway_FC] is being built...
2022-3-24 8:29:17.69: 	Block [0], FMs-In: 12, FMs-Out: 5, Conv Filter dimensions: [1, 1, 1]
2022-3-24 8:29:17.72: Adding the final Softmax layer...
2022-3-24 8:29:17.73: Finished building the CNN's model.
2022-3-24 8:29:17.73: Pathway [NORMAL], Mode: [train], Input's Shape: (?, 2, 25, 25, 25)
2022-3-24 8:29:17.73: 	Block [0], Mode: [train], Input's Shape: (?, 2, 25, 25, 25)
2022-3-24 8:29:17.75: 	Block [1], Mode: [train], Input's Shape: (?, 4, 23, 23, 23)
2022-3-24 8:29:17.77: 	Block [2], Mode: [train], Input's Shape: (?, 5, 21, 21, 21)
2022-3-24 8:29:17.79: Pathway [NORMAL], Mode: [train], Output's Shape: (?, 6, 19, 19, 19)
2022-3-24 8:29:17.79: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [train], Input's Shape: (?, 2, 13, 13, 13)
2022-3-24 8:29:17.79: 	Block [0], Mode: [train], Input's Shape: (?, 2, 13, 13, 13)
2022-3-24 8:29:17.80: 	Block [1], Mode: [train], Input's Shape: (?, 4, 11, 11, 11)
2022-3-24 8:29:17.82: 	Block [2], Mode: [train], Input's Shape: (?, 5, 9, 9, 9)
2022-3-24 8:29:17.86: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [train], Output's Shape: (?, 6, 7, 7, 7)
2022-3-24 8:29:18.19: Pathway [FC], Mode: [train], Input's Shape: (?, 12, 19, 19, 19)
2022-3-24 8:29:18.19: 	Block [0], Mode: [train], Input's Shape: (?, 12, 19, 19, 19)
2022-3-24 8:29:18.22: Pathway [FC], Mode: [train], Output's Shape: (?, 5, 19, 19, 19)
2022-3-24 8:29:18.28: Pathway [NORMAL], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:29:18.28: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:29:18.29: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 5, 5, 5)
2022-3-24 8:29:18.32: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 3, 3, 3)
2022-3-24 8:29:18.34: Pathway [NORMAL], Mode: [infer], Output's Shape: (?, 6, 1, 1, 1)
2022-3-24 8:29:18.34: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:29:18.34: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:29:18.35: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 5, 5, 5)
2022-3-24 8:29:18.37: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 3, 3, 3)
2022-3-24 8:29:18.39: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Output's Shape: (?, 6, 1, 1, 1)
2022-3-24 8:29:18.47: Pathway [FC], Mode: [infer], Input's Shape: (?, 12, 1, 1, 1)
2022-3-24 8:29:18.47: 	Block [0], Mode: [infer], Input's Shape: (?, 12, 1, 1, 1)
2022-3-24 8:29:18.49: Pathway [FC], Mode: [infer], Output's Shape: (?, 5, 1, 1, 1)
2022-3-24 8:29:18.50: Pathway [NORMAL], Mode: [infer], Input's Shape: (?, 2, 45, 45, 45)
2022-3-24 8:29:18.50: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 45, 45, 45)
2022-3-24 8:29:18.51: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 43, 43, 43)
2022-3-24 8:29:18.54: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 41, 41, 41)
2022-3-24 8:29:18.56: Pathway [NORMAL], Mode: [infer], Output's Shape: (?, 6, 39, 39, 39)
2022-3-24 8:29:18.57: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Input's Shape: (?, 2, 19, 19, 19)
2022-3-24 8:29:18.57: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 19, 19, 19)
2022-3-24 8:29:18.58: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 17, 17, 17)
2022-3-24 8:29:18.60: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 15, 15, 15)
2022-3-24 8:29:18.63: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Output's Shape: (?, 6, 13, 13, 13)
2022-3-24 8:29:18.71: Pathway [FC], Mode: [infer], Input's Shape: (?, 12, 39, 39, 39)
2022-3-24 8:29:18.71: 	Block [0], Mode: [infer], Input's Shape: (?, 12, 39, 39, 39)
2022-3-24 8:29:18.73: Pathway [FC], Mode: [infer], Output's Shape: (?, 5, 39, 39, 39)
2022-3-24 8:29:18.75: =========== Building Trainer ===========

2022-3-24 8:29:18.75: Building Trainer.
2022-3-24 8:29:18.75: COST: Using cross entropy with weight: 1.0
2022-3-24 8:29:18.80: ...Initializing state of the optimizer...
2022-3-24 8:29:19.31: ----------- Creating Tensorboard Loggers -----------
2022-3-24 8:29:20.23: Loggers created successfully
2022-3-24 8:29:20.23: -----------=============================-----------
2022-3-24 8:29:20.23: =========== Compiling the Training Function ===========
2022-3-24 8:29:20.24: =======================================================

2022-3-24 8:29:21.25: ...Building the training function...
2022-3-24 8:29:21.26: ...Collecting ops and feeds for training...
2022-3-24 8:29:21.30: Done.
2022-3-24 8:29:21.30: =========== Compiling the Validation Function =========
2022-3-24 8:29:21.30: ...Building the validation function...
2022-3-24 8:29:21.30: ...Collecting ops and feeds for validation...
2022-3-24 8:29:21.35: Done.
2022-3-24 8:29:21.35: =========== Compiling the Testing Function ============
2022-3-24 8:29:21.35: ...Building the function for testing and visualisation of FMs...
2022-3-24 8:29:21.35: ...Collecting ops and feeds for testing...
2022-3-24 8:29:21.36: Done.
2022-3-24 8:29:21.49: =========== Initializing network and trainer variables  ===============
2022-3-24 8:29:22.04: 
2022-3-24 8:29:22.04: ERROR: Caught exception from main process: Cannot assign a device for operation net/b: node net/b (defined at /project_scripts/hnc_segmentation/deep_medic/deepmedic/deepmedic/neuralnet/layers.py:254) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:CPU:1, /job:localhost/replica:0/task:0/device:CPU:10, /job:localhost/replica:0/task:0/device:CPU:100, /job:localhost/replica:0/task:0/device:CPU:101, /job:localhost/replica:0/task:0/device:CPU:102, /job:localhost/replica:0/task:0/device:CPU:103, /job:localhost/replica:0/task:0/device:CPU:104, /job:localhost/replica:0/task:0/device:CPU:105, /job:localhost/replica:0/task:0/device:CPU:106, /job:localhost/replica:0/task:0/device:CPU:107, /job:localhost/replica:0/task:0/device:CPU:108, /job:localhost/replica:0/task:0/device:CPU:109, /job:localhost/replica:0/task:0/device:CPU:11, /job:localhost/replica:0/task:0/device:CPU:110, /job:localhost/replica:0/task:0/device:CPU:111, /job:localhost/replica:0/task:0/device:CPU:112, /job:localhost/replica:0/task:0/device:CPU:113, /job:localhost/replica:0/task:0/device:CPU:114, /job:localhost/replica:0/task:0/device:CPU:115, /job:localhost/replica:0/task:0/device:CPU:116, /job:localhost/replica:0/task:0/device:CPU:117, /job:localhost/replica:0/task:0/device:CPU:118, /job:localhost/replica:0/task:0/device:CPU:119, /job:localhost/replica:0/task:0/device:CPU:12, /job:localhost/replica:0/task:0/device:CPU:120, /job:localhost/replica:0/task:0/device:CPU:121, /job:localhost/replica:0/task:0/device:CPU:122, /job:localhost/replica:0/task:0/device:CPU:123, /job:localhost/replica:0/task:0/device:CPU:124, /job:localhost/replica:0/task:0/device:CPU:125, /job:localhost/replica:0/task:0/device:CPU:126, /job:localhost/replica:0/task:0/device:CPU:127, /job:localhost/replica:0/task:0/device:CPU:128, /job:localhost/replica:0/task:0/device:CPU:129, /job:localhost/replica:0/task:0/device:CPU:13, /job:localhost/replica:0/task:0/device:CPU:130, /job:localhost/replica:0/task:0/device:CPU:131, /job:localhost/replica:0/task:0/device:CPU:132, /job:localhost/replica:0/task:0/device:CPU:133, /job:localhost/replica:0/task:0/device:CPU:134, /job:localhost/replica:0/task:0/device:CPU:135, /job:localhost/replica:0/task:0/device:CPU:136, /job:localhost/replica:0/task:0/device:CPU:137, /job:localhost/replica:0/task:0/device:CPU:138, /job:localhost/replica:0/task:0/device:CPU:139, /job:localhost/replica:0/task:0/device:CPU:14, /job:localhost/replica:0/task:0/device:CPU:140, /job:localhost/replica:0/task:0/device:CPU:141, /job:localhost/replica:0/task:0/device:CPU:142, /job:localhost/replica:0/task:0/device:CPU:143, /job:localhost/replica:0/task:0/device:CPU:144, /job:localhost/replica:0/task:0/device:CPU:145, /job:localhost/replica:0/task:0/device:CPU:146, /job:localhost/replica:0/task:0/device:CPU:147, /job:localhost/replica:0/task:0/device:CPU:148, /job:localhost/replica:0/task:0/device:CPU:149, /job:localhost/replica:0/task:0/device:CPU:15, /job:localhost/replica:0/task:0/device:CPU:150, /job:localhost/replica:0/task:0/device:CPU:151, /job:localhost/replica:0/task:0/device:CPU:152, /job:localhost/replica:0/task:0/device:CPU:153, /job:localhost/replica:0/task:0/device:CPU:154, /job:localhost/replica:0/task:0/device:CPU:155, /job:localhost/replica:0/task:0/device:CPU:156, /job:localhost/replica:0/task:0/device:CPU:157, /job:localhost/replica:0/task:0/device:CPU:158, /job:localhost/replica:0/task:0/device:CPU:159, /job:localhost/replica:0/task:0/device:CPU:16, /job:localhost/replica:0/task:0/device:CPU:160, /job:localhost/replica:0/task:0/device:CPU:161, /job:localhost/replica:0/task:0/device:CPU:162, /job:localhost/replica:0/task:0/device:CPU:163, /job:localhost/replica:0/task:0/device:CPU:164, /job:localhost/replica:0/task:0/device:CPU:165, /job:localhost/replica:0/task:0/device:CPU:166, /job:localhost/replica:0/task:0/device:CPU:167, /job:localhost/replica:0/task:0/device:CPU:168, /job:localhost/replica:0/task:0/device:CPU:169, /job:localhost/replica:0/task:0/device:CPU:17, /job:localhost/replica:0/task:0/device:CPU:170, /job:localhost/replica:0/task:0/device:CPU:171, /job:localhost/replica:0/task:0/device:CPU:172, /job:localhost/replica:0/task:0/device:CPU:173, /job:localhost/replica:0/task:0/device:CPU:174, /job:localhost/replica:0/task:0/device:CPU:175, /job:localhost/replica:0/task:0/device:CPU:176, /job:localhost/replica:0/task:0/device:CPU:177, /job:localhost/replica:0/task:0/device:CPU:178, /job:localhost/replica:0/task:0/device:CPU:179, /job:localhost/replica:0/task:0/device:CPU:18, /job:localhost/replica:0/task:0/device:CPU:180, /job:localhost/replica:0/task:0/device:CPU:181, /job:localhost/replica:0/task:0/device:CPU:182, /job:localhost/replica:0/task:0/device:CPU:183, /job:localhost/replica:0/task:0/device:CPU:184, /job:localhost/replica:0/task:0/device:CPU:185, /job:localhost/replica:0/task:0/device:CPU:186, /job:localhost/replica:0/task:0/device:CPU:187, /job:localhost/replica:0/task:0/device:CPU:188, /job:localhost/replica:0/task:0/device:CPU:189, /job:localhost/replica:0/task:0/device:CPU:19, /job:localhost/replica:0/task:0/device:CPU:190, /job:localhost/replica:0/task:0/device:CPU:191, /job:localhost/replica:0/task:0/device:CPU:192, /job:localhost/replica:0/task:0/device:CPU:193, /job:localhost/replica:0/task:0/device:CPU:194, /job:localhost/replica:0/task:0/device:CPU:195, /job:localhost/replica:0/task:0/device:CPU:196, /job:localhost/replica:0/task:0/device:CPU:197, /job:localhost/replica:0/task:0/device:CPU:198, /job:localhost/replica:0/task:0/device:CPU:199, /job:localhost/replica:0/task:0/device:CPU:2, /job:localhost/replica:0/task:0/device:CPU:20, /job:localhost/replica:0/task:0/device:CPU:200, /job:localhost/replica:0/task:0/device:CPU:201, /job:localhost/replica:0/task:0/device:CPU:202, /job:localhost/replica:0/task:0/device:CPU:203, /job:localhost/replica:0/task:0/device:CPU:204, /job:localhost/replica:0/task:0/device:CPU:205, /job:localhost/replica:0/task:0/device:CPU:206, /job:localhost/replica:0/task:0/device:CPU:207, /job:localhost/replica:0/task:0/device:CPU:208, /job:localhost/replica:0/task:0/device:CPU:209, /job:localhost/replica:0/task:0/device:CPU:21, /job:localhost/replica:0/task:0/device:CPU:210, /job:localhost/replica:0/task:0/device:CPU:211, /job:localhost/replica:0/task:0/device:CPU:212, /job:localhost/replica:0/task:0/device:CPU:213, /job:localhost/replica:0/task:0/device:CPU:214, /job:localhost/replica:0/task:0/device:CPU:215, /job:localhost/replica:0/task:0/device:CPU:216, /job:localhost/replica:0/task:0/device:CPU:217, /job:localhost/replica:0/task:0/device:CPU:218, /job:localhost/replica:0/task:0/device:CPU:219, /job:localhost/replica:0/task:0/device:CPU:22, /job:localhost/replica:0/task:0/device:CPU:220, /job:localhost/replica:0/task:0/device:CPU:221, /job:localhost/replica:0/task:0/device:CPU:222, /job:localhost/replica:0/task:0/device:CPU:223, /job:localhost/replica:0/task:0/device:CPU:224, /job:localhost/replica:0/task:0/device:CPU:225, /job:localhost/replica:0/task:0/device:CPU:226, /job:localhost/replica:0/task:0/device:CPU:227, /job:localhost/replica:0/task:0/device:CPU:228, /job:localhost/replica:0/task:0/device:CPU:229, /job:localhost/replica:0/task:0/device:CPU:23, /job:localhost/replica:0/task:0/device:CPU:230, /job:localhost/replica:0/task:0/device:CPU:231, /job:localhost/replica:0/task:0/device:CPU:232, /job:localhost/replica:0/task:0/device:CPU:233, /job:localhost/replica:0/task:0/device:CPU:234, /job:localhost/replica:0/task:0/device:CPU:235, /job:localhost/replica:0/task:0/device:CPU:236, /job:localhost/replica:0/task:0/device:CPU:237, /job:localhost/replica:0/task:0/device:CPU:238, /job:localhost/replica:0/task:0/device:CPU:239, /job:localhost/replica:0/task:0/device:CPU:24, /job:localhost/replica:0/task:0/device:CPU:240, /job:localhost/replica:0/task:0/device:CPU:241, /job:localhost/replica:0/task:0/device:CPU:242, /job:localhost/replica:0/task:0/device:CPU:243, /job:localhost/replica:0/task:0/device:CPU:244, /job:localhost/replica:0/task:0/device:CPU:245, /job:localhost/replica:0/task:0/device:CPU:246, /job:localhost/replica:0/task:0/device:CPU:247, /job:localhost/replica:0/task:0/device:CPU:248, /job:localhost/replica:0/task:0/device:CPU:249, /job:localhost/replica:0/task:0/device:CPU:25, /job:localhost/replica:0/task:0/device:CPU:250, /job:localhost/replica:0/task:0/device:CPU:251, /job:localhost/replica:0/task:0/device:CPU:252, /job:localhost/replica:0/task:0/device:CPU:253, /job:localhost/replica:0/task:0/device:CPU:254, /job:localhost/replica:0/task:0/device:CPU:255, /job:localhost/replica:0/task:0/device:CPU:256, /job:localhost/replica:0/task:0/device:CPU:257, /job:localhost/replica:0/task:0/device:CPU:258, /job:localhost/replica:0/task:0/device:CPU:259, /job:localhost/replica:0/task:0/device:CPU:26, /job:localhost/replica:0/task:0/device:CPU:260, /job:localhost/replica:0/task:0/device:CPU:261, /job:localhost/replica:0/task:0/device:CPU:262, /job:localhost/replica:0/task:0/device:CPU:263, /job:localhost/replica:0/task:0/device:CPU:264, /job:localhost/replica:0/task:0/device:CPU:265, /job:localhost/replica:0/task:0/device:CPU:266, /job:localhost/replica:0/task:0/device:CPU:267, /job:localhost/replica:0/task:0/device:CPU:268, /job:localhost/replica:0/task:0/device:CPU:269, /job:localhost/replica:0/task:0/device:CPU:27, /job:localhost/replica:0/task:0/device:CPU:270, /job:localhost/replica:0/task:0/device:CPU:271, /job:localhost/replica:0/task:0/device:CPU:272, /job:localhost/replica:0/task:0/device:CPU:273, /job:localhost/replica:0/task:0/device:CPU:274, /job:localhost/replica:0/task:0/device:CPU:275, /job:localhost/replica:0/task:0/device:CPU:276, /job:localhost/replica:0/task:0/device:CPU:277, /job:localhost/replica:0/task:0/device:CPU:278, /job:localhost/replica:0/task:0/device:CPU:279, /job:localhost/replica:0/task:0/device:CPU:28, /job:localhost/replica:0/task:0/device:CPU:280, /job:localhost/replica:0/task:0/device:CPU:281, /job:localhost/replica:0/task:0/device:CPU:282, /job:localhost/replica:0/task:0/device:CPU:283, /job:localhost/replica:0/task:0/device:CPU:284, /job:localhost/replica:0/task:0/device:CPU:285, /job:localhost/replica:0/task:0/device:CPU:286, /job:localhost/replica:0/task:0/device:CPU:287, /job:localhost/replica:0/task:0/device:CPU:288, /job:localhost/replica:0/task:0/device:CPU:289, /job:localhost/replica:0/task:0/device:CPU:29, /job:localhost/replica:0/task:0/device:CPU:290, /job:localhost/replica:0/task:0/device:CPU:291, /job:localhost/replica:0/task:0/device:CPU:292, /job:localhost/replica:0/task:0/device:CPU:293, /job:localhost/replica:0/task:0/device:CPU:294, /job:localhost/replica:0/task:0/device:CPU:295, /job:localhost/replica:0/task:0/device:CPU:296, /job:localhost/replica:0/task:0/device:CPU:297, /job:localhost/replica:0/task:0/device:CPU:298, /job:localhost/replica:0/task:0/device:CPU:299, /job:localhost/replica:0/task:0/device:CPU:3, /job:localhost/replica:0/task:0/device:CPU:30, /job:localhost/replica:0/task:0/device:CPU:300, /job:localhost/replica:0/task:0/device:CPU:301, /job:localhost/replica:0/task:0/device:CPU:302, /job:localhost/replica:0/task:0/device:CPU:303, /job:localhost/replica:0/task:0/device:CPU:304, /job:localhost/replica:0/task:0/device:CPU:305, /job:localhost/replica:0/task:0/device:CPU:306, /job:localhost/replica:0/task:0/device:CPU:307, /job:localhost/replica:0/task:0/device:CPU:308, /job:localhost/replica:0/task:0/device:CPU:309, /job:localhost/replica:0/task:0/device:CPU:31, /job:localhost/replica:0/task:0/device:CPU:310, /job:localhost/replica:0/task:0/device:CPU:311, /job:localhost/replica:0/task:0/device:CPU:312, /job:localhost/replica:0/task:0/device:CPU:313, /job:localhost/replica:0/task:0/device:CPU:314, /job:localhost/replica:0/task:0/device:CPU:315, /job:localhost/replica:0/task:0/device:CPU:316, /job:localhost/replica:0/task:0/device:CPU:317, /job:localhost/replica:0/task:0/device:CPU:318, /job:localhost/replica:0/task:0/device:CPU:319, /job:localhost/replica:0/task:0/device:CPU:32, /job:localhost/replica:0/task:0/device:CPU:320, /job:localhost/replica:0/task:0/device:CPU:321, /job:localhost/replica:0/task:0/device:CPU:322, /job:localhost/replica:0/task:0/device:CPU:323, /job:localhost/replica:0/task:0/device:CPU:324, /job:localhost/replica:0/task:0/device:CPU:325, /job:localhost/replica:0/task:0/device:CPU:326, /job:localhost/replica:0/task:0/device:CPU:327, /job:localhost/replica:0/task:0/device:CPU:328, /job:localhost/replica:0/task:0/device:CPU:329, /job:localhost/replica:0/task:0/device:CPU:33, /job:localhost/replica:0/task:0/device:CPU:330, /job:localhost/replica:0/task:0/device:CPU:331, /job:localhost/replica:0/task:0/device:CPU:332, /job:localhost/replica:0/task:0/device:CPU:333, /job:localhost/replica:0/task:0/device:CPU:334, /job:localhost/replica:0/task:0/device:CPU:335, /job:localhost/replica:0/task:0/device:CPU:336, /job:localhost/replica:0/task:0/device:CPU:337, /job:localhost/replica:0/task:0/device:CPU:338, /job:localhost/replica:0/task:0/device:CPU:339, /job:localhost/replica:0/task:0/device:CPU:34, /job:localhost/replica:0/task:0/device:CPU:340, /job:localhost/replica:0/task:0/device:CPU:341, /job:localhost/replica:0/task:0/device:CPU:342, /job:localhost/replica:0/task:0/device:CPU:343, /job:localhost/replica:0/task:0/device:CPU:344, /job:localhost/replica:0/task:0/device:CPU:345, /job:localhost/replica:0/task:0/device:CPU:346, /job:localhost/replica:0/task:0/device:CPU:347, /job:localhost/replica:0/task:0/device:CPU:348, /job:localhost/replica:0/task:0/device:CPU:349, /job:localhost/replica:0/task:0/device:CPU:35, /job:localhost/replica:0/task:0/device:CPU:350, /job:localhost/replica:0/task:0/device:CPU:351, /job:localhost/replica:0/task:0/device:CPU:352, /job:localhost/replica:0/task:0/device:CPU:353, /job:localhost/replica:0/task:0/device:CPU:354, /job:localhost/replica:0/task:0/device:CPU:355, /job:localhost/replica:0/task:0/device:CPU:356, /job:localhost/replica:0/task:0/device:CPU:357, /job:localhost/replica:0/task:0/device:CPU:358, /job:localhost/replica:0/task:0/device:CPU:359, /job:localhost/replica:0/task:0/device:CPU:36, /job:localhost/replica:0/task:0/device:CPU:360, /job:localhost/replica:0/task:0/device:CPU:361, /job:localhost/replica:0/task:0/device:CPU:362, /job:localhost/replica:0/task:0/device:CPU:363, /job:localhost/replica:0/task:0/device:CPU:364, /job:localhost/replica:0/task:0/device:CPU:365, /job:localhost/replica:0/task:0/device:CPU:366, /job:localhost/replica:0/task:0/device:CPU:367, /job:localhost/replica:0/task:0/device:CPU:368, /job:localhost/replica:0/task:0/device:CPU:369, /job:localhost/replica:0/task:0/device:CPU:37, /job:localhost/replica:0/task:0/device:CPU:370, /job:localhost/replica:0/task:0/device:CPU:371, /job:localhost/replica:0/task:0/device:CPU:372, /job:localhost/replica:0/task:0/device:CPU:373, /job:localhost/replica:0/task:0/device:CPU:374, /job:localhost/replica:0/task:0/device:CPU:375, /job:localhost/replica:0/task:0/device:CPU:376, /job:localhost/replica:0/task:0/device:CPU:377, /job:localhost/replica:0/task:0/device:CPU:378, /job:localhost/replica:0/task:0/device:CPU:379, /job:localhost/replica:0/task:0/device:CPU:38, /job:localhost/replica:0/task:0/device:CPU:380, /job:localhost/replica:0/task:0/device:CPU:381, /job:localhost/replica:0/task:0/device:CPU:382, /job:localhost/replica:0/task:0/device:CPU:383, /job:localhost/replica:0/task:0/device:CPU:384, /job:localhost/replica:0/task:0/device:CPU:385, /job:localhost/replica:0/task:0/device:CPU:386, /job:localhost/replica:0/task:0/device:CPU:387, /job:localhost/replica:0/task:0/device:CPU:388, /job:localhost/replica:0/task:0/device:CPU:389, /job:localhost/replica:0/task:0/device:CPU:39, /job:localhost/replica:0/task:0/device:CPU:390, /job:localhost/replica:0/task:0/device:CPU:391, /job:localhost/replica:0/task:0/device:CPU:392, /job:localhost/replica:0/task:0/device:CPU:393, /job:localhost/replica:0/task:0/device:CPU:394, /job:localhost/replica:0/task:0/device:CPU:395, /job:localhost/replica:0/task:0/device:CPU:396, /job:localhost/replica:0/task:0/device:CPU:397, /job:localhost/replica:0/task:0/device:CPU:398, /job:localhost/replica:0/task:0/device:CPU:399, /job:localhost/replica:0/task:0/device:CPU:4, /job:localhost/replica:0/task:0/device:CPU:40, /job:localhost/replica:0/task:0/device:CPU:400, /job:localhost/replica:0/task:0/device:CPU:401, /job:localhost/replica:0/task:0/device:CPU:402, /job:localhost/replica:0/task:0/device:CPU:403, /job:localhost/replica:0/task:0/device:CPU:404, /job:localhost/replica:0/task:0/device:CPU:405, /job:localhost/replica:0/task:0/device:CPU:406, /job:localhost/replica:0/task:0/device:CPU:407, /job:localhost/replica:0/task:0/device:CPU:408, /job:localhost/replica:0/task:0/device:CPU:409, /job:localhost/replica:0/task:0/device:CPU:41, /job:localhost/replica:0/task:0/device:CPU:410, /job:localhost/replica:0/task:0/device:CPU:411, /job:localhost/replica:0/task:0/device:CPU:412, /job:localhost/replica:0/task:0/device:CPU:413, /job:localhost/replica:0/task:0/device:CPU:414, /job:localhost/replica:0/task:0/device:CPU:415, /job:localhost/replica:0/task:0/device:CPU:416, /job:localhost/replica:0/task:0/device:CPU:417, /job:localhost/replica:0/task:0/device:CPU:418, /job:localhost/replica:0/task:0/device:CPU:419, /job:localhost/replica:0/task:0/device:CPU:42, /job:localhost/replica:0/task:0/device:CPU:420, /job:localhost/replica:0/task:0/device:CPU:421, /job:localhost/replica:0/task:0/device:CPU:422, /job:localhost/replica:0/task:0/device:CPU:423, /job:localhost/replica:0/task:0/device:CPU:424, /job:localhost/replica:0/task:0/device:CPU:425, /job:localhost/replica:0/task:0/device:CPU:426, /job:localhost/replica:0/task:0/device:CPU:427, /job:localhost/replica:0/task:0/device:CPU:428, /job:localhost/replica:0/task:0/device:CPU:429, /job:localhost/replica:0/task:0/device:CPU:43, /job:localhost/replica:0/task:0/device:CPU:430, /job:localhost/replica:0/task:0/device:CPU:431, /job:localhost/replica:0/task:0/device:CPU:432, /job:localhost/replica:0/task:0/device:CPU:433, /job:localhost/replica:0/task:0/device:CPU:434, /job:localhost/replica:0/task:0/device:CPU:435, /job:localhost/replica:0/task:0/device:CPU:436, /job:localhost/replica:0/task:0/device:CPU:437, /job:localhost/replica:0/task:0/device:CPU:438, /job:localhost/replica:0/task:0/device:CPU:439, /job:localhost/replica:0/task:0/device:CPU:44, /job:localhost/replica:0/task:0/device:CPU:440, /job:localhost/replica:0/task:0/device:CPU:441, /job:localhost/replica:0/task:0/device:CPU:442, /job:localhost/replica:0/task:0/device:CPU:443, /job:localhost/replica:0/task:0/device:CPU:444, /job:localhost/replica:0/task:0/device:CPU:445, /job:localhost/replica:0/task:0/device:CPU:446, /job:localhost/replica:0/task:0/device:CPU:447, /job:localhost/replica:0/task:0/device:CPU:448, /job:localhost/replica:0/task:0/device:CPU:449, /job:localhost/replica:0/task:0/device:CPU:45, /job:localhost/replica:0/task:0/device:CPU:450, /job:localhost/replica:0/task:0/device:CPU:451, /job:localhost/replica:0/task:0/device:CPU:452, /job:localhost/replica:0/task:0/device:CPU:453, /job:localhost/replica:0/task:0/device:CPU:454, /job:localhost/replica:0/task:0/device:CPU:455, /job:localhost/replica:0/task:0/device:CPU:456, /job:localhost/replica:0/task:0/device:CPU:457, /job:localhost/replica:0/task:0/device:CPU:458, /job:localhost/replica:0/task:0/device:CPU:459, /job:localhost/replica:0/task:0/device:CPU:46, /job:localhost/replica:0/task:0/device:CPU:460, /job:localhost/replica:0/task:0/device:CPU:461, /job:localhost/replica:0/task:0/device:CPU:462, /job:localhost/replica:0/task:0/device:CPU:463, /job:localhost/replica:0/task:0/device:CPU:464, /job:localhost/replica:0/task:0/device:CPU:465, /job:localhost/replica:0/task:0/device:CPU:466, /job:localhost/replica:0/task:0/device:CPU:467, /job:localhost/replica:0/task:0/device:CPU:468, /job:localhost/replica:0/task:0/device:CPU:469, /job:localhost/replica:0/task:0/device:CPU:47, /job:localhost/replica:0/task:0/device:CPU:470, /job:localhost/replica:0/task:0/device:CPU:471, /job:localhost/replica:0/task:0/device:CPU:472, /job:localhost/replica:0/task:0/device:CPU:473, /job:localhost/replica:0/task:0/device:CPU:474, /job:localhost/replica:0/task:0/device:CPU:475, /job:localhost/replica:0/task:0/device:CPU:476, /job:localhost/replica:0/task:0/device:CPU:477, /job:localhost/replica:0/task:0/device:CPU:478, /job:localhost/replica:0/task:0/device:CPU:479, /job:localhost/replica:0/task:0/device:CPU:48, /job:localhost/replica:0/task:0/device:CPU:480, /job:localhost/replica:0/task:0/device:CPU:481, /job:localhost/replica:0/task:0/device:CPU:482, /job:localhost/replica:0/task:0/device:CPU:483, /job:localhost/replica:0/task:0/device:CPU:484, /job:localhost/replica:0/task:0/device:CPU:485, /job:localhost/replica:0/task:0/device:CPU:486, /job:localhost/replica:0/task:0/device:CPU:487, /job:localhost/replica:0/task:0/device:CPU:488, /job:localhost/replica:0/task:0/device:CPU:489, /job:localhost/replica:0/task:0/device:CPU:49, /job:localhost/replica:0/task:0/device:CPU:490, /job:localhost/replica:0/task:0/device:CPU:491, /job:localhost/replica:0/task:0/device:CPU:492, /job:localhost/replica:0/task:0/device:CPU:493, /job:localhost/replica:0/task:0/device:CPU:494, /job:localhost/replica:0/task:0/device:CPU:495, /job:localhost/replica:0/task:0/device:CPU:496, /job:localhost/replica:0/task:0/device:CPU:497, /job:localhost/replica:0/task:0/device:CPU:498, /job:localhost/replica:0/task:0/device:CPU:499, /job:localhost/replica:0/task:0/device:CPU:5, /job:localhost/replica:0/task:0/device:CPU:50, /job:localhost/replica:0/task:0/device:CPU:500, /job:localhost/replica:0/task:0/device:CPU:501, /job:localhost/replica:0/task:0/device:CPU:502, /job:localhost/replica:0/task:0/device:CPU:503, /job:localhost/replica:0/task:0/device:CPU:504, /job:localhost/replica:0/task:0/device:CPU:505, /job:localhost/replica:0/task:0/device:CPU:506, /job:localhost/replica:0/task:0/device:CPU:507, /job:localhost/replica:0/task:0/device:CPU:508, /job:localhost/replica:0/task:0/device:CPU:509, /job:localhost/replica:0/task:0/device:CPU:51, /job:localhost/replica:0/task:0/device:CPU:510, /job:localhost/replica:0/task:0/device:CPU:511, /job:localhost/replica:0/task:0/device:CPU:512, /job:localhost/replica:0/task:0/device:CPU:513, /job:localhost/replica:0/task:0/device:CPU:514, /job:localhost/replica:0/task:0/device:CPU:515, /job:localhost/replica:0/task:0/device:CPU:516, /job:localhost/replica:0/task:0/device:CPU:517, /job:localhost/replica:0/task:0/device:CPU:518, /job:localhost/replica:0/task:0/device:CPU:519, /job:localhost/replica:0/task:0/device:CPU:52, /job:localhost/replica:0/task:0/device:CPU:520, /job:localhost/replica:0/task:0/device:CPU:521, /job:localhost/replica:0/task:0/device:CPU:522, /job:localhost/replica:0/task:0/device:CPU:523, /job:localhost/replica:0/task:0/device:CPU:524, /job:localhost/replica:0/task:0/device:CPU:525, /job:localhost/replica:0/task:0/device:CPU:526, /job:localhost/replica:0/task:0/device:CPU:527, /job:localhost/replica:0/task:0/device:CPU:528, /job:localhost/replica:0/task:0/device:CPU:529, /job:localhost/replica:0/task:0/device:CPU:53, /job:localhost/replica:0/task:0/device:CPU:530, /job:localhost/replica:0/task:0/device:CPU:531, /job:localhost/replica:0/task:0/device:CPU:532, /job:localhost/replica:0/task:0/device:CPU:533, /job:localhost/replica:0/task:0/device:CPU:534, /job:localhost/replica:0/task:0/device:CPU:535, /job:localhost/replica:0/task:0/device:CPU:536, /job:localhost/replica:0/task:0/device:CPU:537, /job:localhost/replica:0/task:0/device:CPU:538, /job:localhost/replica:0/task:0/device:CPU:539, /job:localhost/replica:0/task:0/device:CPU:54, /job:localhost/replica:0/task:0/device:CPU:540, /job:localhost/replica:0/task:0/device:CPU:541, /job:localhost/replica:0/task:0/device:CPU:542, /job:localhost/replica:0/task:0/device:CPU:543, /job:localhost/replica:0/task:0/device:CPU:544, /job:localhost/replica:0/task:0/device:CPU:545, /job:localhost/replica:0/task:0/device:CPU:546, /job:localhost/replica:0/task:0/device:CPU:547, /job:localhost/replica:0/task:0/device:CPU:548, /job:localhost/replica:0/task:0/device:CPU:549, /job:localhost/replica:0/task:0/device:CPU:55, /job:localhost/replica:0/task:0/device:CPU:550, /job:localhost/replica:0/task:0/device:CPU:551, /job:localhost/replica:0/task:0/device:CPU:552, /job:localhost/replica:0/task:0/device:CPU:553, /job:localhost/replica:0/task:0/device:CPU:554, /job:localhost/replica:0/task:0/device:CPU:555, /job:localhost/replica:0/task:0/device:CPU:556, /job:localhost/replica:0/task:0/device:CPU:557, /job:localhost/replica:0/task:0/device:CPU:558, /job:localhost/replica:0/task:0/device:CPU:559, /job:localhost/replica:0/task:0/device:CPU:56, /job:localhost/replica:0/task:0/device:CPU:560, /job:localhost/replica:0/task:0/device:CPU:561, /job:localhost/replica:0/task:0/device:CPU:562, /job:localhost/replica:0/task:0/device:CPU:563, /job:localhost/replica:0/task:0/device:CPU:564, /job:localhost/replica:0/task:0/device:CPU:565, /job:localhost/replica:0/task:0/device:CPU:566, /job:localhost/replica:0/task:0/device:CPU:567, /job:localhost/replica:0/task:0/device:CPU:568, /job:localhost/replica:0/task:0/device:CPU:569, /job:localhost/replica:0/task:0/device:CPU:57, /job:localhost/replica:0/task:0/device:CPU:570, /job:localhost/replica:0/task:0/device:CPU:571, /job:localhost/replica:0/task:0/device:CPU:572, /job:localhost/replica:0/task:0/device:CPU:573, /job:localhost/replica:0/task:0/device:CPU:574, /job:localhost/replica:0/task:0/device:CPU:575, /job:localhost/replica:0/task:0/device:CPU:576, /job:localhost/replica:0/task:0/device:CPU:577, /job:localhost/replica:0/task:0/device:CPU:578, /job:localhost/replica:0/task:0/device:CPU:579, /job:localhost/replica:0/task:0/device:CPU:58, /job:localhost/replica:0/task:0/device:CPU:580, /job:localhost/replica:0/task:0/device:CPU:581, /job:localhost/replica:0/task:0/device:CPU:582, /job:localhost/replica:0/task:0/device:CPU:583, /job:localhost/replica:0/task:0/device:CPU:584, /job:localhost/replica:0/task:0/device:CPU:585, /job:localhost/replica:0/task:0/device:CPU:586, /job:localhost/replica:0/task:0/device:CPU:587, /job:localhost/replica:0/task:0/device:CPU:588, /job:localhost/replica:0/task:0/device:CPU:589, /job:localhost/replica:0/task:0/device:CPU:59, /job:localhost/replica:0/task:0/device:CPU:590, /job:localhost/replica:0/task:0/device:CPU:591, /job:localhost/replica:0/task:0/device:CPU:592, /job:localhost/replica:0/task:0/device:CPU:593, /job:localhost/replica:0/task:0/device:CPU:594, /job:localhost/replica:0/task:0/device:CPU:595, /job:localhost/replica:0/task:0/device:CPU:596, /job:localhost/replica:0/task:0/device:CPU:597, /job:localhost/replica:0/task:0/device:CPU:598, /job:localhost/replica:0/task:0/device:CPU:599, /job:localhost/replica:0/task:0/device:CPU:6, /job:localhost/replica:0/task:0/device:CPU:60, /job:localhost/replica:0/task:0/device:CPU:600, /job:localhost/replica:0/task:0/device:CPU:601, /job:localhost/replica:0/task:0/device:CPU:602, /job:localhost/replica:0/task:0/device:CPU:603, /job:localhost/replica:0/task:0/device:CPU:604, /job:localhost/replica:0/task:0/device:CPU:605, /job:localhost/replica:0/task:0/device:CPU:606, /job:localhost/replica:0/task:0/device:CPU:607, /job:localhost/replica:0/task:0/device:CPU:608, /job:localhost/replica:0/task:0/device:CPU:609, /job:localhost/replica:0/task:0/device:CPU:61, /job:localhost/replica:0/task:0/device:CPU:610, /job:localhost/replica:0/task:0/device:CPU:611, /job:localhost/replica:0/task:0/device:CPU:612, /job:localhost/replica:0/task:0/device:CPU:613, /job:localhost/replica:0/task:0/device:CPU:614, /job:localhost/replica:0/task:0/device:CPU:615, /job:localhost/replica:0/task:0/device:CPU:616, /job:localhost/replica:0/task:0/device:CPU:617, /job:localhost/replica:0/task:0/device:CPU:618, /job:localhost/replica:0/task:0/device:CPU:619, /job:localhost/replica:0/task:0/device:CPU:62, /job:localhost/replica:0/task:0/device:CPU:620, /job:localhost/replica:0/task:0/device:CPU:621, /job:localhost/replica:0/task:0/device:CPU:622, /job:localhost/replica:0/task:0/device:CPU:623, /job:localhost/replica:0/task:0/device:CPU:624, /job:localhost/replica:0/task:0/device:CPU:625, /job:localhost/replica:0/task:0/device:CPU:626, /job:localhost/replica:0/task:0/device:CPU:627, /job:localhost/replica:0/task:0/device:CPU:628, /job:localhost/replica:0/task:0/device:CPU:629, /job:localhost/replica:0/task:0/device:CPU:63, /job:localhost/replica:0/task:0/device:CPU:630, /job:localhost/replica:0/task:0/device:CPU:631, /job:localhost/replica:0/task:0/device:CPU:632, /job:localhost/replica:0/task:0/device:CPU:633, /job:localhost/replica:0/task:0/device:CPU:634, /job:localhost/replica:0/task:0/device:CPU:635, /job:localhost/replica:0/task:0/device:CPU:636, /job:localhost/replica:0/task:0/device:CPU:637, /job:localhost/replica:0/task:0/device:CPU:638, /job:localhost/replica:0/task:0/device:CPU:639, /job:localhost/replica:0/task:0/device:CPU:64, /job:localhost/replica:0/task:0/device:CPU:640, /job:localhost/replica:0/task:0/device:CPU:641, /job:localhost/replica:0/task:0/device:CPU:642, /job:localhost/replica:0/task:0/device:CPU:643, /job:localhost/replica:0/task:0/device:CPU:644, /job:localhost/replica:0/task:0/device:CPU:645, /job:localhost/replica:0/task:0/device:CPU:646, /job:localhost/replica:0/task:0/device:CPU:647, /job:localhost/replica:0/task:0/device:CPU:648, /job:localhost/replica:0/task:0/device:CPU:649, /job:localhost/replica:0/task:0/device:CPU:65, /job:localhost/replica:0/task:0/device:CPU:650, /job:localhost/replica:0/task:0/device:CPU:651, /job:localhost/replica:0/task:0/device:CPU:652, /job:localhost/replica:0/task:0/device:CPU:653, /job:localhost/replica:0/task:0/device:CPU:654, /job:localhost/replica:0/task:0/device:CPU:655, /job:localhost/replica:0/task:0/device:CPU:656, /job:localhost/replica:0/task:0/device:CPU:657, /job:localhost/replica:0/task:0/device:CPU:658, /job:localhost/replica:0/task:0/device:CPU:659, /job:localhost/replica:0/task:0/device:CPU:66, /job:localhost/replica:0/task:0/device:CPU:660, /job:localhost/replica:0/task:0/device:CPU:661, /job:localhost/replica:0/task:0/device:CPU:662, /job:localhost/replica:0/task:0/device:CPU:663, /job:localhost/replica:0/task:0/device:CPU:664, /job:localhost/replica:0/task:0/device:CPU:665, /job:localhost/replica:0/task:0/device:CPU:666, /job:localhost/replica:0/task:0/device:CPU:667, /job:localhost/replica:0/task:0/device:CPU:668, /job:localhost/replica:0/task:0/device:CPU:669, /job:localhost/replica:0/task:0/device:CPU:67, /job:localhost/replica:0/task:0/device:CPU:670, /job:localhost/replica:0/task:0/device:CPU:671, /job:localhost/replica:0/task:0/device:CPU:672, /job:localhost/replica:0/task:0/device:CPU:673, /job:localhost/replica:0/task:0/device:CPU:674, /job:localhost/replica:0/task:0/device:CPU:675, /job:localhost/replica:0/task:0/device:CPU:676, /job:localhost/replica:0/task:0/device:CPU:677, /job:localhost/replica:0/task:0/device:CPU:678, /job:localhost/replica:0/task:0/device:CPU:679, /job:localhost/replica:0/task:0/device:CPU:68, /job:localhost/replica:0/task:0/device:CPU:680, /job:localhost/replica:0/task:0/device:CPU:681, /job:localhost/replica:0/task:0/device:CPU:682, /job:localhost/replica:0/task:0/device:CPU:683, /job:localhost/replica:0/task:0/device:CPU:684, /job:localhost/replica:0/task:0/device:CPU:685, /job:localhost/replica:0/task:0/device:CPU:686, /job:localhost/replica:0/task:0/device:CPU:687, /job:localhost/replica:0/task:0/device:CPU:688, /job:localhost/replica:0/task:0/device:CPU:689, /job:localhost/replica:0/task:0/device:CPU:69, /job:localhost/replica:0/task:0/device:CPU:690, /job:localhost/replica:0/task:0/device:CPU:691, /job:localhost/replica:0/task:0/device:CPU:692, /job:localhost/replica:0/task:0/device:CPU:693, /job:localhost/replica:0/task:0/device:CPU:694, /job:localhost/replica:0/task:0/device:CPU:695, /job:localhost/replica:0/task:0/device:CPU:696, /job:localhost/replica:0/task:0/device:CPU:697, /job:localhost/replica:0/task:0/device:CPU:698, /job:localhost/replica:0/task:0/device:CPU:699, /job:localhost/replica:0/task:0/device:CPU:7, /job:localhost/replica:0/task:0/device:CPU:70, /job:localhost/replica:0/task:0/device:CPU:700, /job:localhost/replica:0/task:0/device:CPU:701, /job:localhost/replica:0/task:0/device:CPU:702, /job:localhost/replica:0/task:0/device:CPU:703, /job:localhost/replica:0/task:0/device:CPU:704, /job:localhost/replica:0/task:0/device:CPU:705, /job:localhost/replica:0/task:0/device:CPU:706, /job:localhost/replica:0/task:0/device:CPU:707, /job:localhost/replica:0/task:0/device:CPU:708, /job:localhost/replica:0/task:0/device:CPU:709, /job:localhost/replica:0/task:0/device:CPU:71, /job:localhost/replica:0/task:0/device:CPU:710, /job:localhost/replica:0/task:0/device:CPU:711, /job:localhost/replica:0/task:0/device:CPU:712, /job:localhost/replica:0/task:0/device:CPU:713, /job:localhost/replica:0/task:0/device:CPU:714, /job:localhost/replica:0/task:0/device:CPU:715, /job:localhost/replica:0/task:0/device:CPU:716, /job:localhost/replica:0/task:0/device:CPU:717, /job:localhost/replica:0/task:0/device:CPU:718, /job:localhost/replica:0/task:0/device:CPU:719, /job:localhost/replica:0/task:0/device:CPU:72, /job:localhost/replica:0/task:0/device:CPU:720, /job:localhost/replica:0/task:0/device:CPU:721, /job:localhost/replica:0/task:0/device:CPU:722, /job:localhost/replica:0/task:0/device:CPU:723, /job:localhost/replica:0/task:0/device:CPU:724, /job:localhost/replica:0/task:0/device:CPU:725, /job:localhost/replica:0/task:0/device:CPU:726, /job:localhost/replica:0/task:0/device:CPU:727, /job:localhost/replica:0/task:0/device:CPU:728, /job:localhost/replica:0/task:0/device:CPU:729, /job:localhost/replica:0/task:0/device:CPU:73, /job:localhost/replica:0/task:0/device:CPU:730, /job:localhost/replica:0/task:0/device:CPU:731, /job:localhost/replica:0/task:0/device:CPU:732, /job:localhost/replica:0/task:0/device:CPU:733, /job:localhost/replica:0/task:0/device:CPU:734, /job:localhost/replica:0/task:0/device:CPU:735, /job:localhost/replica:0/task:0/device:CPU:736, /job:localhost/replica:0/task:0/device:CPU:737, /job:localhost/replica:0/task:0/device:CPU:738, /job:localhost/replica:0/task:0/device:CPU:739, /job:localhost/replica:0/task:0/device:CPU:74, /job:localhost/replica:0/task:0/device:CPU:740, /job:localhost/replica:0/task:0/device:CPU:741, /job:localhost/replica:0/task:0/device:CPU:742, /job:localhost/replica:0/task:0/device:CPU:743, /job:localhost/replica:0/task:0/device:CPU:744, /job:localhost/replica:0/task:0/device:CPU:745, /job:localhost/replica:0/task:0/device:CPU:746, /job:localhost/replica:0/task:0/device:CPU:747, /job:localhost/replica:0/task:0/device:CPU:748, /job:localhost/replica:0/task:0/device:CPU:749, /job:localhost/replica:0/task:0/device:CPU:75, /job:localhost/replica:0/task:0/device:CPU:750, /job:localhost/replica:0/task:0/device:CPU:751, /job:localhost/replica:0/task:0/device:CPU:752, /job:localhost/replica:0/task:0/device:CPU:753, /job:localhost/replica:0/task:0/device:CPU:754, /job:localhost/replica:0/task:0/device:CPU:755, /job:localhost/replica:0/task:0/device:CPU:756, /job:localhost/replica:0/task:0/device:CPU:757, /job:localhost/replica:0/task:0/device:CPU:758, /job:localhost/replica:0/task:0/device:CPU:759, /job:localhost/replica:0/task:0/device:CPU:76, /job:localhost/replica:0/task:0/device:CPU:760, /job:localhost/replica:0/task:0/device:CPU:761, /job:localhost/replica:0/task:0/device:CPU:762, /job:localhost/replica:0/task:0/device:CPU:763, /job:localhost/replica:0/task:0/device:CPU:764, /job:localhost/replica:0/task:0/device:CPU:765, /job:localhost/replica:0/task:0/device:CPU:766, /job:localhost/replica:0/task:0/device:CPU:767, /job:localhost/replica:0/task:0/device:CPU:768, /job:localhost/replica:0/task:0/device:CPU:769, /job:localhost/replica:0/task:0/device:CPU:77, /job:localhost/replica:0/task:0/device:CPU:770, /job:localhost/replica:0/task:0/device:CPU:771, /job:localhost/replica:0/task:0/device:CPU:772, /job:localhost/replica:0/task:0/device:CPU:773, /job:localhost/replica:0/task:0/device:CPU:774, /job:localhost/replica:0/task:0/device:CPU:775, /job:localhost/replica:0/task:0/device:CPU:776, /job:localhost/replica:0/task:0/device:CPU:777, /job:localhost/replica:0/task:0/device:CPU:778, /job:localhost/replica:0/task:0/device:CPU:779, /job:localhost/replica:0/task:0/device:CPU:78, /job:localhost/replica:0/task:0/device:CPU:780, /job:localhost/replica:0/task:0/device:CPU:781, /job:localhost/replica:0/task:0/device:CPU:782, /job:localhost/replica:0/task:0/device:CPU:783, /job:localhost/replica:0/task:0/device:CPU:784, /job:localhost/replica:0/task:0/device:CPU:785, /job:localhost/replica:0/task:0/device:CPU:786, /job:localhost/replica:0/task:0/device:CPU:787, /job:localhost/replica:0/task:0/device:CPU:788, /job:localhost/replica:0/task:0/device:CPU:789, /job:localhost/replica:0/task:0/device:CPU:79, /job:localhost/replica:0/task:0/device:CPU:790, /job:localhost/replica:0/task:0/device:CPU:791, /job:localhost/replica:0/task:0/device:CPU:792, /job:localhost/replica:0/task:0/device:CPU:793, /job:localhost/replica:0/task:0/device:CPU:794, /job:localhost/replica:0/task:0/device:CPU:795, /job:localhost/replica:0/task:0/device:CPU:796, /job:localhost/replica:0/task:0/device:CPU:797, /job:localhost/replica:0/task:0/device:CPU:798, /job:localhost/replica:0/task:0/device:CPU:799, /job:localhost/replica:0/task:0/device:CPU:8, /job:localhost/replica:0/task:0/device:CPU:80, /job:localhost/replica:0/task:0/device:CPU:800, /job:localhost/replica:0/task:0/device:CPU:801, /job:localhost/replica:0/task:0/device:CPU:802, /job:localhost/replica:0/task:0/device:CPU:803, /job:localhost/replica:0/task:0/device:CPU:804, /job:localhost/replica:0/task:0/device:CPU:805, /job:localhost/replica:0/task:0/device:CPU:806, /job:localhost/replica:0/task:0/device:CPU:807, /job:localhost/replica:0/task:0/device:CPU:808, /job:localhost/replica:0/task:0/device:CPU:809, /job:localhost/replica:0/task:0/device:CPU:81, /job:localhost/replica:0/task:0/device:CPU:810, /job:localhost/replica:0/task:0/device:CPU:811, /job:localhost/replica:0/task:0/device:CPU:812, /job:localhost/replica:0/task:0/device:CPU:813, /job:localhost/replica:0/task:0/device:CPU:814, /job:localhost/replica:0/task:0/device:CPU:815, /job:localhost/replica:0/task:0/device:CPU:816, /job:localhost/replica:0/task:0/device:CPU:817, /job:localhost/replica:0/task:0/device:CPU:818, /job:localhost/replica:0/task:0/device:CPU:819, /job:localhost/replica:0/task:0/device:CPU:82, /job:localhost/replica:0/task:0/device:CPU:820, /job:localhost/replica:0/task:0/device:CPU:821, /job:localhost/replica:0/task:0/device:CPU:822, /job:localhost/replica:0/task:0/device:CPU:823, /job:localhost/replica:0/task:0/device:CPU:824, /job:localhost/replica:0/task:0/device:CPU:825, /job:localhost/replica:0/task:0/device:CPU:826, /job:localhost/replica:0/task:0/device:CPU:827, /job:localhost/replica:0/task:0/device:CPU:828, /job:localhost/replica:0/task:0/device:CPU:829, /job:localhost/replica:0/task:0/device:CPU:83, /job:localhost/replica:0/task:0/device:CPU:830, /job:localhost/replica:0/task:0/device:CPU:831, /job:localhost/replica:0/task:0/device:CPU:832, /job:localhost/replica:0/task:0/device:CPU:833, /job:localhost/replica:0/task:0/device:CPU:834, /job:localhost/replica:0/task:0/device:CPU:835, /job:localhost/replica:0/task:0/device:CPU:836, /job:localhost/replica:0/task:0/device:CPU:837, /job:localhost/replica:0/task:0/device:CPU:838, /job:localhost/replica:0/task:0/device:CPU:839, /job:localhost/replica:0/task:0/device:CPU:84, /job:localhost/replica:0/task:0/device:CPU:840, /job:localhost/replica:0/task:0/device:CPU:841, /job:localhost/replica:0/task:0/device:CPU:842, /job:localhost/replica:0/task:0/device:CPU:843, /job:localhost/replica:0/task:0/device:CPU:844, /job:localhost/replica:0/task:0/device:CPU:845, /job:localhost/replica:0/task:0/device:CPU:846, /job:localhost/replica:0/task:0/device:CPU:847, /job:localhost/replica:0/task:0/device:CPU:848, /job:localhost/replica:0/task:0/device:CPU:849, /job:localhost/replica:0/task:0/device:CPU:85, /job:localhost/replica:0/task:0/device:CPU:850, /job:localhost/replica:0/task:0/device:CPU:851, /job:localhost/replica:0/task:0/device:CPU:852, /job:localhost/replica:0/task:0/device:CPU:853, /job:localhost/replica:0/task:0/device:CPU:854, /job:localhost/replica:0/task:0/device:CPU:855, /job:localhost/replica:0/task:0/device:CPU:856, /job:localhost/replica:0/task:0/device:CPU:857, /job:localhost/replica:0/task:0/device:CPU:858, /job:localhost/replica:0/task:0/device:CPU:859, /job:localhost/replica:0/task:0/device:CPU:86, /job:localhost/replica:0/task:0/device:CPU:860, /job:localhost/replica:0/task:0/device:CPU:861, /job:localhost/replica:0/task:0/device:CPU:862, /job:localhost/replica:0/task:0/device:CPU:863, /job:localhost/replica:0/task:0/device:CPU:864, /job:localhost/replica:0/task:0/device:CPU:865, /job:localhost/replica:0/task:0/device:CPU:866, /job:localhost/replica:0/task:0/device:CPU:867, /job:localhost/replica:0/task:0/device:CPU:868, /job:localhost/replica:0/task:0/device:CPU:869, /job:localhost/replica:0/task:0/device:CPU:87, /job:localhost/replica:0/task:0/device:CPU:870, /job:localhost/replica:0/task:0/device:CPU:871, /job:localhost/replica:0/task:0/device:CPU:872, /job:localhost/replica:0/task:0/device:CPU:873, /job:localhost/replica:0/task:0/device:CPU:874, /job:localhost/replica:0/task:0/device:CPU:875, /job:localhost/replica:0/task:0/device:CPU:876, /job:localhost/replica:0/task:0/device:CPU:877, /job:localhost/replica:0/task:0/device:CPU:878, /job:localhost/replica:0/task:0/device:CPU:879, /job:localhost/replica:0/task:0/device:CPU:88, /job:localhost/replica:0/task:0/device:CPU:880, /job:localhost/replica:0/task:0/device:CPU:881, /job:localhost/replica:0/task:0/device:CPU:882, /job:localhost/replica:0/task:0/device:CPU:883, /job:localhost/replica:0/task:0/device:CPU:884, /job:localhost/replica:0/task:0/device:CPU:885, /job:localhost/replica:0/task:0/device:CPU:886, /job:localhost/replica:0/task:0/device:CPU:887, /job:localhost/replica:0/task:0/device:CPU:888, /job:localhost/replica:0/task:0/device:CPU:889, /job:localhost/replica:0/task:0/device:CPU:89, /job:localhost/replica:0/task:0/device:CPU:890, /job:localhost/replica:0/task:0/device:CPU:891, /job:localhost/replica:0/task:0/device:CPU:892, /job:localhost/replica:0/task:0/device:CPU:893, /job:localhost/replica:0/task:0/device:CPU:894, /job:localhost/replica:0/task:0/device:CPU:895, /job:localhost/replica:0/task:0/device:CPU:896, /job:localhost/replica:0/task:0/device:CPU:897, /job:localhost/replica:0/task:0/device:CPU:898, /job:localhost/replica:0/task:0/device:CPU:899, /job:localhost/replica:0/task:0/device:CPU:9, /job:localhost/replica:0/task:0/device:CPU:90, /job:localhost/replica:0/task:0/device:CPU:900, /job:localhost/replica:0/task:0/device:CPU:901, /job:localhost/replica:0/task:0/device:CPU:902, /job:localhost/replica:0/task:0/device:CPU:903, /job:localhost/replica:0/task:0/device:CPU:904, /job:localhost/replica:0/task:0/device:CPU:905, /job:localhost/replica:0/task:0/device:CPU:906, /job:localhost/replica:0/task:0/device:CPU:907, /job:localhost/replica:0/task:0/device:CPU:908, /job:localhost/replica:0/task:0/device:CPU:909, /job:localhost/replica:0/task:0/device:CPU:91, /job:localhost/replica:0/task:0/device:CPU:910, /job:localhost/replica:0/task:0/device:CPU:911, /job:localhost/replica:0/task:0/device:CPU:912, /job:localhost/replica:0/task:0/device:CPU:913, /job:localhost/replica:0/task:0/device:CPU:914, /job:localhost/replica:0/task:0/device:CPU:915, /job:localhost/replica:0/task:0/device:CPU:916, /job:localhost/replica:0/task:0/device:CPU:917, /job:localhost/replica:0/task:0/device:CPU:918, /job:localhost/replica:0/task:0/device:CPU:919, /job:localhost/replica:0/task:0/device:CPU:92, /job:localhost/replica:0/task:0/device:CPU:920, /job:localhost/replica:0/task:0/device:CPU:921, /job:localhost/replica:0/task:0/device:CPU:922, /job:localhost/replica:0/task:0/device:CPU:923, /job:localhost/replica:0/task:0/device:CPU:924, /job:localhost/replica:0/task:0/device:CPU:925, /job:localhost/replica:0/task:0/device:CPU:926, /job:localhost/replica:0/task:0/device:CPU:927, /job:localhost/replica:0/task:0/device:CPU:928, /job:localhost/replica:0/task:0/device:CPU:929, /job:localhost/replica:0/task:0/device:CPU:93, /job:localhost/replica:0/task:0/device:CPU:930, /job:localhost/replica:0/task:0/device:CPU:931, /job:localhost/replica:0/task:0/device:CPU:932, /job:localhost/replica:0/task:0/device:CPU:933, /job:localhost/replica:0/task:0/device:CPU:934, /job:localhost/replica:0/task:0/device:CPU:935, /job:localhost/replica:0/task:0/device:CPU:936, /job:localhost/replica:0/task:0/device:CPU:937, /job:localhost/replica:0/task:0/device:CPU:938, /job:localhost/replica:0/task:0/device:CPU:939, /job:localhost/replica:0/task:0/device:CPU:94, /job:localhost/replica:0/task:0/device:CPU:940, /job:localhost/replica:0/task:0/device:CPU:941, /job:localhost/replica:0/task:0/device:CPU:942, /job:localhost/replica:0/task:0/device:CPU:943, /job:localhost/replica:0/task:0/device:CPU:944, /job:localhost/replica:0/task:0/device:CPU:945, /job:localhost/replica:0/task:0/device:CPU:946, /job:localhost/replica:0/task:0/device:CPU:947, /job:localhost/replica:0/task:0/device:CPU:948, /job:localhost/replica:0/task:0/device:CPU:949, /job:localhost/replica:0/task:0/device:CPU:95, /job:localhost/replica:0/task:0/device:CPU:950, /job:localhost/replica:0/task:0/device:CPU:951, /job:localhost/replica:0/task:0/device:CPU:952, /job:localhost/replica:0/task:0/device:CPU:953, /job:localhost/replica:0/task:0/device:CPU:954, /job:localhost/replica:0/task:0/device:CPU:955, /job:localhost/replica:0/task:0/device:CPU:956, /job:localhost/replica:0/task:0/device:CPU:957, /job:localhost/replica:0/task:0/device:CPU:958, /job:localhost/replica:0/task:0/device:CPU:959, /job:localhost/replica:0/task:0/device:CPU:96, /job:localhost/replica:0/task:0/device:CPU:960, /job:localhost/replica:0/task:0/device:CPU:961, /job:localhost/replica:0/task:0/device:CPU:962, /job:localhost/replica:0/task:0/device:CPU:963, /job:localhost/replica:0/task:0/device:CPU:964, /job:localhost/replica:0/task:0/device:CPU:965, /job:localhost/replica:0/task:0/device:CPU:966, /job:localhost/replica:0/task:0/device:CPU:967, /job:localhost/replica:0/task:0/device:CPU:968, /job:localhost/replica:0/task:0/device:CPU:969, /job:localhost/replica:0/task:0/device:CPU:97, /job:localhost/replica:0/task:0/device:CPU:970, /job:localhost/replica:0/task:0/device:CPU:971, /job:localhost/replica:0/task:0/device:CPU:972, /job:localhost/replica:0/task:0/device:CPU:973, /job:localhost/replica:0/task:0/device:CPU:974, /job:localhost/replica:0/task:0/device:CPU:975, /job:localhost/replica:0/task:0/device:CPU:976, /job:localhost/replica:0/task:0/device:CPU:977, /job:localhost/replica:0/task:0/device:CPU:978, /job:localhost/replica:0/task:0/device:CPU:979, /job:localhost/replica:0/task:0/device:CPU:98, /job:localhost/replica:0/task:0/device:CPU:980, /job:localhost/replica:0/task:0/device:CPU:981, /job:localhost/replica:0/task:0/device:CPU:982, /job:localhost/replica:0/task:0/device:CPU:983, /job:localhost/replica:0/task:0/device:CPU:984, /job:localhost/replica:0/task:0/device:CPU:985, /job:localhost/replica:0/task:0/device:CPU:986, /job:localhost/replica:0/task:0/device:CPU:987, /job:localhost/replica:0/task:0/device:CPU:988, /job:localhost/replica:0/task:0/device:CPU:989, /job:localhost/replica:0/task:0/device:CPU:99, /job:localhost/replica:0/task:0/device:CPU:990, /job:localhost/replica:0/task:0/device:CPU:991, /job:localhost/replica:0/task:0/device:CPU:992, /job:localhost/replica:0/task:0/device:CPU:993, /job:localhost/replica:0/task:0/device:CPU:994, /job:localhost/replica:0/task:0/device:CPU:995, /job:localhost/replica:0/task:0/device:CPU:996, /job:localhost/replica:0/task:0/device:CPU:997, /job:localhost/replica:0/task:0/device:CPU:998, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
	 [[net/b]]
2022-3-24 8:29:22.08: Traceback (most recent call last):
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1356, in _do_call
    return fn(*args)
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1339, in _run_fn
    self._extend_graph()
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1374, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation net/b: {{node net/b}}was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:CPU:1, /job:localhost/replica:0/task:0/device:CPU:10, /job:localhost/replica:0/task:0/device:CPU:100, /job:localhost/replica:0/task:0/device:CPU:101, /job:localhost/replica:0/task:0/device:CPU:102, /job:localhost/replica:0/task:0/device:CPU:103, /job:localhost/replica:0/task:0/device:CPU:104, /job:localhost/replica:0/task:0/device:CPU:105, /job:localhost/replica:0/task:0/device:CPU:106, /job:localhost/replica:0/task:0/device:CPU:107, /job:localhost/replica:0/task:0/device:CPU:108, /job:localhost/replica:0/task:0/device:CPU:109, /job:localhost/replica:0/task:0/device:CPU:11, /job:localhost/replica:0/task:0/device:CPU:110, /job:localhost/replica:0/task:0/device:CPU:111, /job:localhost/replica:0/task:0/device:CPU:112, /job:localhost/replica:0/task:0/device:CPU:113, /job:localhost/replica:0/task:0/device:CPU:114, /job:localhost/replica:0/task:0/device:CPU:115, /job:localhost/replica:0/task:0/device:CPU:116, /job:localhost/replica:0/task:0/device:CPU:117, /job:localhost/replica:0/task:0/device:CPU:118, /job:localhost/replica:0/task:0/device:CPU:119, /job:localhost/replica:0/task:0/device:CPU:12, /job:localhost/replica:0/task:0/device:CPU:120, /job:localhost/replica:0/task:0/device:CPU:121, /job:localhost/replica:0/task:0/device:CPU:122, /job:localhost/replica:0/task:0/device:CPU:123, /job:localhost/replica:0/task:0/device:CPU:124, /job:localhost/replica:0/task:0/device:CPU:125, /job:localhost/replica:0/task:0/device:CPU:126, /job:localhost/replica:0/task:0/device:CPU:127, /job:localhost/replica:0/task:0/device:CPU:128, /job:localhost/replica:0/task:0/device:CPU:129, /job:localhost/replica:0/task:0/device:CPU:13, /job:localhost/replica:0/task:0/device:CPU:130, /job:localhost/replica:0/task:0/device:CPU:131, /job:localhost/replica:0/task:0/device:CPU:132, /job:localhost/replica:0/task:0/device:CPU:133, /job:localhost/replica:0/task:0/device:CPU:134, /job:localhost/replica:0/task:0/device:CPU:135, /job:localhost/replica:0/task:0/device:CPU:136, /job:localhost/replica:0/task:0/device:CPU:137, /job:localhost/replica:0/task:0/device:CPU:138, /job:localhost/replica:0/task:0/device:CPU:139, /job:localhost/replica:0/task:0/device:CPU:14, /job:localhost/replica:0/task:0/device:CPU:140, /job:localhost/replica:0/task:0/device:CPU:141, /job:localhost/replica:0/task:0/device:CPU:142, /job:localhost/replica:0/task:0/device:CPU:143, /job:localhost/replica:0/task:0/device:CPU:144, /job:localhost/replica:0/task:0/device:CPU:145, /job:localhost/replica:0/task:0/device:CPU:146, /job:localhost/replica:0/task:0/device:CPU:147, /job:localhost/replica:0/task:0/device:CPU:148, /job:localhost/replica:0/task:0/device:CPU:149, /job:localhost/replica:0/task:0/device:CPU:15, /job:localhost/replica:0/task:0/device:CPU:150, /job:localhost/replica:0/task:0/device:CPU:151, /job:localhost/replica:0/task:0/device:CPU:152, /job:localhost/replica:0/task:0/device:CPU:153, /job:localhost/replica:0/task:0/device:CPU:154, /job:localhost/replica:0/task:0/device:CPU:155, /job:localhost/replica:0/task:0/device:CPU:156, /job:localhost/replica:0/task:0/device:CPU:157, /job:localhost/replica:0/task:0/device:CPU:158, /job:localhost/replica:0/task:0/device:CPU:159, /job:localhost/replica:0/task:0/device:CPU:16, /job:localhost/replica:0/task:0/device:CPU:160, /job:localhost/replica:0/task:0/device:CPU:161, /job:localhost/replica:0/task:0/device:CPU:162, /job:localhost/replica:0/task:0/device:CPU:163, /job:localhost/replica:0/task:0/device:CPU:164, /job:localhost/replica:0/task:0/device:CPU:165, /job:localhost/replica:0/task:0/device:CPU:166, /job:localhost/replica:0/task:0/device:CPU:167, /job:localhost/replica:0/task:0/device:CPU:168, /job:localhost/replica:0/task:0/device:CPU:169, /job:localhost/replica:0/task:0/device:CPU:17, /job:localhost/replica:0/task:0/device:CPU:170, /job:localhost/replica:0/task:0/device:CPU:171, /job:localhost/replica:0/task:0/device:CPU:172, /job:localhost/replica:0/task:0/device:CPU:173, /job:localhost/replica:0/task:0/device:CPU:174, /job:localhost/replica:0/task:0/device:CPU:175, /job:localhost/replica:0/task:0/device:CPU:176, /job:localhost/replica:0/task:0/device:CPU:177, /job:localhost/replica:0/task:0/device:CPU:178, /job:localhost/replica:0/task:0/device:CPU:179, /job:localhost/replica:0/task:0/device:CPU:18, /job:localhost/replica:0/task:0/device:CPU:180, /job:localhost/replica:0/task:0/device:CPU:181, /job:localhost/replica:0/task:0/device:CPU:182, /job:localhost/replica:0/task:0/device:CPU:183, /job:localhost/replica:0/task:0/device:CPU:184, /job:localhost/replica:0/task:0/device:CPU:185, /job:localhost/replica:0/task:0/device:CPU:186, /job:localhost/replica:0/task:0/device:CPU:187, /job:localhost/replica:0/task:0/device:CPU:188, /job:localhost/replica:0/task:0/device:CPU:189, /job:localhost/replica:0/task:0/device:CPU:19, /job:localhost/replica:0/task:0/device:CPU:190, /job:localhost/replica:0/task:0/device:CPU:191, /job:localhost/replica:0/task:0/device:CPU:192, /job:localhost/replica:0/task:0/device:CPU:193, /job:localhost/replica:0/task:0/device:CPU:194, /job:localhost/replica:0/task:0/device:CPU:195, /job:localhost/replica:0/task:0/device:CPU:196, /job:localhost/replica:0/task:0/device:CPU:197, /job:localhost/replica:0/task:0/device:CPU:198, /job:localhost/replica:0/task:0/device:CPU:199, /job:localhost/replica:0/task:0/device:CPU:2, /job:localhost/replica:0/task:0/device:CPU:20, /job:localhost/replica:0/task:0/device:CPU:200, /job:localhost/replica:0/task:0/device:CPU:201, /job:localhost/replica:0/task:0/device:CPU:202, /job:localhost/replica:0/task:0/device:CPU:203, /job:localhost/replica:0/task:0/device:CPU:204, /job:localhost/replica:0/task:0/device:CPU:205, /job:localhost/replica:0/task:0/device:CPU:206, /job:localhost/replica:0/task:0/device:CPU:207, /job:localhost/replica:0/task:0/device:CPU:208, /job:localhost/replica:0/task:0/device:CPU:209, /job:localhost/replica:0/task:0/device:CPU:21, /job:localhost/replica:0/task:0/device:CPU:210, /job:localhost/replica:0/task:0/device:CPU:211, /job:localhost/replica:0/task:0/device:CPU:212, /job:localhost/replica:0/task:0/device:CPU:213, /job:localhost/replica:0/task:0/device:CPU:214, /job:localhost/replica:0/task:0/device:CPU:215, /job:localhost/replica:0/task:0/device:CPU:216, /job:localhost/replica:0/task:0/device:CPU:217, /job:localhost/replica:0/task:0/device:CPU:218, /job:localhost/replica:0/task:0/device:CPU:219, /job:localhost/replica:0/task:0/device:CPU:22, /job:localhost/replica:0/task:0/device:CPU:220, /job:localhost/replica:0/task:0/device:CPU:221, /job:localhost/replica:0/task:0/device:CPU:222, /job:localhost/replica:0/task:0/device:CPU:223, /job:localhost/replica:0/task:0/device:CPU:224, /job:localhost/replica:0/task:0/device:CPU:225, /job:localhost/replica:0/task:0/device:CPU:226, /job:localhost/replica:0/task:0/device:CPU:227, /job:localhost/replica:0/task:0/device:CPU:228, /job:localhost/replica:0/task:0/device:CPU:229, /job:localhost/replica:0/task:0/device:CPU:23, /job:localhost/replica:0/task:0/device:CPU:230, /job:localhost/replica:0/task:0/device:CPU:231, /job:localhost/replica:0/task:0/device:CPU:232, /job:localhost/replica:0/task:0/device:CPU:233, /job:localhost/replica:0/task:0/device:CPU:234, /job:localhost/replica:0/task:0/device:CPU:235, /job:localhost/replica:0/task:0/device:CPU:236, /job:localhost/replica:0/task:0/device:CPU:237, /job:localhost/replica:0/task:0/device:CPU:238, /job:localhost/replica:0/task:0/device:CPU:239, /job:localhost/replica:0/task:0/device:CPU:24, /job:localhost/replica:0/task:0/device:CPU:240, /job:localhost/replica:0/task:0/device:CPU:241, /job:localhost/replica:0/task:0/device:CPU:242, /job:localhost/replica:0/task:0/device:CPU:243, /job:localhost/replica:0/task:0/device:CPU:244, /job:localhost/replica:0/task:0/device:CPU:245, /job:localhost/replica:0/task:0/device:CPU:246, /job:localhost/replica:0/task:0/device:CPU:247, /job:localhost/replica:0/task:0/device:CPU:248, /job:localhost/replica:0/task:0/device:CPU:249, /job:localhost/replica:0/task:0/device:CPU:25, /job:localhost/replica:0/task:0/device:CPU:250, /job:localhost/replica:0/task:0/device:CPU:251, /job:localhost/replica:0/task:0/device:CPU:252, /job:localhost/replica:0/task:0/device:CPU:253, /job:localhost/replica:0/task:0/device:CPU:254, /job:localhost/replica:0/task:0/device:CPU:255, /job:localhost/replica:0/task:0/device:CPU:256, /job:localhost/replica:0/task:0/device:CPU:257, /job:localhost/replica:0/task:0/device:CPU:258, /job:localhost/replica:0/task:0/device:CPU:259, /job:localhost/replica:0/task:0/device:CPU:26, /job:localhost/replica:0/task:0/device:CPU:260, /job:localhost/replica:0/task:0/device:CPU:261, /job:localhost/replica:0/task:0/device:CPU:262, /job:localhost/replica:0/task:0/device:CPU:263, /job:localhost/replica:0/task:0/device:CPU:264, /job:localhost/replica:0/task:0/device:CPU:265, /job:localhost/replica:0/task:0/device:CPU:266, /job:localhost/replica:0/task:0/device:CPU:267, /job:localhost/replica:0/task:0/device:CPU:268, /job:localhost/replica:0/task:0/device:CPU:269, /job:localhost/replica:0/task:0/device:CPU:27, /job:localhost/replica:0/task:0/device:CPU:270, /job:localhost/replica:0/task:0/device:CPU:271, /job:localhost/replica:0/task:0/device:CPU:272, /job:localhost/replica:0/task:0/device:CPU:273, /job:localhost/replica:0/task:0/device:CPU:274, /job:localhost/replica:0/task:0/device:CPU:275, /job:localhost/replica:0/task:0/device:CPU:276, /job:localhost/replica:0/task:0/device:CPU:277, /job:localhost/replica:0/task:0/device:CPU:278, /job:localhost/replica:0/task:0/device:CPU:279, /job:localhost/replica:0/task:0/device:CPU:28, /job:localhost/replica:0/task:0/device:CPU:280, /job:localhost/replica:0/task:0/device:CPU:281, /job:localhost/replica:0/task:0/device:CPU:282, /job:localhost/replica:0/task:0/device:CPU:283, /job:localhost/replica:0/task:0/device:CPU:284, /job:localhost/replica:0/task:0/device:CPU:285, /job:localhost/replica:0/task:0/device:CPU:286, /job:localhost/replica:0/task:0/device:CPU:287, /job:localhost/replica:0/task:0/device:CPU:288, /job:localhost/replica:0/task:0/device:CPU:289, /job:localhost/replica:0/task:0/device:CPU:29, /job:localhost/replica:0/task:0/device:CPU:290, /job:localhost/replica:0/task:0/device:CPU:291, /job:localhost/replica:0/task:0/device:CPU:292, /job:localhost/replica:0/task:0/device:CPU:293, /job:localhost/replica:0/task:0/device:CPU:294, /job:localhost/replica:0/task:0/device:CPU:295, /job:localhost/replica:0/task:0/device:CPU:296, /job:localhost/replica:0/task:0/device:CPU:297, /job:localhost/replica:0/task:0/device:CPU:298, /job:localhost/replica:0/task:0/device:CPU:299, /job:localhost/replica:0/task:0/device:CPU:3, /job:localhost/replica:0/task:0/device:CPU:30, /job:localhost/replica:0/task:0/device:CPU:300, /job:localhost/replica:0/task:0/device:CPU:301, /job:localhost/replica:0/task:0/device:CPU:302, /job:localhost/replica:0/task:0/device:CPU:303, /job:localhost/replica:0/task:0/device:CPU:304, /job:localhost/replica:0/task:0/device:CPU:305, /job:localhost/replica:0/task:0/device:CPU:306, /job:localhost/replica:0/task:0/device:CPU:307, /job:localhost/replica:0/task:0/device:CPU:308, /job:localhost/replica:0/task:0/device:CPU:309, /job:localhost/replica:0/task:0/device:CPU:31, /job:localhost/replica:0/task:0/device:CPU:310, /job:localhost/replica:0/task:0/device:CPU:311, /job:localhost/replica:0/task:0/device:CPU:312, /job:localhost/replica:0/task:0/device:CPU:313, /job:localhost/replica:0/task:0/device:CPU:314, /job:localhost/replica:0/task:0/device:CPU:315, /job:localhost/replica:0/task:0/device:CPU:316, /job:localhost/replica:0/task:0/device:CPU:317, /job:localhost/replica:0/task:0/device:CPU:318, /job:localhost/replica:0/task:0/device:CPU:319, /job:localhost/replica:0/task:0/device:CPU:32, /job:localhost/replica:0/task:0/device:CPU:320, /job:localhost/replica:0/task:0/device:CPU:321, /job:localhost/replica:0/task:0/device:CPU:322, /job:localhost/replica:0/task:0/device:CPU:323, /job:localhost/replica:0/task:0/device:CPU:324, /job:localhost/replica:0/task:0/device:CPU:325, /job:localhost/replica:0/task:0/device:CPU:326, /job:localhost/replica:0/task:0/device:CPU:327, /job:localhost/replica:0/task:0/device:CPU:328, /job:localhost/replica:0/task:0/device:CPU:329, /job:localhost/replica:0/task:0/device:CPU:33, /job:localhost/replica:0/task:0/device:CPU:330, /job:localhost/replica:0/task:0/device:CPU:331, /job:localhost/replica:0/task:0/device:CPU:332, /job:localhost/replica:0/task:0/device:CPU:333, /job:localhost/replica:0/task:0/device:CPU:334, /job:localhost/replica:0/task:0/device:CPU:335, /job:localhost/replica:0/task:0/device:CPU:336, /job:localhost/replica:0/task:0/device:CPU:337, /job:localhost/replica:0/task:0/device:CPU:338, /job:localhost/replica:0/task:0/device:CPU:339, /job:localhost/replica:0/task:0/device:CPU:34, /job:localhost/replica:0/task:0/device:CPU:340, /job:localhost/replica:0/task:0/device:CPU:341, /job:localhost/replica:0/task:0/device:CPU:342, /job:localhost/replica:0/task:0/device:CPU:343, /job:localhost/replica:0/task:0/device:CPU:344, /job:localhost/replica:0/task:0/device:CPU:345, /job:localhost/replica:0/task:0/device:CPU:346, /job:localhost/replica:0/task:0/device:CPU:347, /job:localhost/replica:0/task:0/device:CPU:348, /job:localhost/replica:0/task:0/device:CPU:349, /job:localhost/replica:0/task:0/device:CPU:35, /job:localhost/replica:0/task:0/device:CPU:350, /job:localhost/replica:0/task:0/device:CPU:351, /job:localhost/replica:0/task:0/device:CPU:352, /job:localhost/replica:0/task:0/device:CPU:353, /job:localhost/replica:0/task:0/device:CPU:354, /job:localhost/replica:0/task:0/device:CPU:355, /job:localhost/replica:0/task:0/device:CPU:356, /job:localhost/replica:0/task:0/device:CPU:357, /job:localhost/replica:0/task:0/device:CPU:358, /job:localhost/replica:0/task:0/device:CPU:359, /job:localhost/replica:0/task:0/device:CPU:36, /job:localhost/replica:0/task:0/device:CPU:360, /job:localhost/replica:0/task:0/device:CPU:361, /job:localhost/replica:0/task:0/device:CPU:362, /job:localhost/replica:0/task:0/device:CPU:363, /job:localhost/replica:0/task:0/device:CPU:364, /job:localhost/replica:0/task:0/device:CPU:365, /job:localhost/replica:0/task:0/device:CPU:366, /job:localhost/replica:0/task:0/device:CPU:367, /job:localhost/replica:0/task:0/device:CPU:368, /job:localhost/replica:0/task:0/device:CPU:369, /job:localhost/replica:0/task:0/device:CPU:37, /job:localhost/replica:0/task:0/device:CPU:370, /job:localhost/replica:0/task:0/device:CPU:371, /job:localhost/replica:0/task:0/device:CPU:372, /job:localhost/replica:0/task:0/device:CPU:373, /job:localhost/replica:0/task:0/device:CPU:374, /job:localhost/replica:0/task:0/device:CPU:375, /job:localhost/replica:0/task:0/device:CPU:376, /job:localhost/replica:0/task:0/device:CPU:377, /job:localhost/replica:0/task:0/device:CPU:378, /job:localhost/replica:0/task:0/device:CPU:379, /job:localhost/replica:0/task:0/device:CPU:38, /job:localhost/replica:0/task:0/device:CPU:380, /job:localhost/replica:0/task:0/device:CPU:381, /job:localhost/replica:0/task:0/device:CPU:382, /job:localhost/replica:0/task:0/device:CPU:383, /job:localhost/replica:0/task:0/device:CPU:384, /job:localhost/replica:0/task:0/device:CPU:385, /job:localhost/replica:0/task:0/device:CPU:386, /job:localhost/replica:0/task:0/device:CPU:387, /job:localhost/replica:0/task:0/device:CPU:388, /job:localhost/replica:0/task:0/device:CPU:389, /job:localhost/replica:0/task:0/device:CPU:39, /job:localhost/replica:0/task:0/device:CPU:390, /job:localhost/replica:0/task:0/device:CPU:391, /job:localhost/replica:0/task:0/device:CPU:392, /job:localhost/replica:0/task:0/device:CPU:393, /job:localhost/replica:0/task:0/device:CPU:394, /job:localhost/replica:0/task:0/device:CPU:395, /job:localhost/replica:0/task:0/device:CPU:396, /job:localhost/replica:0/task:0/device:CPU:397, /job:localhost/replica:0/task:0/device:CPU:398, /job:localhost/replica:0/task:0/device:CPU:399, /job:localhost/replica:0/task:0/device:CPU:4, /job:localhost/replica:0/task:0/device:CPU:40, /job:localhost/replica:0/task:0/device:CPU:400, /job:localhost/replica:0/task:0/device:CPU:401, /job:localhost/replica:0/task:0/device:CPU:402, /job:localhost/replica:0/task:0/device:CPU:403, /job:localhost/replica:0/task:0/device:CPU:404, /job:localhost/replica:0/task:0/device:CPU:405, /job:localhost/replica:0/task:0/device:CPU:406, /job:localhost/replica:0/task:0/device:CPU:407, /job:localhost/replica:0/task:0/device:CPU:408, /job:localhost/replica:0/task:0/device:CPU:409, /job:localhost/replica:0/task:0/device:CPU:41, /job:localhost/replica:0/task:0/device:CPU:410, /job:localhost/replica:0/task:0/device:CPU:411, /job:localhost/replica:0/task:0/device:CPU:412, /job:localhost/replica:0/task:0/device:CPU:413, /job:localhost/replica:0/task:0/device:CPU:414, /job:localhost/replica:0/task:0/device:CPU:415, /job:localhost/replica:0/task:0/device:CPU:416, /job:localhost/replica:0/task:0/device:CPU:417, /job:localhost/replica:0/task:0/device:CPU:418, /job:localhost/replica:0/task:0/device:CPU:419, /job:localhost/replica:0/task:0/device:CPU:42, /job:localhost/replica:0/task:0/device:CPU:420, /job:localhost/replica:0/task:0/device:CPU:421, /job:localhost/replica:0/task:0/device:CPU:422, /job:localhost/replica:0/task:0/device:CPU:423, /job:localhost/replica:0/task:0/device:CPU:424, /job:localhost/replica:0/task:0/device:CPU:425, /job:localhost/replica:0/task:0/device:CPU:426, /job:localhost/replica:0/task:0/device:CPU:427, /job:localhost/replica:0/task:0/device:CPU:428, /job:localhost/replica:0/task:0/device:CPU:429, /job:localhost/replica:0/task:0/device:CPU:43, /job:localhost/replica:0/task:0/device:CPU:430, /job:localhost/replica:0/task:0/device:CPU:431, /job:localhost/replica:0/task:0/device:CPU:432, /job:localhost/replica:0/task:0/device:CPU:433, /job:localhost/replica:0/task:0/device:CPU:434, /job:localhost/replica:0/task:0/device:CPU:435, /job:localhost/replica:0/task:0/device:CPU:436, /job:localhost/replica:0/task:0/device:CPU:437, /job:localhost/replica:0/task:0/device:CPU:438, /job:localhost/replica:0/task:0/device:CPU:439, /job:localhost/replica:0/task:0/device:CPU:44, /job:localhost/replica:0/task:0/device:CPU:440, /job:localhost/replica:0/task:0/device:CPU:441, /job:localhost/replica:0/task:0/device:CPU:442, /job:localhost/replica:0/task:0/device:CPU:443, /job:localhost/replica:0/task:0/device:CPU:444, /job:localhost/replica:0/task:0/device:CPU:445, /job:localhost/replica:0/task:0/device:CPU:446, /job:localhost/replica:0/task:0/device:CPU:447, /job:localhost/replica:0/task:0/device:CPU:448, /job:localhost/replica:0/task:0/device:CPU:449, /job:localhost/replica:0/task:0/device:CPU:45, /job:localhost/replica:0/task:0/device:CPU:450, /job:localhost/replica:0/task:0/device:CPU:451, /job:localhost/replica:0/task:0/device:CPU:452, /job:localhost/replica:0/task:0/device:CPU:453, /job:localhost/replica:0/task:0/device:CPU:454, /job:localhost/replica:0/task:0/device:CPU:455, /job:localhost/replica:0/task:0/device:CPU:456, /job:localhost/replica:0/task:0/device:CPU:457, /job:localhost/replica:0/task:0/device:CPU:458, /job:localhost/replica:0/task:0/device:CPU:459, /job:localhost/replica:0/task:0/device:CPU:46, /job:localhost/replica:0/task:0/device:CPU:460, /job:localhost/replica:0/task:0/device:CPU:461, /job:localhost/replica:0/task:0/device:CPU:462, /job:localhost/replica:0/task:0/device:CPU:463, /job:localhost/replica:0/task:0/device:CPU:464, /job:localhost/replica:0/task:0/device:CPU:465, /job:localhost/replica:0/task:0/device:CPU:466, /job:localhost/replica:0/task:0/device:CPU:467, /job:localhost/replica:0/task:0/device:CPU:468, /job:localhost/replica:0/task:0/device:CPU:469, /job:localhost/replica:0/task:0/device:CPU:47, /job:localhost/replica:0/task:0/device:CPU:470, /job:localhost/replica:0/task:0/device:CPU:471, /job:localhost/replica:0/task:0/device:CPU:472, /job:localhost/replica:0/task:0/device:CPU:473, /job:localhost/replica:0/task:0/device:CPU:474, /job:localhost/replica:0/task:0/device:CPU:475, /job:localhost/replica:0/task:0/device:CPU:476, /job:localhost/replica:0/task:0/device:CPU:477, /job:localhost/replica:0/task:0/device:CPU:478, /job:localhost/replica:0/task:0/device:CPU:479, /job:localhost/replica:0/task:0/device:CPU:48, /job:localhost/replica:0/task:0/device:CPU:480, /job:localhost/replica:0/task:0/device:CPU:481, /job:localhost/replica:0/task:0/device:CPU:482, /job:localhost/replica:0/task:0/device:CPU:483, /job:localhost/replica:0/task:0/device:CPU:484, /job:localhost/replica:0/task:0/device:CPU:485, /job:localhost/replica:0/task:0/device:CPU:486, /job:localhost/replica:0/task:0/device:CPU:487, /job:localhost/replica:0/task:0/device:CPU:488, /job:localhost/replica:0/task:0/device:CPU:489, /job:localhost/replica:0/task:0/device:CPU:49, /job:localhost/replica:0/task:0/device:CPU:490, /job:localhost/replica:0/task:0/device:CPU:491, /job:localhost/replica:0/task:0/device:CPU:492, /job:localhost/replica:0/task:0/device:CPU:493, /job:localhost/replica:0/task:0/device:CPU:494, /job:localhost/replica:0/task:0/device:CPU:495, /job:localhost/replica:0/task:0/device:CPU:496, /job:localhost/replica:0/task:0/device:CPU:497, /job:localhost/replica:0/task:0/device:CPU:498, /job:localhost/replica:0/task:0/device:CPU:499, /job:localhost/replica:0/task:0/device:CPU:5, /job:localhost/replica:0/task:0/device:CPU:50, /job:localhost/replica:0/task:0/device:CPU:500, /job:localhost/replica:0/task:0/device:CPU:501, /job:localhost/replica:0/task:0/device:CPU:502, /job:localhost/replica:0/task:0/device:CPU:503, /job:localhost/replica:0/task:0/device:CPU:504, /job:localhost/replica:0/task:0/device:CPU:505, /job:localhost/replica:0/task:0/device:CPU:506, /job:localhost/replica:0/task:0/device:CPU:507, /job:localhost/replica:0/task:0/device:CPU:508, /job:localhost/replica:0/task:0/device:CPU:509, /job:localhost/replica:0/task:0/device:CPU:51, /job:localhost/replica:0/task:0/device:CPU:510, /job:localhost/replica:0/task:0/device:CPU:511, /job:localhost/replica:0/task:0/device:CPU:512, /job:localhost/replica:0/task:0/device:CPU:513, /job:localhost/replica:0/task:0/device:CPU:514, /job:localhost/replica:0/task:0/device:CPU:515, /job:localhost/replica:0/task:0/device:CPU:516, /job:localhost/replica:0/task:0/device:CPU:517, /job:localhost/replica:0/task:0/device:CPU:518, /job:localhost/replica:0/task:0/device:CPU:519, /job:localhost/replica:0/task:0/device:CPU:52, /job:localhost/replica:0/task:0/device:CPU:520, /job:localhost/replica:0/task:0/device:CPU:521, /job:localhost/replica:0/task:0/device:CPU:522, /job:localhost/replica:0/task:0/device:CPU:523, /job:localhost/replica:0/task:0/device:CPU:524, /job:localhost/replica:0/task:0/device:CPU:525, /job:localhost/replica:0/task:0/device:CPU:526, /job:localhost/replica:0/task:0/device:CPU:527, /job:localhost/replica:0/task:0/device:CPU:528, /job:localhost/replica:0/task:0/device:CPU:529, /job:localhost/replica:0/task:0/device:CPU:53, /job:localhost/replica:0/task:0/device:CPU:530, /job:localhost/replica:0/task:0/device:CPU:531, /job:localhost/replica:0/task:0/device:CPU:532, /job:localhost/replica:0/task:0/device:CPU:533, /job:localhost/replica:0/task:0/device:CPU:534, /job:localhost/replica:0/task:0/device:CPU:535, /job:localhost/replica:0/task:0/device:CPU:536, /job:localhost/replica:0/task:0/device:CPU:537, /job:localhost/replica:0/task:0/device:CPU:538, /job:localhost/replica:0/task:0/device:CPU:539, /job:localhost/replica:0/task:0/device:CPU:54, /job:localhost/replica:0/task:0/device:CPU:540, /job:localhost/replica:0/task:0/device:CPU:541, /job:localhost/replica:0/task:0/device:CPU:542, /job:localhost/replica:0/task:0/device:CPU:543, /job:localhost/replica:0/task:0/device:CPU:544, /job:localhost/replica:0/task:0/device:CPU:545, /job:localhost/replica:0/task:0/device:CPU:546, /job:localhost/replica:0/task:0/device:CPU:547, /job:localhost/replica:0/task:0/device:CPU:548, /job:localhost/replica:0/task:0/device:CPU:549, /job:localhost/replica:0/task:0/device:CPU:55, /job:localhost/replica:0/task:0/device:CPU:550, /job:localhost/replica:0/task:0/device:CPU:551, /job:localhost/replica:0/task:0/device:CPU:552, /job:localhost/replica:0/task:0/device:CPU:553, /job:localhost/replica:0/task:0/device:CPU:554, /job:localhost/replica:0/task:0/device:CPU:555, /job:localhost/replica:0/task:0/device:CPU:556, /job:localhost/replica:0/task:0/device:CPU:557, /job:localhost/replica:0/task:0/device:CPU:558, /job:localhost/replica:0/task:0/device:CPU:559, /job:localhost/replica:0/task:0/device:CPU:56, /job:localhost/replica:0/task:0/device:CPU:560, /job:localhost/replica:0/task:0/device:CPU:561, /job:localhost/replica:0/task:0/device:CPU:562, /job:localhost/replica:0/task:0/device:CPU:563, /job:localhost/replica:0/task:0/device:CPU:564, /job:localhost/replica:0/task:0/device:CPU:565, /job:localhost/replica:0/task:0/device:CPU:566, /job:localhost/replica:0/task:0/device:CPU:567, /job:localhost/replica:0/task:0/device:CPU:568, /job:localhost/replica:0/task:0/device:CPU:569, /job:localhost/replica:0/task:0/device:CPU:57, /job:localhost/replica:0/task:0/device:CPU:570, /job:localhost/replica:0/task:0/device:CPU:571, /job:localhost/replica:0/task:0/device:CPU:572, /job:localhost/replica:0/task:0/device:CPU:573, /job:localhost/replica:0/task:0/device:CPU:574, /job:localhost/replica:0/task:0/device:CPU:575, /job:localhost/replica:0/task:0/device:CPU:576, /job:localhost/replica:0/task:0/device:CPU:577, /job:localhost/replica:0/task:0/device:CPU:578, /job:localhost/replica:0/task:0/device:CPU:579, /job:localhost/replica:0/task:0/device:CPU:58, /job:localhost/replica:0/task:0/device:CPU:580, /job:localhost/replica:0/task:0/device:CPU:581, /job:localhost/replica:0/task:0/device:CPU:582, /job:localhost/replica:0/task:0/device:CPU:583, /job:localhost/replica:0/task:0/device:CPU:584, /job:localhost/replica:0/task:0/device:CPU:585, /job:localhost/replica:0/task:0/device:CPU:586, /job:localhost/replica:0/task:0/device:CPU:587, /job:localhost/replica:0/task:0/device:CPU:588, /job:localhost/replica:0/task:0/device:CPU:589, /job:localhost/replica:0/task:0/device:CPU:59, /job:localhost/replica:0/task:0/device:CPU:590, /job:localhost/replica:0/task:0/device:CPU:591, /job:localhost/replica:0/task:0/device:CPU:592, /job:localhost/replica:0/task:0/device:CPU:593, /job:localhost/replica:0/task:0/device:CPU:594, /job:localhost/replica:0/task:0/device:CPU:595, /job:localhost/replica:0/task:0/device:CPU:596, /job:localhost/replica:0/task:0/device:CPU:597, /job:localhost/replica:0/task:0/device:CPU:598, /job:localhost/replica:0/task:0/device:CPU:599, /job:localhost/replica:0/task:0/device:CPU:6, /job:localhost/replica:0/task:0/device:CPU:60, /job:localhost/replica:0/task:0/device:CPU:600, /job:localhost/replica:0/task:0/device:CPU:601, /job:localhost/replica:0/task:0/device:CPU:602, /job:localhost/replica:0/task:0/device:CPU:603, /job:localhost/replica:0/task:0/device:CPU:604, /job:localhost/replica:0/task:0/device:CPU:605, /job:localhost/replica:0/task:0/device:CPU:606, /job:localhost/replica:0/task:0/device:CPU:607, /job:localhost/replica:0/task:0/device:CPU:608, /job:localhost/replica:0/task:0/device:CPU:609, /job:localhost/replica:0/task:0/device:CPU:61, /job:localhost/replica:0/task:0/device:CPU:610, /job:localhost/replica:0/task:0/device:CPU:611, /job:localhost/replica:0/task:0/device:CPU:612, /job:localhost/replica:0/task:0/device:CPU:613, /job:localhost/replica:0/task:0/device:CPU:614, /job:localhost/replica:0/task:0/device:CPU:615, /job:localhost/replica:0/task:0/device:CPU:616, /job:localhost/replica:0/task:0/device:CPU:617, /job:localhost/replica:0/task:0/device:CPU:618, /job:localhost/replica:0/task:0/device:CPU:619, /job:localhost/replica:0/task:0/device:CPU:62, /job:localhost/replica:0/task:0/device:CPU:620, /job:localhost/replica:0/task:0/device:CPU:621, /job:localhost/replica:0/task:0/device:CPU:622, /job:localhost/replica:0/task:0/device:CPU:623, /job:localhost/replica:0/task:0/device:CPU:624, /job:localhost/replica:0/task:0/device:CPU:625, /job:localhost/replica:0/task:0/device:CPU:626, /job:localhost/replica:0/task:0/device:CPU:627, /job:localhost/replica:0/task:0/device:CPU:628, /job:localhost/replica:0/task:0/device:CPU:629, /job:localhost/replica:0/task:0/device:CPU:63, /job:localhost/replica:0/task:0/device:CPU:630, /job:localhost/replica:0/task:0/device:CPU:631, /job:localhost/replica:0/task:0/device:CPU:632, /job:localhost/replica:0/task:0/device:CPU:633, /job:localhost/replica:0/task:0/device:CPU:634, /job:localhost/replica:0/task:0/device:CPU:635, /job:localhost/replica:0/task:0/device:CPU:636, /job:localhost/replica:0/task:0/device:CPU:637, /job:localhost/replica:0/task:0/device:CPU:638, /job:localhost/replica:0/task:0/device:CPU:639, /job:localhost/replica:0/task:0/device:CPU:64, /job:localhost/replica:0/task:0/device:CPU:640, /job:localhost/replica:0/task:0/device:CPU:641, /job:localhost/replica:0/task:0/device:CPU:642, /job:localhost/replica:0/task:0/device:CPU:643, /job:localhost/replica:0/task:0/device:CPU:644, /job:localhost/replica:0/task:0/device:CPU:645, /job:localhost/replica:0/task:0/device:CPU:646, /job:localhost/replica:0/task:0/device:CPU:647, /job:localhost/replica:0/task:0/device:CPU:648, /job:localhost/replica:0/task:0/device:CPU:649, /job:localhost/replica:0/task:0/device:CPU:65, /job:localhost/replica:0/task:0/device:CPU:650, /job:localhost/replica:0/task:0/device:CPU:651, /job:localhost/replica:0/task:0/device:CPU:652, /job:localhost/replica:0/task:0/device:CPU:653, /job:localhost/replica:0/task:0/device:CPU:654, /job:localhost/replica:0/task:0/device:CPU:655, /job:localhost/replica:0/task:0/device:CPU:656, /job:localhost/replica:0/task:0/device:CPU:657, /job:localhost/replica:0/task:0/device:CPU:658, /job:localhost/replica:0/task:0/device:CPU:659, /job:localhost/replica:0/task:0/device:CPU:66, /job:localhost/replica:0/task:0/device:CPU:660, /job:localhost/replica:0/task:0/device:CPU:661, /job:localhost/replica:0/task:0/device:CPU:662, /job:localhost/replica:0/task:0/device:CPU:663, /job:localhost/replica:0/task:0/device:CPU:664, /job:localhost/replica:0/task:0/device:CPU:665, /job:localhost/replica:0/task:0/device:CPU:666, /job:localhost/replica:0/task:0/device:CPU:667, /job:localhost/replica:0/task:0/device:CPU:668, /job:localhost/replica:0/task:0/device:CPU:669, /job:localhost/replica:0/task:0/device:CPU:67, /job:localhost/replica:0/task:0/device:CPU:670, /job:localhost/replica:0/task:0/device:CPU:671, /job:localhost/replica:0/task:0/device:CPU:672, /job:localhost/replica:0/task:0/device:CPU:673, /job:localhost/replica:0/task:0/device:CPU:674, /job:localhost/replica:0/task:0/device:CPU:675, /job:localhost/replica:0/task:0/device:CPU:676, /job:localhost/replica:0/task:0/device:CPU:677, /job:localhost/replica:0/task:0/device:CPU:678, /job:localhost/replica:0/task:0/device:CPU:679, /job:localhost/replica:0/task:0/device:CPU:68, /job:localhost/replica:0/task:0/device:CPU:680, /job:localhost/replica:0/task:0/device:CPU:681, /job:localhost/replica:0/task:0/device:CPU:682, /job:localhost/replica:0/task:0/device:CPU:683, /job:localhost/replica:0/task:0/device:CPU:684, /job:localhost/replica:0/task:0/device:CPU:685, /job:localhost/replica:0/task:0/device:CPU:686, /job:localhost/replica:0/task:0/device:CPU:687, /job:localhost/replica:0/task:0/device:CPU:688, /job:localhost/replica:0/task:0/device:CPU:689, /job:localhost/replica:0/task:0/device:CPU:69, /job:localhost/replica:0/task:0/device:CPU:690, /job:localhost/replica:0/task:0/device:CPU:691, /job:localhost/replica:0/task:0/device:CPU:692, /job:localhost/replica:0/task:0/device:CPU:693, /job:localhost/replica:0/task:0/device:CPU:694, /job:localhost/replica:0/task:0/device:CPU:695, /job:localhost/replica:0/task:0/device:CPU:696, /job:localhost/replica:0/task:0/device:CPU:697, /job:localhost/replica:0/task:0/device:CPU:698, /job:localhost/replica:0/task:0/device:CPU:699, /job:localhost/replica:0/task:0/device:CPU:7, /job:localhost/replica:0/task:0/device:CPU:70, /job:localhost/replica:0/task:0/device:CPU:700, /job:localhost/replica:0/task:0/device:CPU:701, /job:localhost/replica:0/task:0/device:CPU:702, /job:localhost/replica:0/task:0/device:CPU:703, /job:localhost/replica:0/task:0/device:CPU:704, /job:localhost/replica:0/task:0/device:CPU:705, /job:localhost/replica:0/task:0/device:CPU:706, /job:localhost/replica:0/task:0/device:CPU:707, /job:localhost/replica:0/task:0/device:CPU:708, /job:localhost/replica:0/task:0/device:CPU:709, /job:localhost/replica:0/task:0/device:CPU:71, /job:localhost/replica:0/task:0/device:CPU:710, /job:localhost/replica:0/task:0/device:CPU:711, /job:localhost/replica:0/task:0/device:CPU:712, /job:localhost/replica:0/task:0/device:CPU:713, /job:localhost/replica:0/task:0/device:CPU:714, /job:localhost/replica:0/task:0/device:CPU:715, /job:localhost/replica:0/task:0/device:CPU:716, /job:localhost/replica:0/task:0/device:CPU:717, /job:localhost/replica:0/task:0/device:CPU:718, /job:localhost/replica:0/task:0/device:CPU:719, /job:localhost/replica:0/task:0/device:CPU:72, /job:localhost/replica:0/task:0/device:CPU:720, /job:localhost/replica:0/task:0/device:CPU:721, /job:localhost/replica:0/task:0/device:CPU:722, /job:localhost/replica:0/task:0/device:CPU:723, /job:localhost/replica:0/task:0/device:CPU:724, /job:localhost/replica:0/task:0/device:CPU:725, /job:localhost/replica:0/task:0/device:CPU:726, /job:localhost/replica:0/task:0/device:CPU:727, /job:localhost/replica:0/task:0/device:CPU:728, /job:localhost/replica:0/task:0/device:CPU:729, /job:localhost/replica:0/task:0/device:CPU:73, /job:localhost/replica:0/task:0/device:CPU:730, /job:localhost/replica:0/task:0/device:CPU:731, /job:localhost/replica:0/task:0/device:CPU:732, /job:localhost/replica:0/task:0/device:CPU:733, /job:localhost/replica:0/task:0/device:CPU:734, /job:localhost/replica:0/task:0/device:CPU:735, /job:localhost/replica:0/task:0/device:CPU:736, /job:localhost/replica:0/task:0/device:CPU:737, /job:localhost/replica:0/task:0/device:CPU:738, /job:localhost/replica:0/task:0/device:CPU:739, /job:localhost/replica:0/task:0/device:CPU:74, /job:localhost/replica:0/task:0/device:CPU:740, /job:localhost/replica:0/task:0/device:CPU:741, /job:localhost/replica:0/task:0/device:CPU:742, /job:localhost/replica:0/task:0/device:CPU:743, /job:localhost/replica:0/task:0/device:CPU:744, /job:localhost/replica:0/task:0/device:CPU:745, /job:localhost/replica:0/task:0/device:CPU:746, /job:localhost/replica:0/task:0/device:CPU:747, /job:localhost/replica:0/task:0/device:CPU:748, /job:localhost/replica:0/task:0/device:CPU:749, /job:localhost/replica:0/task:0/device:CPU:75, /job:localhost/replica:0/task:0/device:CPU:750, /job:localhost/replica:0/task:0/device:CPU:751, /job:localhost/replica:0/task:0/device:CPU:752, /job:localhost/replica:0/task:0/device:CPU:753, /job:localhost/replica:0/task:0/device:CPU:754, /job:localhost/replica:0/task:0/device:CPU:755, /job:localhost/replica:0/task:0/device:CPU:756, /job:localhost/replica:0/task:0/device:CPU:757, /job:localhost/replica:0/task:0/device:CPU:758, /job:localhost/replica:0/task:0/device:CPU:759, /job:localhost/replica:0/task:0/device:CPU:76, /job:localhost/replica:0/task:0/device:CPU:760, /job:localhost/replica:0/task:0/device:CPU:761, /job:localhost/replica:0/task:0/device:CPU:762, /job:localhost/replica:0/task:0/device:CPU:763, /job:localhost/replica:0/task:0/device:CPU:764, /job:localhost/replica:0/task:0/device:CPU:765, /job:localhost/replica:0/task:0/device:CPU:766, /job:localhost/replica:0/task:0/device:CPU:767, /job:localhost/replica:0/task:0/device:CPU:768, /job:localhost/replica:0/task:0/device:CPU:769, /job:localhost/replica:0/task:0/device:CPU:77, /job:localhost/replica:0/task:0/device:CPU:770, /job:localhost/replica:0/task:0/device:CPU:771, /job:localhost/replica:0/task:0/device:CPU:772, /job:localhost/replica:0/task:0/device:CPU:773, /job:localhost/replica:0/task:0/device:CPU:774, /job:localhost/replica:0/task:0/device:CPU:775, /job:localhost/replica:0/task:0/device:CPU:776, /job:localhost/replica:0/task:0/device:CPU:777, /job:localhost/replica:0/task:0/device:CPU:778, /job:localhost/replica:0/task:0/device:CPU:779, /job:localhost/replica:0/task:0/device:CPU:78, /job:localhost/replica:0/task:0/device:CPU:780, /job:localhost/replica:0/task:0/device:CPU:781, /job:localhost/replica:0/task:0/device:CPU:782, /job:localhost/replica:0/task:0/device:CPU:783, /job:localhost/replica:0/task:0/device:CPU:784, /job:localhost/replica:0/task:0/device:CPU:785, /job:localhost/replica:0/task:0/device:CPU:786, /job:localhost/replica:0/task:0/device:CPU:787, /job:localhost/replica:0/task:0/device:CPU:788, /job:localhost/replica:0/task:0/device:CPU:789, /job:localhost/replica:0/task:0/device:CPU:79, /job:localhost/replica:0/task:0/device:CPU:790, /job:localhost/replica:0/task:0/device:CPU:791, /job:localhost/replica:0/task:0/device:CPU:792, /job:localhost/replica:0/task:0/device:CPU:793, /job:localhost/replica:0/task:0/device:CPU:794, /job:localhost/replica:0/task:0/device:CPU:795, /job:localhost/replica:0/task:0/device:CPU:796, /job:localhost/replica:0/task:0/device:CPU:797, /job:localhost/replica:0/task:0/device:CPU:798, /job:localhost/replica:0/task:0/device:CPU:799, /job:localhost/replica:0/task:0/device:CPU:8, /job:localhost/replica:0/task:0/device:CPU:80, /job:localhost/replica:0/task:0/device:CPU:800, /job:localhost/replica:0/task:0/device:CPU:801, /job:localhost/replica:0/task:0/device:CPU:802, /job:localhost/replica:0/task:0/device:CPU:803, /job:localhost/replica:0/task:0/device:CPU:804, /job:localhost/replica:0/task:0/device:CPU:805, /job:localhost/replica:0/task:0/device:CPU:806, /job:localhost/replica:0/task:0/device:CPU:807, /job:localhost/replica:0/task:0/device:CPU:808, /job:localhost/replica:0/task:0/device:CPU:809, /job:localhost/replica:0/task:0/device:CPU:81, /job:localhost/replica:0/task:0/device:CPU:810, /job:localhost/replica:0/task:0/device:CPU:811, /job:localhost/replica:0/task:0/device:CPU:812, /job:localhost/replica:0/task:0/device:CPU:813, /job:localhost/replica:0/task:0/device:CPU:814, /job:localhost/replica:0/task:0/device:CPU:815, /job:localhost/replica:0/task:0/device:CPU:816, /job:localhost/replica:0/task:0/device:CPU:817, /job:localhost/replica:0/task:0/device:CPU:818, /job:localhost/replica:0/task:0/device:CPU:819, /job:localhost/replica:0/task:0/device:CPU:82, /job:localhost/replica:0/task:0/device:CPU:820, /job:localhost/replica:0/task:0/device:CPU:821, /job:localhost/replica:0/task:0/device:CPU:822, /job:localhost/replica:0/task:0/device:CPU:823, /job:localhost/replica:0/task:0/device:CPU:824, /job:localhost/replica:0/task:0/device:CPU:825, /job:localhost/replica:0/task:0/device:CPU:826, /job:localhost/replica:0/task:0/device:CPU:827, /job:localhost/replica:0/task:0/device:CPU:828, /job:localhost/replica:0/task:0/device:CPU:829, /job:localhost/replica:0/task:0/device:CPU:83, /job:localhost/replica:0/task:0/device:CPU:830, /job:localhost/replica:0/task:0/device:CPU:831, /job:localhost/replica:0/task:0/device:CPU:832, /job:localhost/replica:0/task:0/device:CPU:833, /job:localhost/replica:0/task:0/device:CPU:834, /job:localhost/replica:0/task:0/device:CPU:835, /job:localhost/replica:0/task:0/device:CPU:836, /job:localhost/replica:0/task:0/device:CPU:837, /job:localhost/replica:0/task:0/device:CPU:838, /job:localhost/replica:0/task:0/device:CPU:839, /job:localhost/replica:0/task:0/device:CPU:84, /job:localhost/replica:0/task:0/device:CPU:840, /job:localhost/replica:0/task:0/device:CPU:841, /job:localhost/replica:0/task:0/device:CPU:842, /job:localhost/replica:0/task:0/device:CPU:843, /job:localhost/replica:0/task:0/device:CPU:844, /job:localhost/replica:0/task:0/device:CPU:845, /job:localhost/replica:0/task:0/device:CPU:846, /job:localhost/replica:0/task:0/device:CPU:847, /job:localhost/replica:0/task:0/device:CPU:848, /job:localhost/replica:0/task:0/device:CPU:849, /job:localhost/replica:0/task:0/device:CPU:85, /job:localhost/replica:0/task:0/device:CPU:850, /job:localhost/replica:0/task:0/device:CPU:851, /job:localhost/replica:0/task:0/device:CPU:852, /job:localhost/replica:0/task:0/device:CPU:853, /job:localhost/replica:0/task:0/device:CPU:854, /job:localhost/replica:0/task:0/device:CPU:855, /job:localhost/replica:0/task:0/device:CPU:856, /job:localhost/replica:0/task:0/device:CPU:857, /job:localhost/replica:0/task:0/device:CPU:858, /job:localhost/replica:0/task:0/device:CPU:859, /job:localhost/replica:0/task:0/device:CPU:86, /job:localhost/replica:0/task:0/device:CPU:860, /job:localhost/replica:0/task:0/device:CPU:861, /job:localhost/replica:0/task:0/device:CPU:862, /job:localhost/replica:0/task:0/device:CPU:863, /job:localhost/replica:0/task:0/device:CPU:864, /job:localhost/replica:0/task:0/device:CPU:865, /job:localhost/replica:0/task:0/device:CPU:866, /job:localhost/replica:0/task:0/device:CPU:867, /job:localhost/replica:0/task:0/device:CPU:868, /job:localhost/replica:0/task:0/device:CPU:869, /job:localhost/replica:0/task:0/device:CPU:87, /job:localhost/replica:0/task:0/device:CPU:870, /job:localhost/replica:0/task:0/device:CPU:871, /job:localhost/replica:0/task:0/device:CPU:872, /job:localhost/replica:0/task:0/device:CPU:873, /job:localhost/replica:0/task:0/device:CPU:874, /job:localhost/replica:0/task:0/device:CPU:875, /job:localhost/replica:0/task:0/device:CPU:876, /job:localhost/replica:0/task:0/device:CPU:877, /job:localhost/replica:0/task:0/device:CPU:878, /job:localhost/replica:0/task:0/device:CPU:879, /job:localhost/replica:0/task:0/device:CPU:88, /job:localhost/replica:0/task:0/device:CPU:880, /job:localhost/replica:0/task:0/device:CPU:881, /job:localhost/replica:0/task:0/device:CPU:882, /job:localhost/replica:0/task:0/device:CPU:883, /job:localhost/replica:0/task:0/device:CPU:884, /job:localhost/replica:0/task:0/device:CPU:885, /job:localhost/replica:0/task:0/device:CPU:886, /job:localhost/replica:0/task:0/device:CPU:887, /job:localhost/replica:0/task:0/device:CPU:888, /job:localhost/replica:0/task:0/device:CPU:889, /job:localhost/replica:0/task:0/device:CPU:89, /job:localhost/replica:0/task:0/device:CPU:890, /job:localhost/replica:0/task:0/device:CPU:891, /job:localhost/replica:0/task:0/device:CPU:892, /job:localhost/replica:0/task:0/device:CPU:893, /job:localhost/replica:0/task:0/device:CPU:894, /job:localhost/replica:0/task:0/device:CPU:895, /job:localhost/replica:0/task:0/device:CPU:896, /job:localhost/replica:0/task:0/device:CPU:897, /job:localhost/replica:0/task:0/device:CPU:898, /job:localhost/replica:0/task:0/device:CPU:899, /job:localhost/replica:0/task:0/device:CPU:9, /job:localhost/replica:0/task:0/device:CPU:90, /job:localhost/replica:0/task:0/device:CPU:900, /job:localhost/replica:0/task:0/device:CPU:901, /job:localhost/replica:0/task:0/device:CPU:902, /job:localhost/replica:0/task:0/device:CPU:903, /job:localhost/replica:0/task:0/device:CPU:904, /job:localhost/replica:0/task:0/device:CPU:905, /job:localhost/replica:0/task:0/device:CPU:906, /job:localhost/replica:0/task:0/device:CPU:907, /job:localhost/replica:0/task:0/device:CPU:908, /job:localhost/replica:0/task:0/device:CPU:909, /job:localhost/replica:0/task:0/device:CPU:91, /job:localhost/replica:0/task:0/device:CPU:910, /job:localhost/replica:0/task:0/device:CPU:911, /job:localhost/replica:0/task:0/device:CPU:912, /job:localhost/replica:0/task:0/device:CPU:913, /job:localhost/replica:0/task:0/device:CPU:914, /job:localhost/replica:0/task:0/device:CPU:915, /job:localhost/replica:0/task:0/device:CPU:916, /job:localhost/replica:0/task:0/device:CPU:917, /job:localhost/replica:0/task:0/device:CPU:918, /job:localhost/replica:0/task:0/device:CPU:919, /job:localhost/replica:0/task:0/device:CPU:92, /job:localhost/replica:0/task:0/device:CPU:920, /job:localhost/replica:0/task:0/device:CPU:921, /job:localhost/replica:0/task:0/device:CPU:922, /job:localhost/replica:0/task:0/device:CPU:923, /job:localhost/replica:0/task:0/device:CPU:924, /job:localhost/replica:0/task:0/device:CPU:925, /job:localhost/replica:0/task:0/device:CPU:926, /job:localhost/replica:0/task:0/device:CPU:927, /job:localhost/replica:0/task:0/device:CPU:928, /job:localhost/replica:0/task:0/device:CPU:929, /job:localhost/replica:0/task:0/device:CPU:93, /job:localhost/replica:0/task:0/device:CPU:930, /job:localhost/replica:0/task:0/device:CPU:931, /job:localhost/replica:0/task:0/device:CPU:932, /job:localhost/replica:0/task:0/device:CPU:933, /job:localhost/replica:0/task:0/device:CPU:934, /job:localhost/replica:0/task:0/device:CPU:935, /job:localhost/replica:0/task:0/device:CPU:936, /job:localhost/replica:0/task:0/device:CPU:937, /job:localhost/replica:0/task:0/device:CPU:938, /job:localhost/replica:0/task:0/device:CPU:939, /job:localhost/replica:0/task:0/device:CPU:94, /job:localhost/replica:0/task:0/device:CPU:940, /job:localhost/replica:0/task:0/device:CPU:941, /job:localhost/replica:0/task:0/device:CPU:942, /job:localhost/replica:0/task:0/device:CPU:943, /job:localhost/replica:0/task:0/device:CPU:944, /job:localhost/replica:0/task:0/device:CPU:945, /job:localhost/replica:0/task:0/device:CPU:946, /job:localhost/replica:0/task:0/device:CPU:947, /job:localhost/replica:0/task:0/device:CPU:948, /job:localhost/replica:0/task:0/device:CPU:949, /job:localhost/replica:0/task:0/device:CPU:95, /job:localhost/replica:0/task:0/device:CPU:950, /job:localhost/replica:0/task:0/device:CPU:951, /job:localhost/replica:0/task:0/device:CPU:952, /job:localhost/replica:0/task:0/device:CPU:953, /job:localhost/replica:0/task:0/device:CPU:954, /job:localhost/replica:0/task:0/device:CPU:955, /job:localhost/replica:0/task:0/device:CPU:956, /job:localhost/replica:0/task:0/device:CPU:957, /job:localhost/replica:0/task:0/device:CPU:958, /job:localhost/replica:0/task:0/device:CPU:959, /job:localhost/replica:0/task:0/device:CPU:96, /job:localhost/replica:0/task:0/device:CPU:960, /job:localhost/replica:0/task:0/device:CPU:961, /job:localhost/replica:0/task:0/device:CPU:962, /job:localhost/replica:0/task:0/device:CPU:963, /job:localhost/replica:0/task:0/device:CPU:964, /job:localhost/replica:0/task:0/device:CPU:965, /job:localhost/replica:0/task:0/device:CPU:966, /job:localhost/replica:0/task:0/device:CPU:967, /job:localhost/replica:0/task:0/device:CPU:968, /job:localhost/replica:0/task:0/device:CPU:969, /job:localhost/replica:0/task:0/device:CPU:97, /job:localhost/replica:0/task:0/device:CPU:970, /job:localhost/replica:0/task:0/device:CPU:971, /job:localhost/replica:0/task:0/device:CPU:972, /job:localhost/replica:0/task:0/device:CPU:973, /job:localhost/replica:0/task:0/device:CPU:974, /job:localhost/replica:0/task:0/device:CPU:975, /job:localhost/replica:0/task:0/device:CPU:976, /job:localhost/replica:0/task:0/device:CPU:977, /job:localhost/replica:0/task:0/device:CPU:978, /job:localhost/replica:0/task:0/device:CPU:979, /job:localhost/replica:0/task:0/device:CPU:98, /job:localhost/replica:0/task:0/device:CPU:980, /job:localhost/replica:0/task:0/device:CPU:981, /job:localhost/replica:0/task:0/device:CPU:982, /job:localhost/replica:0/task:0/device:CPU:983, /job:localhost/replica:0/task:0/device:CPU:984, /job:localhost/replica:0/task:0/device:CPU:985, /job:localhost/replica:0/task:0/device:CPU:986, /job:localhost/replica:0/task:0/device:CPU:987, /job:localhost/replica:0/task:0/device:CPU:988, /job:localhost/replica:0/task:0/device:CPU:989, /job:localhost/replica:0/task:0/device:CPU:99, /job:localhost/replica:0/task:0/device:CPU:990, /job:localhost/replica:0/task:0/device:CPU:991, /job:localhost/replica:0/task:0/device:CPU:992, /job:localhost/replica:0/task:0/device:CPU:993, /job:localhost/replica:0/task:0/device:CPU:994, /job:localhost/replica:0/task:0/device:CPU:995, /job:localhost/replica:0/task:0/device:CPU:996, /job:localhost/replica:0/task:0/device:CPU:997, /job:localhost/replica:0/task:0/device:CPU:998, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
	 [[net/b]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/homes/kovacs/anaconda3/envs/deep_medic_dgk1/bin/deepMedicRun", line 178, in <module>
    session.run_session(sess_device, model_params, args.reset_trainer)
  File "/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/deepmedic/frontEnd/trainSession.py", line 198, in run_session
    tf.compat.v1.variables_initializer(var_list=coll_vars_net).run()
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2679, in run
    _run_using_default_session(self, feed_dict, self.graph, session)
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 5614, in _run_using_default_session
    session.run(operation, feed_dict)
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 950, in run
    run_metadata_ptr)
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1350, in _do_run
    run_metadata)
  File "/homes/kovacs/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation net/b: node net/b (defined at /project_scripts/hnc_segmentation/deep_medic/deepmedic/deepmedic/neuralnet/layers.py:254) was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:CPU:1, /job:localhost/replica:0/task:0/device:CPU:10, /job:localhost/replica:0/task:0/device:CPU:100, /job:localhost/replica:0/task:0/device:CPU:101, /job:localhost/replica:0/task:0/device:CPU:102, /job:localhost/replica:0/task:0/device:CPU:103, /job:localhost/replica:0/task:0/device:CPU:104, /job:localhost/replica:0/task:0/device:CPU:105, /job:localhost/replica:0/task:0/device:CPU:106, /job:localhost/replica:0/task:0/device:CPU:107, /job:localhost/replica:0/task:0/device:CPU:108, /job:localhost/replica:0/task:0/device:CPU:109, /job:localhost/replica:0/task:0/device:CPU:11, /job:localhost/replica:0/task:0/device:CPU:110, /job:localhost/replica:0/task:0/device:CPU:111, /job:localhost/replica:0/task:0/device:CPU:112, /job:localhost/replica:0/task:0/device:CPU:113, /job:localhost/replica:0/task:0/device:CPU:114, /job:localhost/replica:0/task:0/device:CPU:115, /job:localhost/replica:0/task:0/device:CPU:116, /job:localhost/replica:0/task:0/device:CPU:117, /job:localhost/replica:0/task:0/device:CPU:118, /job:localhost/replica:0/task:0/device:CPU:119, /job:localhost/replica:0/task:0/device:CPU:12, /job:localhost/replica:0/task:0/device:CPU:120, /job:localhost/replica:0/task:0/device:CPU:121, /job:localhost/replica:0/task:0/device:CPU:122, /job:localhost/replica:0/task:0/device:CPU:123, /job:localhost/replica:0/task:0/device:CPU:124, /job:localhost/replica:0/task:0/device:CPU:125, /job:localhost/replica:0/task:0/device:CPU:126, /job:localhost/replica:0/task:0/device:CPU:127, /job:localhost/replica:0/task:0/device:CPU:128, /job:localhost/replica:0/task:0/device:CPU:129, /job:localhost/replica:0/task:0/device:CPU:13, /job:localhost/replica:0/task:0/device:CPU:130, /job:localhost/replica:0/task:0/device:CPU:131, /job:localhost/replica:0/task:0/device:CPU:132, /job:localhost/replica:0/task:0/device:CPU:133, /job:localhost/replica:0/task:0/device:CPU:134, /job:localhost/replica:0/task:0/device:CPU:135, /job:localhost/replica:0/task:0/device:CPU:136, /job:localhost/replica:0/task:0/device:CPU:137, /job:localhost/replica:0/task:0/device:CPU:138, /job:localhost/replica:0/task:0/device:CPU:139, /job:localhost/replica:0/task:0/device:CPU:14, /job:localhost/replica:0/task:0/device:CPU:140, /job:localhost/replica:0/task:0/device:CPU:141, /job:localhost/replica:0/task:0/device:CPU:142, /job:localhost/replica:0/task:0/device:CPU:143, /job:localhost/replica:0/task:0/device:CPU:144, /job:localhost/replica:0/task:0/device:CPU:145, /job:localhost/replica:0/task:0/device:CPU:146, /job:localhost/replica:0/task:0/device:CPU:147, /job:localhost/replica:0/task:0/device:CPU:148, /job:localhost/replica:0/task:0/device:CPU:149, /job:localhost/replica:0/task:0/device:CPU:15, /job:localhost/replica:0/task:0/device:CPU:150, /job:localhost/replica:0/task:0/device:CPU:151, /job:localhost/replica:0/task:0/device:CPU:152, /job:localhost/replica:0/task:0/device:CPU:153, /job:localhost/replica:0/task:0/device:CPU:154, /job:localhost/replica:0/task:0/device:CPU:155, /job:localhost/replica:0/task:0/device:CPU:156, /job:localhost/replica:0/task:0/device:CPU:157, /job:localhost/replica:0/task:0/device:CPU:158, /job:localhost/replica:0/task:0/device:CPU:159, /job:localhost/replica:0/task:0/device:CPU:16, /job:localhost/replica:0/task:0/device:CPU:160, /job:localhost/replica:0/task:0/device:CPU:161, /job:localhost/replica:0/task:0/device:CPU:162, /job:localhost/replica:0/task:0/device:CPU:163, /job:localhost/replica:0/task:0/device:CPU:164, /job:localhost/replica:0/task:0/device:CPU:165, /job:localhost/replica:0/task:0/device:CPU:166, /job:localhost/replica:0/task:0/device:CPU:167, /job:localhost/replica:0/task:0/device:CPU:168, /job:localhost/replica:0/task:0/device:CPU:169, /job:localhost/replica:0/task:0/device:CPU:17, /job:localhost/replica:0/task:0/device:CPU:170, /job:localhost/replica:0/task:0/device:CPU:171, /job:localhost/replica:0/task:0/device:CPU:172, /job:localhost/replica:0/task:0/device:CPU:173, /job:localhost/replica:0/task:0/device:CPU:174, /job:localhost/replica:0/task:0/device:CPU:175, /job:localhost/replica:0/task:0/device:CPU:176, /job:localhost/replica:0/task:0/device:CPU:177, /job:localhost/replica:0/task:0/device:CPU:178, /job:localhost/replica:0/task:0/device:CPU:179, /job:localhost/replica:0/task:0/device:CPU:18, /job:localhost/replica:0/task:0/device:CPU:180, /job:localhost/replica:0/task:0/device:CPU:181, /job:localhost/replica:0/task:0/device:CPU:182, /job:localhost/replica:0/task:0/device:CPU:183, /job:localhost/replica:0/task:0/device:CPU:184, /job:localhost/replica:0/task:0/device:CPU:185, /job:localhost/replica:0/task:0/device:CPU:186, /job:localhost/replica:0/task:0/device:CPU:187, /job:localhost/replica:0/task:0/device:CPU:188, /job:localhost/replica:0/task:0/device:CPU:189, /job:localhost/replica:0/task:0/device:CPU:19, /job:localhost/replica:0/task:0/device:CPU:190, /job:localhost/replica:0/task:0/device:CPU:191, /job:localhost/replica:0/task:0/device:CPU:192, /job:localhost/replica:0/task:0/device:CPU:193, /job:localhost/replica:0/task:0/device:CPU:194, /job:localhost/replica:0/task:0/device:CPU:195, /job:localhost/replica:0/task:0/device:CPU:196, /job:localhost/replica:0/task:0/device:CPU:197, /job:localhost/replica:0/task:0/device:CPU:198, /job:localhost/replica:0/task:0/device:CPU:199, /job:localhost/replica:0/task:0/device:CPU:2, /job:localhost/replica:0/task:0/device:CPU:20, /job:localhost/replica:0/task:0/device:CPU:200, /job:localhost/replica:0/task:0/device:CPU:201, /job:localhost/replica:0/task:0/device:CPU:202, /job:localhost/replica:0/task:0/device:CPU:203, /job:localhost/replica:0/task:0/device:CPU:204, /job:localhost/replica:0/task:0/device:CPU:205, /job:localhost/replica:0/task:0/device:CPU:206, /job:localhost/replica:0/task:0/device:CPU:207, /job:localhost/replica:0/task:0/device:CPU:208, /job:localhost/replica:0/task:0/device:CPU:209, /job:localhost/replica:0/task:0/device:CPU:21, /job:localhost/replica:0/task:0/device:CPU:210, /job:localhost/replica:0/task:0/device:CPU:211, /job:localhost/replica:0/task:0/device:CPU:212, /job:localhost/replica:0/task:0/device:CPU:213, /job:localhost/replica:0/task:0/device:CPU:214, /job:localhost/replica:0/task:0/device:CPU:215, /job:localhost/replica:0/task:0/device:CPU:216, /job:localhost/replica:0/task:0/device:CPU:217, /job:localhost/replica:0/task:0/device:CPU:218, /job:localhost/replica:0/task:0/device:CPU:219, /job:localhost/replica:0/task:0/device:CPU:22, /job:localhost/replica:0/task:0/device:CPU:220, /job:localhost/replica:0/task:0/device:CPU:221, /job:localhost/replica:0/task:0/device:CPU:222, /job:localhost/replica:0/task:0/device:CPU:223, /job:localhost/replica:0/task:0/device:CPU:224, /job:localhost/replica:0/task:0/device:CPU:225, /job:localhost/replica:0/task:0/device:CPU:226, /job:localhost/replica:0/task:0/device:CPU:227, /job:localhost/replica:0/task:0/device:CPU:228, /job:localhost/replica:0/task:0/device:CPU:229, /job:localhost/replica:0/task:0/device:CPU:23, /job:localhost/replica:0/task:0/device:CPU:230, /job:localhost/replica:0/task:0/device:CPU:231, /job:localhost/replica:0/task:0/device:CPU:232, /job:localhost/replica:0/task:0/device:CPU:233, /job:localhost/replica:0/task:0/device:CPU:234, /job:localhost/replica:0/task:0/device:CPU:235, /job:localhost/replica:0/task:0/device:CPU:236, /job:localhost/replica:0/task:0/device:CPU:237, /job:localhost/replica:0/task:0/device:CPU:238, /job:localhost/replica:0/task:0/device:CPU:239, /job:localhost/replica:0/task:0/device:CPU:24, /job:localhost/replica:0/task:0/device:CPU:240, /job:localhost/replica:0/task:0/device:CPU:241, /job:localhost/replica:0/task:0/device:CPU:242, /job:localhost/replica:0/task:0/device:CPU:243, /job:localhost/replica:0/task:0/device:CPU:244, /job:localhost/replica:0/task:0/device:CPU:245, /job:localhost/replica:0/task:0/device:CPU:246, /job:localhost/replica:0/task:0/device:CPU:247, /job:localhost/replica:0/task:0/device:CPU:248, /job:localhost/replica:0/task:0/device:CPU:249, /job:localhost/replica:0/task:0/device:CPU:25, /job:localhost/replica:0/task:0/device:CPU:250, /job:localhost/replica:0/task:0/device:CPU:251, /job:localhost/replica:0/task:0/device:CPU:252, /job:localhost/replica:0/task:0/device:CPU:253, /job:localhost/replica:0/task:0/device:CPU:254, /job:localhost/replica:0/task:0/device:CPU:255, /job:localhost/replica:0/task:0/device:CPU:256, /job:localhost/replica:0/task:0/device:CPU:257, /job:localhost/replica:0/task:0/device:CPU:258, /job:localhost/replica:0/task:0/device:CPU:259, /job:localhost/replica:0/task:0/device:CPU:26, /job:localhost/replica:0/task:0/device:CPU:260, /job:localhost/replica:0/task:0/device:CPU:261, /job:localhost/replica:0/task:0/device:CPU:262, /job:localhost/replica:0/task:0/device:CPU:263, /job:localhost/replica:0/task:0/device:CPU:264, /job:localhost/replica:0/task:0/device:CPU:265, /job:localhost/replica:0/task:0/device:CPU:266, /job:localhost/replica:0/task:0/device:CPU:267, /job:localhost/replica:0/task:0/device:CPU:268, /job:localhost/replica:0/task:0/device:CPU:269, /job:localhost/replica:0/task:0/device:CPU:27, /job:localhost/replica:0/task:0/device:CPU:270, /job:localhost/replica:0/task:0/device:CPU:271, /job:localhost/replica:0/task:0/device:CPU:272, /job:localhost/replica:0/task:0/device:CPU:273, /job:localhost/replica:0/task:0/device:CPU:274, /job:localhost/replica:0/task:0/device:CPU:275, /job:localhost/replica:0/task:0/device:CPU:276, /job:localhost/replica:0/task:0/device:CPU:277, /job:localhost/replica:0/task:0/device:CPU:278, /job:localhost/replica:0/task:0/device:CPU:279, /job:localhost/replica:0/task:0/device:CPU:28, /job:localhost/replica:0/task:0/device:CPU:280, /job:localhost/replica:0/task:0/device:CPU:281, /job:localhost/replica:0/task:0/device:CPU:282, /job:localhost/replica:0/task:0/device:CPU:283, /job:localhost/replica:0/task:0/device:CPU:284, /job:localhost/replica:0/task:0/device:CPU:285, /job:localhost/replica:0/task:0/device:CPU:286, /job:localhost/replica:0/task:0/device:CPU:287, /job:localhost/replica:0/task:0/device:CPU:288, /job:localhost/replica:0/task:0/device:CPU:289, /job:localhost/replica:0/task:0/device:CPU:29, /job:localhost/replica:0/task:0/device:CPU:290, /job:localhost/replica:0/task:0/device:CPU:291, /job:localhost/replica:0/task:0/device:CPU:292, /job:localhost/replica:0/task:0/device:CPU:293, /job:localhost/replica:0/task:0/device:CPU:294, /job:localhost/replica:0/task:0/device:CPU:295, /job:localhost/replica:0/task:0/device:CPU:296, /job:localhost/replica:0/task:0/device:CPU:297, /job:localhost/replica:0/task:0/device:CPU:298, /job:localhost/replica:0/task:0/device:CPU:299, /job:localhost/replica:0/task:0/device:CPU:3, /job:localhost/replica:0/task:0/device:CPU:30, /job:localhost/replica:0/task:0/device:CPU:300, /job:localhost/replica:0/task:0/device:CPU:301, /job:localhost/replica:0/task:0/device:CPU:302, /job:localhost/replica:0/task:0/device:CPU:303, /job:localhost/replica:0/task:0/device:CPU:304, /job:localhost/replica:0/task:0/device:CPU:305, /job:localhost/replica:0/task:0/device:CPU:306, /job:localhost/replica:0/task:0/device:CPU:307, /job:localhost/replica:0/task:0/device:CPU:308, /job:localhost/replica:0/task:0/device:CPU:309, /job:localhost/replica:0/task:0/device:CPU:31, /job:localhost/replica:0/task:0/device:CPU:310, /job:localhost/replica:0/task:0/device:CPU:311, /job:localhost/replica:0/task:0/device:CPU:312, /job:localhost/replica:0/task:0/device:CPU:313, /job:localhost/replica:0/task:0/device:CPU:314, /job:localhost/replica:0/task:0/device:CPU:315, /job:localhost/replica:0/task:0/device:CPU:316, /job:localhost/replica:0/task:0/device:CPU:317, /job:localhost/replica:0/task:0/device:CPU:318, /job:localhost/replica:0/task:0/device:CPU:319, /job:localhost/replica:0/task:0/device:CPU:32, /job:localhost/replica:0/task:0/device:CPU:320, /job:localhost/replica:0/task:0/device:CPU:321, /job:localhost/replica:0/task:0/device:CPU:322, /job:localhost/replica:0/task:0/device:CPU:323, /job:localhost/replica:0/task:0/device:CPU:324, /job:localhost/replica:0/task:0/device:CPU:325, /job:localhost/replica:0/task:0/device:CPU:326, /job:localhost/replica:0/task:0/device:CPU:327, /job:localhost/replica:0/task:0/device:CPU:328, /job:localhost/replica:0/task:0/device:CPU:329, /job:localhost/replica:0/task:0/device:CPU:33, /job:localhost/replica:0/task:0/device:CPU:330, /job:localhost/replica:0/task:0/device:CPU:331, /job:localhost/replica:0/task:0/device:CPU:332, /job:localhost/replica:0/task:0/device:CPU:333, /job:localhost/replica:0/task:0/device:CPU:334, /job:localhost/replica:0/task:0/device:CPU:335, /job:localhost/replica:0/task:0/device:CPU:336, /job:localhost/replica:0/task:0/device:CPU:337, /job:localhost/replica:0/task:0/device:CPU:338, /job:localhost/replica:0/task:0/device:CPU:339, /job:localhost/replica:0/task:0/device:CPU:34, /job:localhost/replica:0/task:0/device:CPU:340, /job:localhost/replica:0/task:0/device:CPU:341, /job:localhost/replica:0/task:0/device:CPU:342, /job:localhost/replica:0/task:0/device:CPU:343, /job:localhost/replica:0/task:0/device:CPU:344, /job:localhost/replica:0/task:0/device:CPU:345, /job:localhost/replica:0/task:0/device:CPU:346, /job:localhost/replica:0/task:0/device:CPU:347, /job:localhost/replica:0/task:0/device:CPU:348, /job:localhost/replica:0/task:0/device:CPU:349, /job:localhost/replica:0/task:0/device:CPU:35, /job:localhost/replica:0/task:0/device:CPU:350, /job:localhost/replica:0/task:0/device:CPU:351, /job:localhost/replica:0/task:0/device:CPU:352, /job:localhost/replica:0/task:0/device:CPU:353, /job:localhost/replica:0/task:0/device:CPU:354, /job:localhost/replica:0/task:0/device:CPU:355, /job:localhost/replica:0/task:0/device:CPU:356, /job:localhost/replica:0/task:0/device:CPU:357, /job:localhost/replica:0/task:0/device:CPU:358, /job:localhost/replica:0/task:0/device:CPU:359, /job:localhost/replica:0/task:0/device:CPU:36, /job:localhost/replica:0/task:0/device:CPU:360, /job:localhost/replica:0/task:0/device:CPU:361, /job:localhost/replica:0/task:0/device:CPU:362, /job:localhost/replica:0/task:0/device:CPU:363, /job:localhost/replica:0/task:0/device:CPU:364, /job:localhost/replica:0/task:0/device:CPU:365, /job:localhost/replica:0/task:0/device:CPU:366, /job:localhost/replica:0/task:0/device:CPU:367, /job:localhost/replica:0/task:0/device:CPU:368, /job:localhost/replica:0/task:0/device:CPU:369, /job:localhost/replica:0/task:0/device:CPU:37, /job:localhost/replica:0/task:0/device:CPU:370, /job:localhost/replica:0/task:0/device:CPU:371, /job:localhost/replica:0/task:0/device:CPU:372, /job:localhost/replica:0/task:0/device:CPU:373, /job:localhost/replica:0/task:0/device:CPU:374, /job:localhost/replica:0/task:0/device:CPU:375, /job:localhost/replica:0/task:0/device:CPU:376, /job:localhost/replica:0/task:0/device:CPU:377, /job:localhost/replica:0/task:0/device:CPU:378, /job:localhost/replica:0/task:0/device:CPU:379, /job:localhost/replica:0/task:0/device:CPU:38, /job:localhost/replica:0/task:0/device:CPU:380, /job:localhost/replica:0/task:0/device:CPU:381, /job:localhost/replica:0/task:0/device:CPU:382, /job:localhost/replica:0/task:0/device:CPU:383, /job:localhost/replica:0/task:0/device:CPU:384, /job:localhost/replica:0/task:0/device:CPU:385, /job:localhost/replica:0/task:0/device:CPU:386, /job:localhost/replica:0/task:0/device:CPU:387, /job:localhost/replica:0/task:0/device:CPU:388, /job:localhost/replica:0/task:0/device:CPU:389, /job:localhost/replica:0/task:0/device:CPU:39, /job:localhost/replica:0/task:0/device:CPU:390, /job:localhost/replica:0/task:0/device:CPU:391, /job:localhost/replica:0/task:0/device:CPU:392, /job:localhost/replica:0/task:0/device:CPU:393, /job:localhost/replica:0/task:0/device:CPU:394, /job:localhost/replica:0/task:0/device:CPU:395, /job:localhost/replica:0/task:0/device:CPU:396, /job:localhost/replica:0/task:0/device:CPU:397, /job:localhost/replica:0/task:0/device:CPU:398, /job:localhost/replica:0/task:0/device:CPU:399, /job:localhost/replica:0/task:0/device:CPU:4, /job:localhost/replica:0/task:0/device:CPU:40, /job:localhost/replica:0/task:0/device:CPU:400, /job:localhost/replica:0/task:0/device:CPU:401, /job:localhost/replica:0/task:0/device:CPU:402, /job:localhost/replica:0/task:0/device:CPU:403, /job:localhost/replica:0/task:0/device:CPU:404, /job:localhost/replica:0/task:0/device:CPU:405, /job:localhost/replica:0/task:0/device:CPU:406, /job:localhost/replica:0/task:0/device:CPU:407, /job:localhost/replica:0/task:0/device:CPU:408, /job:localhost/replica:0/task:0/device:CPU:409, /job:localhost/replica:0/task:0/device:CPU:41, /job:localhost/replica:0/task:0/device:CPU:410, /job:localhost/replica:0/task:0/device:CPU:411, /job:localhost/replica:0/task:0/device:CPU:412, /job:localhost/replica:0/task:0/device:CPU:413, /job:localhost/replica:0/task:0/device:CPU:414, /job:localhost/replica:0/task:0/device:CPU:415, /job:localhost/replica:0/task:0/device:CPU:416, /job:localhost/replica:0/task:0/device:CPU:417, /job:localhost/replica:0/task:0/device:CPU:418, /job:localhost/replica:0/task:0/device:CPU:419, /job:localhost/replica:0/task:0/device:CPU:42, /job:localhost/replica:0/task:0/device:CPU:420, /job:localhost/replica:0/task:0/device:CPU:421, /job:localhost/replica:0/task:0/device:CPU:422, /job:localhost/replica:0/task:0/device:CPU:423, /job:localhost/replica:0/task:0/device:CPU:424, /job:localhost/replica:0/task:0/device:CPU:425, /job:localhost/replica:0/task:0/device:CPU:426, /job:localhost/replica:0/task:0/device:CPU:427, /job:localhost/replica:0/task:0/device:CPU:428, /job:localhost/replica:0/task:0/device:CPU:429, /job:localhost/replica:0/task:0/device:CPU:43, /job:localhost/replica:0/task:0/device:CPU:430, /job:localhost/replica:0/task:0/device:CPU:431, /job:localhost/replica:0/task:0/device:CPU:432, /job:localhost/replica:0/task:0/device:CPU:433, /job:localhost/replica:0/task:0/device:CPU:434, /job:localhost/replica:0/task:0/device:CPU:435, /job:localhost/replica:0/task:0/device:CPU:436, /job:localhost/replica:0/task:0/device:CPU:437, /job:localhost/replica:0/task:0/device:CPU:438, /job:localhost/replica:0/task:0/device:CPU:439, /job:localhost/replica:0/task:0/device:CPU:44, /job:localhost/replica:0/task:0/device:CPU:440, /job:localhost/replica:0/task:0/device:CPU:441, /job:localhost/replica:0/task:0/device:CPU:442, /job:localhost/replica:0/task:0/device:CPU:443, /job:localhost/replica:0/task:0/device:CPU:444, /job:localhost/replica:0/task:0/device:CPU:445, /job:localhost/replica:0/task:0/device:CPU:446, /job:localhost/replica:0/task:0/device:CPU:447, /job:localhost/replica:0/task:0/device:CPU:448, /job:localhost/replica:0/task:0/device:CPU:449, /job:localhost/replica:0/task:0/device:CPU:45, /job:localhost/replica:0/task:0/device:CPU:450, /job:localhost/replica:0/task:0/device:CPU:451, /job:localhost/replica:0/task:0/device:CPU:452, /job:localhost/replica:0/task:0/device:CPU:453, /job:localhost/replica:0/task:0/device:CPU:454, /job:localhost/replica:0/task:0/device:CPU:455, /job:localhost/replica:0/task:0/device:CPU:456, /job:localhost/replica:0/task:0/device:CPU:457, /job:localhost/replica:0/task:0/device:CPU:458, /job:localhost/replica:0/task:0/device:CPU:459, /job:localhost/replica:0/task:0/device:CPU:46, /job:localhost/replica:0/task:0/device:CPU:460, /job:localhost/replica:0/task:0/device:CPU:461, /job:localhost/replica:0/task:0/device:CPU:462, /job:localhost/replica:0/task:0/device:CPU:463, /job:localhost/replica:0/task:0/device:CPU:464, /job:localhost/replica:0/task:0/device:CPU:465, /job:localhost/replica:0/task:0/device:CPU:466, /job:localhost/replica:0/task:0/device:CPU:467, /job:localhost/replica:0/task:0/device:CPU:468, /job:localhost/replica:0/task:0/device:CPU:469, /job:localhost/replica:0/task:0/device:CPU:47, /job:localhost/replica:0/task:0/device:CPU:470, /job:localhost/replica:0/task:0/device:CPU:471, /job:localhost/replica:0/task:0/device:CPU:472, /job:localhost/replica:0/task:0/device:CPU:473, /job:localhost/replica:0/task:0/device:CPU:474, /job:localhost/replica:0/task:0/device:CPU:475, /job:localhost/replica:0/task:0/device:CPU:476, /job:localhost/replica:0/task:0/device:CPU:477, /job:localhost/replica:0/task:0/device:CPU:478, /job:localhost/replica:0/task:0/device:CPU:479, /job:localhost/replica:0/task:0/device:CPU:48, /job:localhost/replica:0/task:0/device:CPU:480, /job:localhost/replica:0/task:0/device:CPU:481, /job:localhost/replica:0/task:0/device:CPU:482, /job:localhost/replica:0/task:0/device:CPU:483, /job:localhost/replica:0/task:0/device:CPU:484, /job:localhost/replica:0/task:0/device:CPU:485, /job:localhost/replica:0/task:0/device:CPU:486, /job:localhost/replica:0/task:0/device:CPU:487, /job:localhost/replica:0/task:0/device:CPU:488, /job:localhost/replica:0/task:0/device:CPU:489, /job:localhost/replica:0/task:0/device:CPU:49, /job:localhost/replica:0/task:0/device:CPU:490, /job:localhost/replica:0/task:0/device:CPU:491, /job:localhost/replica:0/task:0/device:CPU:492, /job:localhost/replica:0/task:0/device:CPU:493, /job:localhost/replica:0/task:0/device:CPU:494, /job:localhost/replica:0/task:0/device:CPU:495, /job:localhost/replica:0/task:0/device:CPU:496, /job:localhost/replica:0/task:0/device:CPU:497, /job:localhost/replica:0/task:0/device:CPU:498, /job:localhost/replica:0/task:0/device:CPU:499, /job:localhost/replica:0/task:0/device:CPU:5, /job:localhost/replica:0/task:0/device:CPU:50, /job:localhost/replica:0/task:0/device:CPU:500, /job:localhost/replica:0/task:0/device:CPU:501, /job:localhost/replica:0/task:0/device:CPU:502, /job:localhost/replica:0/task:0/device:CPU:503, /job:localhost/replica:0/task:0/device:CPU:504, /job:localhost/replica:0/task:0/device:CPU:505, /job:localhost/replica:0/task:0/device:CPU:506, /job:localhost/replica:0/task:0/device:CPU:507, /job:localhost/replica:0/task:0/device:CPU:508, /job:localhost/replica:0/task:0/device:CPU:509, /job:localhost/replica:0/task:0/device:CPU:51, /job:localhost/replica:0/task:0/device:CPU:510, /job:localhost/replica:0/task:0/device:CPU:511, /job:localhost/replica:0/task:0/device:CPU:512, /job:localhost/replica:0/task:0/device:CPU:513, /job:localhost/replica:0/task:0/device:CPU:514, /job:localhost/replica:0/task:0/device:CPU:515, /job:localhost/replica:0/task:0/device:CPU:516, /job:localhost/replica:0/task:0/device:CPU:517, /job:localhost/replica:0/task:0/device:CPU:518, /job:localhost/replica:0/task:0/device:CPU:519, /job:localhost/replica:0/task:0/device:CPU:52, /job:localhost/replica:0/task:0/device:CPU:520, /job:localhost/replica:0/task:0/device:CPU:521, /job:localhost/replica:0/task:0/device:CPU:522, /job:localhost/replica:0/task:0/device:CPU:523, /job:localhost/replica:0/task:0/device:CPU:524, /job:localhost/replica:0/task:0/device:CPU:525, /job:localhost/replica:0/task:0/device:CPU:526, /job:localhost/replica:0/task:0/device:CPU:527, /job:localhost/replica:0/task:0/device:CPU:528, /job:localhost/replica:0/task:0/device:CPU:529, /job:localhost/replica:0/task:0/device:CPU:53, /job:localhost/replica:0/task:0/device:CPU:530, /job:localhost/replica:0/task:0/device:CPU:531, /job:localhost/replica:0/task:0/device:CPU:532, /job:localhost/replica:0/task:0/device:CPU:533, /job:localhost/replica:0/task:0/device:CPU:534, /job:localhost/replica:0/task:0/device:CPU:535, /job:localhost/replica:0/task:0/device:CPU:536, /job:localhost/replica:0/task:0/device:CPU:537, /job:localhost/replica:0/task:0/device:CPU:538, /job:localhost/replica:0/task:0/device:CPU:539, /job:localhost/replica:0/task:0/device:CPU:54, /job:localhost/replica:0/task:0/device:CPU:540, /job:localhost/replica:0/task:0/device:CPU:541, /job:localhost/replica:0/task:0/device:CPU:542, /job:localhost/replica:0/task:0/device:CPU:543, /job:localhost/replica:0/task:0/device:CPU:544, /job:localhost/replica:0/task:0/device:CPU:545, /job:localhost/replica:0/task:0/device:CPU:546, /job:localhost/replica:0/task:0/device:CPU:547, /job:localhost/replica:0/task:0/device:CPU:548, /job:localhost/replica:0/task:0/device:CPU:549, /job:localhost/replica:0/task:0/device:CPU:55, /job:localhost/replica:0/task:0/device:CPU:550, /job:localhost/replica:0/task:0/device:CPU:551, /job:localhost/replica:0/task:0/device:CPU:552, /job:localhost/replica:0/task:0/device:CPU:553, /job:localhost/replica:0/task:0/device:CPU:554, /job:localhost/replica:0/task:0/device:CPU:555, /job:localhost/replica:0/task:0/device:CPU:556, /job:localhost/replica:0/task:0/device:CPU:557, /job:localhost/replica:0/task:0/device:CPU:558, /job:localhost/replica:0/task:0/device:CPU:559, /job:localhost/replica:0/task:0/device:CPU:56, /job:localhost/replica:0/task:0/device:CPU:560, /job:localhost/replica:0/task:0/device:CPU:561, /job:localhost/replica:0/task:0/device:CPU:562, /job:localhost/replica:0/task:0/device:CPU:563, /job:localhost/replica:0/task:0/device:CPU:564, /job:localhost/replica:0/task:0/device:CPU:565, /job:localhost/replica:0/task:0/device:CPU:566, /job:localhost/replica:0/task:0/device:CPU:567, /job:localhost/replica:0/task:0/device:CPU:568, /job:localhost/replica:0/task:0/device:CPU:569, /job:localhost/replica:0/task:0/device:CPU:57, /job:localhost/replica:0/task:0/device:CPU:570, /job:localhost/replica:0/task:0/device:CPU:571, /job:localhost/replica:0/task:0/device:CPU:572, /job:localhost/replica:0/task:0/device:CPU:573, /job:localhost/replica:0/task:0/device:CPU:574, /job:localhost/replica:0/task:0/device:CPU:575, /job:localhost/replica:0/task:0/device:CPU:576, /job:localhost/replica:0/task:0/device:CPU:577, /job:localhost/replica:0/task:0/device:CPU:578, /job:localhost/replica:0/task:0/device:CPU:579, /job:localhost/replica:0/task:0/device:CPU:58, /job:localhost/replica:0/task:0/device:CPU:580, /job:localhost/replica:0/task:0/device:CPU:581, /job:localhost/replica:0/task:0/device:CPU:582, /job:localhost/replica:0/task:0/device:CPU:583, /job:localhost/replica:0/task:0/device:CPU:584, /job:localhost/replica:0/task:0/device:CPU:585, /job:localhost/replica:0/task:0/device:CPU:586, /job:localhost/replica:0/task:0/device:CPU:587, /job:localhost/replica:0/task:0/device:CPU:588, /job:localhost/replica:0/task:0/device:CPU:589, /job:localhost/replica:0/task:0/device:CPU:59, /job:localhost/replica:0/task:0/device:CPU:590, /job:localhost/replica:0/task:0/device:CPU:591, /job:localhost/replica:0/task:0/device:CPU:592, /job:localhost/replica:0/task:0/device:CPU:593, /job:localhost/replica:0/task:0/device:CPU:594, /job:localhost/replica:0/task:0/device:CPU:595, /job:localhost/replica:0/task:0/device:CPU:596, /job:localhost/replica:0/task:0/device:CPU:597, /job:localhost/replica:0/task:0/device:CPU:598, /job:localhost/replica:0/task:0/device:CPU:599, /job:localhost/replica:0/task:0/device:CPU:6, /job:localhost/replica:0/task:0/device:CPU:60, /job:localhost/replica:0/task:0/device:CPU:600, /job:localhost/replica:0/task:0/device:CPU:601, /job:localhost/replica:0/task:0/device:CPU:602, /job:localhost/replica:0/task:0/device:CPU:603, /job:localhost/replica:0/task:0/device:CPU:604, /job:localhost/replica:0/task:0/device:CPU:605, /job:localhost/replica:0/task:0/device:CPU:606, /job:localhost/replica:0/task:0/device:CPU:607, /job:localhost/replica:0/task:0/device:CPU:608, /job:localhost/replica:0/task:0/device:CPU:609, /job:localhost/replica:0/task:0/device:CPU:61, /job:localhost/replica:0/task:0/device:CPU:610, /job:localhost/replica:0/task:0/device:CPU:611, /job:localhost/replica:0/task:0/device:CPU:612, /job:localhost/replica:0/task:0/device:CPU:613, /job:localhost/replica:0/task:0/device:CPU:614, /job:localhost/replica:0/task:0/device:CPU:615, /job:localhost/replica:0/task:0/device:CPU:616, /job:localhost/replica:0/task:0/device:CPU:617, /job:localhost/replica:0/task:0/device:CPU:618, /job:localhost/replica:0/task:0/device:CPU:619, /job:localhost/replica:0/task:0/device:CPU:62, /job:localhost/replica:0/task:0/device:CPU:620, /job:localhost/replica:0/task:0/device:CPU:621, /job:localhost/replica:0/task:0/device:CPU:622, /job:localhost/replica:0/task:0/device:CPU:623, /job:localhost/replica:0/task:0/device:CPU:624, /job:localhost/replica:0/task:0/device:CPU:625, /job:localhost/replica:0/task:0/device:CPU:626, /job:localhost/replica:0/task:0/device:CPU:627, /job:localhost/replica:0/task:0/device:CPU:628, /job:localhost/replica:0/task:0/device:CPU:629, /job:localhost/replica:0/task:0/device:CPU:63, /job:localhost/replica:0/task:0/device:CPU:630, /job:localhost/replica:0/task:0/device:CPU:631, /job:localhost/replica:0/task:0/device:CPU:632, /job:localhost/replica:0/task:0/device:CPU:633, /job:localhost/replica:0/task:0/device:CPU:634, /job:localhost/replica:0/task:0/device:CPU:635, /job:localhost/replica:0/task:0/device:CPU:636, /job:localhost/replica:0/task:0/device:CPU:637, /job:localhost/replica:0/task:0/device:CPU:638, /job:localhost/replica:0/task:0/device:CPU:639, /job:localhost/replica:0/task:0/device:CPU:64, /job:localhost/replica:0/task:0/device:CPU:640, /job:localhost/replica:0/task:0/device:CPU:641, /job:localhost/replica:0/task:0/device:CPU:642, /job:localhost/replica:0/task:0/device:CPU:643, /job:localhost/replica:0/task:0/device:CPU:644, /job:localhost/replica:0/task:0/device:CPU:645, /job:localhost/replica:0/task:0/device:CPU:646, /job:localhost/replica:0/task:0/device:CPU:647, /job:localhost/replica:0/task:0/device:CPU:648, /job:localhost/replica:0/task:0/device:CPU:649, /job:localhost/replica:0/task:0/device:CPU:65, /job:localhost/replica:0/task:0/device:CPU:650, /job:localhost/replica:0/task:0/device:CPU:651, /job:localhost/replica:0/task:0/device:CPU:652, /job:localhost/replica:0/task:0/device:CPU:653, /job:localhost/replica:0/task:0/device:CPU:654, /job:localhost/replica:0/task:0/device:CPU:655, /job:localhost/replica:0/task:0/device:CPU:656, /job:localhost/replica:0/task:0/device:CPU:657, /job:localhost/replica:0/task:0/device:CPU:658, /job:localhost/replica:0/task:0/device:CPU:659, /job:localhost/replica:0/task:0/device:CPU:66, /job:localhost/replica:0/task:0/device:CPU:660, /job:localhost/replica:0/task:0/device:CPU:661, /job:localhost/replica:0/task:0/device:CPU:662, /job:localhost/replica:0/task:0/device:CPU:663, /job:localhost/replica:0/task:0/device:CPU:664, /job:localhost/replica:0/task:0/device:CPU:665, /job:localhost/replica:0/task:0/device:CPU:666, /job:localhost/replica:0/task:0/device:CPU:667, /job:localhost/replica:0/task:0/device:CPU:668, /job:localhost/replica:0/task:0/device:CPU:669, /job:localhost/replica:0/task:0/device:CPU:67, /job:localhost/replica:0/task:0/device:CPU:670, /job:localhost/replica:0/task:0/device:CPU:671, /job:localhost/replica:0/task:0/device:CPU:672, /job:localhost/replica:0/task:0/device:CPU:673, /job:localhost/replica:0/task:0/device:CPU:674, /job:localhost/replica:0/task:0/device:CPU:675, /job:localhost/replica:0/task:0/device:CPU:676, /job:localhost/replica:0/task:0/device:CPU:677, /job:localhost/replica:0/task:0/device:CPU:678, /job:localhost/replica:0/task:0/device:CPU:679, /job:localhost/replica:0/task:0/device:CPU:68, /job:localhost/replica:0/task:0/device:CPU:680, /job:localhost/replica:0/task:0/device:CPU:681, /job:localhost/replica:0/task:0/device:CPU:682, /job:localhost/replica:0/task:0/device:CPU:683, /job:localhost/replica:0/task:0/device:CPU:684, /job:localhost/replica:0/task:0/device:CPU:685, /job:localhost/replica:0/task:0/device:CPU:686, /job:localhost/replica:0/task:0/device:CPU:687, /job:localhost/replica:0/task:0/device:CPU:688, /job:localhost/replica:0/task:0/device:CPU:689, /job:localhost/replica:0/task:0/device:CPU:69, /job:localhost/replica:0/task:0/device:CPU:690, /job:localhost/replica:0/task:0/device:CPU:691, /job:localhost/replica:0/task:0/device:CPU:692, /job:localhost/replica:0/task:0/device:CPU:693, /job:localhost/replica:0/task:0/device:CPU:694, /job:localhost/replica:0/task:0/device:CPU:695, /job:localhost/replica:0/task:0/device:CPU:696, /job:localhost/replica:0/task:0/device:CPU:697, /job:localhost/replica:0/task:0/device:CPU:698, /job:localhost/replica:0/task:0/device:CPU:699, /job:localhost/replica:0/task:0/device:CPU:7, /job:localhost/replica:0/task:0/device:CPU:70, /job:localhost/replica:0/task:0/device:CPU:700, /job:localhost/replica:0/task:0/device:CPU:701, /job:localhost/replica:0/task:0/device:CPU:702, /job:localhost/replica:0/task:0/device:CPU:703, /job:localhost/replica:0/task:0/device:CPU:704, /job:localhost/replica:0/task:0/device:CPU:705, /job:localhost/replica:0/task:0/device:CPU:706, /job:localhost/replica:0/task:0/device:CPU:707, /job:localhost/replica:0/task:0/device:CPU:708, /job:localhost/replica:0/task:0/device:CPU:709, /job:localhost/replica:0/task:0/device:CPU:71, /job:localhost/replica:0/task:0/device:CPU:710, /job:localhost/replica:0/task:0/device:CPU:711, /job:localhost/replica:0/task:0/device:CPU:712, /job:localhost/replica:0/task:0/device:CPU:713, /job:localhost/replica:0/task:0/device:CPU:714, /job:localhost/replica:0/task:0/device:CPU:715, /job:localhost/replica:0/task:0/device:CPU:716, /job:localhost/replica:0/task:0/device:CPU:717, /job:localhost/replica:0/task:0/device:CPU:718, /job:localhost/replica:0/task:0/device:CPU:719, /job:localhost/replica:0/task:0/device:CPU:72, /job:localhost/replica:0/task:0/device:CPU:720, /job:localhost/replica:0/task:0/device:CPU:721, /job:localhost/replica:0/task:0/device:CPU:722, /job:localhost/replica:0/task:0/device:CPU:723, /job:localhost/replica:0/task:0/device:CPU:724, /job:localhost/replica:0/task:0/device:CPU:725, /job:localhost/replica:0/task:0/device:CPU:726, /job:localhost/replica:0/task:0/device:CPU:727, /job:localhost/replica:0/task:0/device:CPU:728, /job:localhost/replica:0/task:0/device:CPU:729, /job:localhost/replica:0/task:0/device:CPU:73, /job:localhost/replica:0/task:0/device:CPU:730, /job:localhost/replica:0/task:0/device:CPU:731, /job:localhost/replica:0/task:0/device:CPU:732, /job:localhost/replica:0/task:0/device:CPU:733, /job:localhost/replica:0/task:0/device:CPU:734, /job:localhost/replica:0/task:0/device:CPU:735, /job:localhost/replica:0/task:0/device:CPU:736, /job:localhost/replica:0/task:0/device:CPU:737, /job:localhost/replica:0/task:0/device:CPU:738, /job:localhost/replica:0/task:0/device:CPU:739, /job:localhost/replica:0/task:0/device:CPU:74, /job:localhost/replica:0/task:0/device:CPU:740, /job:localhost/replica:0/task:0/device:CPU:741, /job:localhost/replica:0/task:0/device:CPU:742, /job:localhost/replica:0/task:0/device:CPU:743, /job:localhost/replica:0/task:0/device:CPU:744, /job:localhost/replica:0/task:0/device:CPU:745, /job:localhost/replica:0/task:0/device:CPU:746, /job:localhost/replica:0/task:0/device:CPU:747, /job:localhost/replica:0/task:0/device:CPU:748, /job:localhost/replica:0/task:0/device:CPU:749, /job:localhost/replica:0/task:0/device:CPU:75, /job:localhost/replica:0/task:0/device:CPU:750, /job:localhost/replica:0/task:0/device:CPU:751, /job:localhost/replica:0/task:0/device:CPU:752, /job:localhost/replica:0/task:0/device:CPU:753, /job:localhost/replica:0/task:0/device:CPU:754, /job:localhost/replica:0/task:0/device:CPU:755, /job:localhost/replica:0/task:0/device:CPU:756, /job:localhost/replica:0/task:0/device:CPU:757, /job:localhost/replica:0/task:0/device:CPU:758, /job:localhost/replica:0/task:0/device:CPU:759, /job:localhost/replica:0/task:0/device:CPU:76, /job:localhost/replica:0/task:0/device:CPU:760, /job:localhost/replica:0/task:0/device:CPU:761, /job:localhost/replica:0/task:0/device:CPU:762, /job:localhost/replica:0/task:0/device:CPU:763, /job:localhost/replica:0/task:0/device:CPU:764, /job:localhost/replica:0/task:0/device:CPU:765, /job:localhost/replica:0/task:0/device:CPU:766, /job:localhost/replica:0/task:0/device:CPU:767, /job:localhost/replica:0/task:0/device:CPU:768, /job:localhost/replica:0/task:0/device:CPU:769, /job:localhost/replica:0/task:0/device:CPU:77, /job:localhost/replica:0/task:0/device:CPU:770, /job:localhost/replica:0/task:0/device:CPU:771, /job:localhost/replica:0/task:0/device:CPU:772, /job:localhost/replica:0/task:0/device:CPU:773, /job:localhost/replica:0/task:0/device:CPU:774, /job:localhost/replica:0/task:0/device:CPU:775, /job:localhost/replica:0/task:0/device:CPU:776, /job:localhost/replica:0/task:0/device:CPU:777, /job:localhost/replica:0/task:0/device:CPU:778, /job:localhost/replica:0/task:0/device:CPU:779, /job:localhost/replica:0/task:0/device:CPU:78, /job:localhost/replica:0/task:0/device:CPU:780, /job:localhost/replica:0/task:0/device:CPU:781, /job:localhost/replica:0/task:0/device:CPU:782, /job:localhost/replica:0/task:0/device:CPU:783, /job:localhost/replica:0/task:0/device:CPU:784, /job:localhost/replica:0/task:0/device:CPU:785, /job:localhost/replica:0/task:0/device:CPU:786, /job:localhost/replica:0/task:0/device:CPU:787, /job:localhost/replica:0/task:0/device:CPU:788, /job:localhost/replica:0/task:0/device:CPU:789, /job:localhost/replica:0/task:0/device:CPU:79, /job:localhost/replica:0/task:0/device:CPU:790, /job:localhost/replica:0/task:0/device:CPU:791, /job:localhost/replica:0/task:0/device:CPU:792, /job:localhost/replica:0/task:0/device:CPU:793, /job:localhost/replica:0/task:0/device:CPU:794, /job:localhost/replica:0/task:0/device:CPU:795, /job:localhost/replica:0/task:0/device:CPU:796, /job:localhost/replica:0/task:0/device:CPU:797, /job:localhost/replica:0/task:0/device:CPU:798, /job:localhost/replica:0/task:0/device:CPU:799, /job:localhost/replica:0/task:0/device:CPU:8, /job:localhost/replica:0/task:0/device:CPU:80, /job:localhost/replica:0/task:0/device:CPU:800, /job:localhost/replica:0/task:0/device:CPU:801, /job:localhost/replica:0/task:0/device:CPU:802, /job:localhost/replica:0/task:0/device:CPU:803, /job:localhost/replica:0/task:0/device:CPU:804, /job:localhost/replica:0/task:0/device:CPU:805, /job:localhost/replica:0/task:0/device:CPU:806, /job:localhost/replica:0/task:0/device:CPU:807, /job:localhost/replica:0/task:0/device:CPU:808, /job:localhost/replica:0/task:0/device:CPU:809, /job:localhost/replica:0/task:0/device:CPU:81, /job:localhost/replica:0/task:0/device:CPU:810, /job:localhost/replica:0/task:0/device:CPU:811, /job:localhost/replica:0/task:0/device:CPU:812, /job:localhost/replica:0/task:0/device:CPU:813, /job:localhost/replica:0/task:0/device:CPU:814, /job:localhost/replica:0/task:0/device:CPU:815, /job:localhost/replica:0/task:0/device:CPU:816, /job:localhost/replica:0/task:0/device:CPU:817, /job:localhost/replica:0/task:0/device:CPU:818, /job:localhost/replica:0/task:0/device:CPU:819, /job:localhost/replica:0/task:0/device:CPU:82, /job:localhost/replica:0/task:0/device:CPU:820, /job:localhost/replica:0/task:0/device:CPU:821, /job:localhost/replica:0/task:0/device:CPU:822, /job:localhost/replica:0/task:0/device:CPU:823, /job:localhost/replica:0/task:0/device:CPU:824, /job:localhost/replica:0/task:0/device:CPU:825, /job:localhost/replica:0/task:0/device:CPU:826, /job:localhost/replica:0/task:0/device:CPU:827, /job:localhost/replica:0/task:0/device:CPU:828, /job:localhost/replica:0/task:0/device:CPU:829, /job:localhost/replica:0/task:0/device:CPU:83, /job:localhost/replica:0/task:0/device:CPU:830, /job:localhost/replica:0/task:0/device:CPU:831, /job:localhost/replica:0/task:0/device:CPU:832, /job:localhost/replica:0/task:0/device:CPU:833, /job:localhost/replica:0/task:0/device:CPU:834, /job:localhost/replica:0/task:0/device:CPU:835, /job:localhost/replica:0/task:0/device:CPU:836, /job:localhost/replica:0/task:0/device:CPU:837, /job:localhost/replica:0/task:0/device:CPU:838, /job:localhost/replica:0/task:0/device:CPU:839, /job:localhost/replica:0/task:0/device:CPU:84, /job:localhost/replica:0/task:0/device:CPU:840, /job:localhost/replica:0/task:0/device:CPU:841, /job:localhost/replica:0/task:0/device:CPU:842, /job:localhost/replica:0/task:0/device:CPU:843, /job:localhost/replica:0/task:0/device:CPU:844, /job:localhost/replica:0/task:0/device:CPU:845, /job:localhost/replica:0/task:0/device:CPU:846, /job:localhost/replica:0/task:0/device:CPU:847, /job:localhost/replica:0/task:0/device:CPU:848, /job:localhost/replica:0/task:0/device:CPU:849, /job:localhost/replica:0/task:0/device:CPU:85, /job:localhost/replica:0/task:0/device:CPU:850, /job:localhost/replica:0/task:0/device:CPU:851, /job:localhost/replica:0/task:0/device:CPU:852, /job:localhost/replica:0/task:0/device:CPU:853, /job:localhost/replica:0/task:0/device:CPU:854, /job:localhost/replica:0/task:0/device:CPU:855, /job:localhost/replica:0/task:0/device:CPU:856, /job:localhost/replica:0/task:0/device:CPU:857, /job:localhost/replica:0/task:0/device:CPU:858, /job:localhost/replica:0/task:0/device:CPU:859, /job:localhost/replica:0/task:0/device:CPU:86, /job:localhost/replica:0/task:0/device:CPU:860, /job:localhost/replica:0/task:0/device:CPU:861, /job:localhost/replica:0/task:0/device:CPU:862, /job:localhost/replica:0/task:0/device:CPU:863, /job:localhost/replica:0/task:0/device:CPU:864, /job:localhost/replica:0/task:0/device:CPU:865, /job:localhost/replica:0/task:0/device:CPU:866, /job:localhost/replica:0/task:0/device:CPU:867, /job:localhost/replica:0/task:0/device:CPU:868, /job:localhost/replica:0/task:0/device:CPU:869, /job:localhost/replica:0/task:0/device:CPU:87, /job:localhost/replica:0/task:0/device:CPU:870, /job:localhost/replica:0/task:0/device:CPU:871, /job:localhost/replica:0/task:0/device:CPU:872, /job:localhost/replica:0/task:0/device:CPU:873, /job:localhost/replica:0/task:0/device:CPU:874, /job:localhost/replica:0/task:0/device:CPU:875, /job:localhost/replica:0/task:0/device:CPU:876, /job:localhost/replica:0/task:0/device:CPU:877, /job:localhost/replica:0/task:0/device:CPU:878, /job:localhost/replica:0/task:0/device:CPU:879, /job:localhost/replica:0/task:0/device:CPU:88, /job:localhost/replica:0/task:0/device:CPU:880, /job:localhost/replica:0/task:0/device:CPU:881, /job:localhost/replica:0/task:0/device:CPU:882, /job:localhost/replica:0/task:0/device:CPU:883, /job:localhost/replica:0/task:0/device:CPU:884, /job:localhost/replica:0/task:0/device:CPU:885, /job:localhost/replica:0/task:0/device:CPU:886, /job:localhost/replica:0/task:0/device:CPU:887, /job:localhost/replica:0/task:0/device:CPU:888, /job:localhost/replica:0/task:0/device:CPU:889, /job:localhost/replica:0/task:0/device:CPU:89, /job:localhost/replica:0/task:0/device:CPU:890, /job:localhost/replica:0/task:0/device:CPU:891, /job:localhost/replica:0/task:0/device:CPU:892, /job:localhost/replica:0/task:0/device:CPU:893, /job:localhost/replica:0/task:0/device:CPU:894, /job:localhost/replica:0/task:0/device:CPU:895, /job:localhost/replica:0/task:0/device:CPU:896, /job:localhost/replica:0/task:0/device:CPU:897, /job:localhost/replica:0/task:0/device:CPU:898, /job:localhost/replica:0/task:0/device:CPU:899, /job:localhost/replica:0/task:0/device:CPU:9, /job:localhost/replica:0/task:0/device:CPU:90, /job:localhost/replica:0/task:0/device:CPU:900, /job:localhost/replica:0/task:0/device:CPU:901, /job:localhost/replica:0/task:0/device:CPU:902, /job:localhost/replica:0/task:0/device:CPU:903, /job:localhost/replica:0/task:0/device:CPU:904, /job:localhost/replica:0/task:0/device:CPU:905, /job:localhost/replica:0/task:0/device:CPU:906, /job:localhost/replica:0/task:0/device:CPU:907, /job:localhost/replica:0/task:0/device:CPU:908, /job:localhost/replica:0/task:0/device:CPU:909, /job:localhost/replica:0/task:0/device:CPU:91, /job:localhost/replica:0/task:0/device:CPU:910, /job:localhost/replica:0/task:0/device:CPU:911, /job:localhost/replica:0/task:0/device:CPU:912, /job:localhost/replica:0/task:0/device:CPU:913, /job:localhost/replica:0/task:0/device:CPU:914, /job:localhost/replica:0/task:0/device:CPU:915, /job:localhost/replica:0/task:0/device:CPU:916, /job:localhost/replica:0/task:0/device:CPU:917, /job:localhost/replica:0/task:0/device:CPU:918, /job:localhost/replica:0/task:0/device:CPU:919, /job:localhost/replica:0/task:0/device:CPU:92, /job:localhost/replica:0/task:0/device:CPU:920, /job:localhost/replica:0/task:0/device:CPU:921, /job:localhost/replica:0/task:0/device:CPU:922, /job:localhost/replica:0/task:0/device:CPU:923, /job:localhost/replica:0/task:0/device:CPU:924, /job:localhost/replica:0/task:0/device:CPU:925, /job:localhost/replica:0/task:0/device:CPU:926, /job:localhost/replica:0/task:0/device:CPU:927, /job:localhost/replica:0/task:0/device:CPU:928, /job:localhost/replica:0/task:0/device:CPU:929, /job:localhost/replica:0/task:0/device:CPU:93, /job:localhost/replica:0/task:0/device:CPU:930, /job:localhost/replica:0/task:0/device:CPU:931, /job:localhost/replica:0/task:0/device:CPU:932, /job:localhost/replica:0/task:0/device:CPU:933, /job:localhost/replica:0/task:0/device:CPU:934, /job:localhost/replica:0/task:0/device:CPU:935, /job:localhost/replica:0/task:0/device:CPU:936, /job:localhost/replica:0/task:0/device:CPU:937, /job:localhost/replica:0/task:0/device:CPU:938, /job:localhost/replica:0/task:0/device:CPU:939, /job:localhost/replica:0/task:0/device:CPU:94, /job:localhost/replica:0/task:0/device:CPU:940, /job:localhost/replica:0/task:0/device:CPU:941, /job:localhost/replica:0/task:0/device:CPU:942, /job:localhost/replica:0/task:0/device:CPU:943, /job:localhost/replica:0/task:0/device:CPU:944, /job:localhost/replica:0/task:0/device:CPU:945, /job:localhost/replica:0/task:0/device:CPU:946, /job:localhost/replica:0/task:0/device:CPU:947, /job:localhost/replica:0/task:0/device:CPU:948, /job:localhost/replica:0/task:0/device:CPU:949, /job:localhost/replica:0/task:0/device:CPU:95, /job:localhost/replica:0/task:0/device:CPU:950, /job:localhost/replica:0/task:0/device:CPU:951, /job:localhost/replica:0/task:0/device:CPU:952, /job:localhost/replica:0/task:0/device:CPU:953, /job:localhost/replica:0/task:0/device:CPU:954, /job:localhost/replica:0/task:0/device:CPU:955, /job:localhost/replica:0/task:0/device:CPU:956, /job:localhost/replica:0/task:0/device:CPU:957, /job:localhost/replica:0/task:0/device:CPU:958, /job:localhost/replica:0/task:0/device:CPU:959, /job:localhost/replica:0/task:0/device:CPU:96, /job:localhost/replica:0/task:0/device:CPU:960, /job:localhost/replica:0/task:0/device:CPU:961, /job:localhost/replica:0/task:0/device:CPU:962, /job:localhost/replica:0/task:0/device:CPU:963, /job:localhost/replica:0/task:0/device:CPU:964, /job:localhost/replica:0/task:0/device:CPU:965, /job:localhost/replica:0/task:0/device:CPU:966, /job:localhost/replica:0/task:0/device:CPU:967, /job:localhost/replica:0/task:0/device:CPU:968, /job:localhost/replica:0/task:0/device:CPU:969, /job:localhost/replica:0/task:0/device:CPU:97, /job:localhost/replica:0/task:0/device:CPU:970, /job:localhost/replica:0/task:0/device:CPU:971, /job:localhost/replica:0/task:0/device:CPU:972, /job:localhost/replica:0/task:0/device:CPU:973, /job:localhost/replica:0/task:0/device:CPU:974, /job:localhost/replica:0/task:0/device:CPU:975, /job:localhost/replica:0/task:0/device:CPU:976, /job:localhost/replica:0/task:0/device:CPU:977, /job:localhost/replica:0/task:0/device:CPU:978, /job:localhost/replica:0/task:0/device:CPU:979, /job:localhost/replica:0/task:0/device:CPU:98, /job:localhost/replica:0/task:0/device:CPU:980, /job:localhost/replica:0/task:0/device:CPU:981, /job:localhost/replica:0/task:0/device:CPU:982, /job:localhost/replica:0/task:0/device:CPU:983, /job:localhost/replica:0/task:0/device:CPU:984, /job:localhost/replica:0/task:0/device:CPU:985, /job:localhost/replica:0/task:0/device:CPU:986, /job:localhost/replica:0/task:0/device:CPU:987, /job:localhost/replica:0/task:0/device:CPU:988, /job:localhost/replica:0/task:0/device:CPU:989, /job:localhost/replica:0/task:0/device:CPU:99, /job:localhost/replica:0/task:0/device:CPU:990, /job:localhost/replica:0/task:0/device:CPU:991, /job:localhost/replica:0/task:0/device:CPU:992, /job:localhost/replica:0/task:0/device:CPU:993, /job:localhost/replica:0/task:0/device:CPU:994, /job:localhost/replica:0/task:0/device:CPU:995, /job:localhost/replica:0/task:0/device:CPU:996, /job:localhost/replica:0/task:0/device:CPU:997, /job:localhost/replica:0/task:0/device:CPU:998, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.
	 [[net/b]]

2022-3-24 8:29:22.10: Finished.
2022-3-24 8:31:31.54: =============================== logger created =======================================
2022-3-24 8:31:31.54: 
2022-3-24 8:31:31.54: ======================== Starting new session ============================
2022-3-24 8:31:31.54: Command line arguments given: 
Namespace(device='cuda', model_cfg='./examples/configFiles/tinyCnn/model/modelConfig.cfg', reset_trainer=False, saved_model=None, test_cfg=None, train_cfg='examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg')
2022-3-24 8:31:32.68: Available devices to Tensorflow:
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 11096335931877216531
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 17416459390510461964
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 16533229100089267862
physical_device_desc: "device: XLA_CPU device"
]
2022-3-24 8:31:32.68: CONFIG: The configuration file for the [model] given is: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/configFiles/tinyCnn/model/modelConfig.cfg
2022-3-24 8:31:32.69: =============================================================
2022-3-24 8:31:32.69: ========== PARAMETERS FOR MAKING THE ARCHITECTURE ===========
2022-3-24 8:31:32.69: =============================================================
2022-3-24 8:31:32.69: CNN model's name = tinyCnn
2022-3-24 8:31:32.69: ~~~~~~~~~~~~~~~~~~Model parameters~~~~~~~~~~~~~~~~
2022-3-24 8:31:32.69: Number of Classes (including background) = 5
2022-3-24 8:31:32.69: ~~Normal Pathway~~
2022-3-24 8:31:32.69: Number of Input Channels = 2
2022-3-24 8:31:32.69: Number of Layers = 3
2022-3-24 8:31:32.69: Number of Feature Maps per layer = [4, 5, 6]
2022-3-24 8:31:32.69: Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]
2022-3-24 8:31:32.70: Padding mode of convs per layer = ['VALID', 'VALID', 'VALID']
2022-3-24 8:31:32.70: Residual connections added at the output of layers (indices from 0) = []
2022-3-24 8:31:32.70: Layers that will be made of Lower Rank (indices from 0) = []
2022-3-24 8:31:32.70: Lower Rank layers will be made of rank = []
2022-3-24 8:31:32.70: ~~Subsampled Pathway~~
2022-3-24 8:31:32.70: Use subsampled Pathway = True
2022-3-24 8:31:32.70: Number of subsampled pathways that will be built = 1
2022-3-24 8:31:32.70: Number of Layers (per sub-pathway) = [3]
2022-3-24 8:31:32.70: Number of Feature Maps per layer (per sub-pathway) = [[4, 5, 6]]
2022-3-24 8:31:32.70: Kernel Dimensions per layer = [[3, 3, 3], [3, 3, 3], [3, 3, 3]]
2022-3-24 8:31:32.71: Padding mode of convs per layer = ['VALID', 'VALID', 'VALID']
2022-3-24 8:31:32.71: Subsampling Factor per dimension (per sub-pathway) = [[3, 3, 3]]
2022-3-24 8:31:32.71: Residual connections added at the output of layers (indices from 0) = []
2022-3-24 8:31:32.71: Layers that will be made of Lower Rank (indices from 0) = []
2022-3-24 8:31:32.71: Lower Rank layers will be made of rank = []
2022-3-24 8:31:32.71: ~~Fully Connected Pathway~~
2022-3-24 8:31:32.71: Number of additional FC layers (Excluding the Classif. Layer) = 0
2022-3-24 8:31:32.72: Number of Feature Maps in the additional FC layers = []
2022-3-24 8:31:32.72: Padding mode of convs per layer = ['VALID']
2022-3-24 8:31:32.72: Residual connections added at the output of layers (indices from 0) = []
2022-3-24 8:31:32.72: Layers that will be made of Lower Rank (indices from 0) = []
2022-3-24 8:31:32.72: Dimensions of Kernels in final FC path before classification = [[1, 1, 1]]
2022-3-24 8:31:32.72: ~~Size Of Image Segments~~
2022-3-24 8:31:32.72: Size of Segments for Training = [25, 25, 25]
2022-3-24 8:31:32.72: Size of Segments for Validation = [7, 7, 7]
2022-3-24 8:31:32.72: Size of Segments for Testing = [45, 45, 45]
2022-3-24 8:31:32.72: ~~Dropout Rates~~
2022-3-24 8:31:32.72: Drop.R. for each layer in Normal Pathway = []
2022-3-24 8:31:32.72: Drop.R. for each layer in Subsampled Pathway = []
2022-3-24 8:31:32.72: Drop.R. for each layer in FC Pathway (additional FC layers + Classific.Layer at end) = [0.5]
2022-3-24 8:31:32.72: ~~Weight Initialization~~
2022-3-24 8:31:32.72: Initialization method and params for the conv kernel weights = ['fanIn', 2]
2022-3-24 8:31:32.73: ~~Activation Function~~
2022-3-24 8:31:32.73: Activation function to use = prelu
2022-3-24 8:31:32.73: ~~Batch Normalization~~
2022-3-24 8:31:32.73: Apply BN straight on pathways' inputs (eg straight on segments) = [False, False, True]
2022-3-24 8:31:32.73: Batch Normalization uses a rolling average for inference, over this many batches = 60
2022-3-24 8:31:32.73: ========== Done with printing session's parameters ==========
2022-3-24 8:31:32.73: =============================================================
2022-3-24 8:31:32.73: CONFIG: The configuration file for the [session] was loaded from: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/configFiles/tinyCnn/train/trainConfigWithValidation.cfg
2022-3-24 8:31:32.74: 
2022-3-24 8:31:32.74: =============    NEW TRAINING SESSION    ==============

2022-3-24 8:31:32.74: 
2022-3-24 8:31:32.74: =============================================================
2022-3-24 8:31:32.74: ========= PARAMETERS FOR THIS TRAINING SESSION ==============
2022-3-24 8:31:32.74: =============================================================
2022-3-24 8:31:32.74: Session's name = trainSessionWithValidTiny
2022-3-24 8:31:32.74: Model will be loaded from save = None
2022-3-24 8:31:32.74: ~~Output~~
2022-3-24 8:31:32.75: Main output folder = /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output
2022-3-24 8:31:32.75: Log performance metrics for tensorboard = True
2022-3-24 8:31:32.75: Path and filename to save trained models = /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny
2022-3-24 8:31:32.75: ~~~~~~~~~~~~~~~~~~Generic Information~~~~~~~~~~~~~~~~
2022-3-24 8:31:32.75: Number of Cases for Training = 2
2022-3-24 8:31:32.75: Number of Cases for Validation = 2
2022-3-24 8:31:32.75: ~~~~~~~~~~~~~~~~~~Training parameters~~~~~~~~~~~~~~~~
2022-3-24 8:31:32.75: Dataframe (csv) filename = None
2022-3-24 8:31:32.75: Filepaths to Channels of the Training Cases = [['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/T1c_subtrMeanDivStd.nii.gz'], ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/T1c_subtrMeanDivStd.nii.gz']]
2022-3-24 8:31:32.77: Filepaths to Ground-Truth labels of the Training Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/OTMultiClass.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/OTMultiClass.nii.gz']
2022-3-24 8:31:32.77: Filepaths to ROI Masks of the Training Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/brainmask.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/brainmask.nii.gz']
2022-3-24 8:31:32.77: ~~ Sampling (train) ~~
2022-3-24 8:31:32.77: Type of Sampling = Fore/Background (0)
2022-3-24 8:31:32.77: Sampling Categories = ['Foreground', 'Background']
2022-3-24 8:31:32.77: Percent of Samples to extract per Sampling Category = [0.5 0.5]
2022-3-24 8:31:32.77: Paths to weight-Maps for sampling of each category = None
2022-3-24 8:31:32.78: ~~Training Cycle~~
2022-3-24 8:31:32.78: Number of Epochs = 2
2022-3-24 8:31:32.78: Number of Subepochs per epoch = 2
2022-3-24 8:31:32.78: Number of cases to load per Subepoch (for extracting the samples for this subepoch) = 50
2022-3-24 8:31:32.78: Number of Segments loaded per subepoch for Training = 1000. NOTE: This number of segments divided by the batch-size defines the number of optimization-iterations that will be performed every subepoch!
2022-3-24 8:31:32.78: Batch size (train) = 10
2022-3-24 8:31:32.78: Number of parallel processes for sampling = 0
2022-3-24 8:31:32.78: ~~Learning Rate Schedule~~
2022-3-24 8:31:32.78: Type of schedule = poly
2022-3-24 8:31:32.78: [Predef] Predefined schedule of epochs when the LR will be lowered = None
2022-3-24 8:31:32.78: [Predef] When decreasing Learning Rate, divide LR by = 2.0
2022-3-24 8:31:32.78: [Poly] Initial epochs to wait before lowering LR = 0.6666666666666666
2022-3-24 8:31:32.79: [Poly] Final epoch for the schedule = 2
2022-3-24 8:31:32.79: [Auto] Initial epochs to wait before lowering LR = 5
2022-3-24 8:31:32.79: [Auto] When decreasing Learning Rate, divide LR by = 2.0
2022-3-24 8:31:32.79: [Auto] Minimum increase in validation accuracy (0. to 1.) that resets the waiting counter = 0.0
2022-3-24 8:31:32.79: [Expon] (Deprecated) parameters = {'epochs_wait_before_decr': 0.6666666666666666, 'final_ep_for_sch': 2, 'lr_to_reach_at_last_ep': 0.00390625, 'mom_to_reach_at_last_ep': 0.9}
2022-3-24 8:31:32.79: ~~Data Augmentation During Training~~
2022-3-24 8:31:32.79: Image level augmentation:
2022-3-24 8:31:32.79: Parameters for image-level augmentation: {'affine': <deepmedic.dataManagement.augmentImage.AugmenterAffineParams object at 0x7fa1998eb710>}
2022-3-24 8:31:32.79: 	 affine: OrderedDict([('prob', 0.7), ('max_rot_xyz', (45.0, 45.0, 45.0)), ('max_scaling', 0.1), ('seed', None), ('interp_order_imgs', 1), ('interp_order_lbls', 0), ('interp_order_roi', 0), ('interp_order_wmaps', 1), ('boundary_mode', 'nearest'), ('cval', 0.0)])
2022-3-24 8:31:32.79: Patch level augmentation:
2022-3-24 8:31:32.79: Mu and std for shift and scale of histograms = {'shift': {'mu': 0.0, 'std': 0.05}, 'scale': {'mu': 1.0, 'std': 0.01}}
2022-3-24 8:31:32.79: Probabilities of reflecting each axis = (0.5, 0.0, 0.0)
2022-3-24 8:31:32.80: Probabilities of rotating planes 0/90/180/270 degrees = {'xy': {'0': 0.8, '90': 0.1, '180': 0.0, '270': 0.1}, 'yz': {'0': 0.0, '90': 0.0, '180': 0.0, '270': 0.0}, 'xz': {'0': 0.0, '90': 0.0, '180': 0.0, '270': 0.0}}
2022-3-24 8:31:32.82: ~~~~~~~~~~~~~~~~~~Validation parameters~~~~~~~~~~~~~~~~
2022-3-24 8:31:32.82: Perform Validation on Samples throughout training? = True
2022-3-24 8:31:32.82: Perform Full Inference on validation cases every few epochs? = True
2022-3-24 8:31:32.82: Dataframe (csv) filename = None
2022-3-24 8:31:32.82: Filepaths to Channels of Validation Cases = [['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/T1c_subtrMeanDivStd.nii.gz'], ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/T1c_subtrMeanDivStd.nii.gz']]
2022-3-24 8:31:32.82: Filepaths to Ground-Truth labels of the Validation Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/OTMultiClass.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/OTMultiClass.nii.gz']
2022-3-24 8:31:32.82: Filepaths to ROI masks for Validation Cases = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/brainmask.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/brainmask.nii.gz']
2022-3-24 8:31:32.82: ~~~~~~~Validation on Samples throughout Training~~~~~~~
2022-3-24 8:31:32.82: Number of Segments loaded per subepoch for Validation = 5000
2022-3-24 8:31:32.83: Batch size (val on samples) = 50
2022-3-24 8:31:32.83: ~~ Sampling (val) ~~
2022-3-24 8:31:32.83: Type of Sampling = Uniform (1)
2022-3-24 8:31:32.83: Sampling Categories = ['Uniform']
2022-3-24 8:31:32.83: Percent of Samples to extract per Sampling Category = [1.0]
2022-3-24 8:31:32.83: Paths to weight-maps for sampling of each category = None
2022-3-24 8:31:32.83: ~~~~~Validation with Full Inference on Validation Cases~~~~~
2022-3-24 8:31:32.83: Perform Full-Inference on Val. cases every that many epochs = 1
2022-3-24 8:31:32.83: Batch size (val on whole volumes) = 10
2022-3-24 8:31:32.83: ~~Predictions (segmentations and prob maps on val. cases)~~
2022-3-24 8:31:32.83: Save Segmentations = True
2022-3-24 8:31:32.83: Save Probability Maps for each class = [True, True, True, True, True]
2022-3-24 8:31:32.83: Filepaths to save results per case = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions//pred_brats_2013_pat0003_1.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions//pred_brats_2013_pat0004_1.nii.gz']
2022-3-24 8:31:32.83: Suffixes with which to save segmentations and probability maps = {'segm': 'Segm', 'prob': 'ProbMapClass'}
2022-3-24 8:31:32.83: ~~Feature Maps~~
2022-3-24 8:31:32.83: Save Feature Maps = False
2022-3-24 8:31:32.83: Min/Max Indices of FMs to visualise per pathway-type and per layer = None
2022-3-24 8:31:32.84: Filepaths to save FMs per case = ['/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features//pred_brats_2013_pat0003_1.nii.gz', '/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/features//pred_brats_2013_pat0004_1.nii.gz']
2022-3-24 8:31:32.84: ~~Optimization~~
2022-3-24 8:31:32.84: Initial Learning rate = 0.001
2022-3-24 8:31:32.84: Optimizer to use: SGD(0), Adam(1), RmsProp(2) = 2
2022-3-24 8:31:32.84: Parameters for Adam: b1= placeholder, b2=placeholder, e= placeholder
2022-3-24 8:31:32.84: Parameters for RmsProp: rho= 0.9, e= 0.0001
2022-3-24 8:31:32.84: Momentum Type: Classic (0) or Nesterov (1) = 1
2022-3-24 8:31:32.84: Momentum Non-Normalized (0) or Normalized (1) = 1
2022-3-24 8:31:32.84: Momentum Value = 0.6
2022-3-24 8:31:32.84: ~~Costs~~
2022-3-24 8:31:32.84: Loss functions and their weights = {'xentr': 1.0, 'iou': None, 'dsc': None}
2022-3-24 8:31:32.85: Reweight samples in cost on a per-class basis = {'type': None, 'prms': None, 'schedule': [0, 2]}
2022-3-24 8:31:32.85: L1 Regularization term = 1e-06
2022-3-24 8:31:32.85: L2 Regularization term = 0.0001
2022-3-24 8:31:32.85: ~~Freeze Weights of Certain Layers~~
2022-3-24 8:31:32.85: Indices of layers from each type of pathway that will be kept fixed (first layer is 0):
2022-3-24 8:31:32.85: Normal pathway's layers to freeze = []
2022-3-24 8:31:32.85: Subsampled pathway's layers to freeze = []
2022-3-24 8:31:32.85: FC pathway's layers to freeze = []
2022-3-24 8:31:32.85: ~~~~~~~~~~~~~~~~~~ PRE-PROCESSING ~~~~~~~~~~~~~~~~
2022-3-24 8:31:32.85: ~~Data Compabitibility Checks~~
2022-3-24 8:31:32.85: Check whether input data has correct format (can slow down process) = True
2022-3-24 8:31:32.85: ~~Padding~~
2022-3-24 8:31:32.85: Pad Input Images = True
2022-3-24 8:31:32.85: ~~Intensity Normalization~~
2022-3-24 8:31:32.85: Verbosity level = 0
2022-3-24 8:31:32.85: Z-Score parameters = {'apply_to_all_channels': False, 'apply_per_channel': None, 'cutoff_percents': None, 'cutoff_times_std': None, 'cutoff_below_mean': False}
2022-3-24 8:31:32.86: ========== Done with printing session's parameters ==========
2022-3-24 8:31:32.86: =============================================================

2022-3-24 8:31:32.86: =======================================================

2022-3-24 8:31:32.86: =========== Making the CNN graph... ===============
2022-3-24 8:31:32.86: ...Building the CNN model...
2022-3-24 8:31:32.86: [Pathway_NORMAL] is being built...
2022-3-24 8:31:32.86: 	Block [0], FMs-In: 2, FMs-Out: 4, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:31:32.89: 	Block [1], FMs-In: 4, FMs-Out: 5, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:31:32.93: 	Block [2], FMs-In: 5, FMs-Out: 6, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:31:32.97: [Pathway_SUBSAMPLED[3, 3, 3]] is being built...
2022-3-24 8:31:32.97: 	Block [0], FMs-In: 2, FMs-Out: 4, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:31:32.99: 	Block [1], FMs-In: 4, FMs-Out: 5, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:31:33.03: 	Block [2], FMs-In: 5, FMs-Out: 6, Conv Filter dimensions: [3, 3, 3]
2022-3-24 8:31:33.06: [Pathway_FC] is being built...
2022-3-24 8:31:33.06: 	Block [0], FMs-In: 12, FMs-Out: 5, Conv Filter dimensions: [1, 1, 1]
2022-3-24 8:31:33.08: Adding the final Softmax layer...
2022-3-24 8:31:33.09: Finished building the CNN's model.
2022-3-24 8:31:33.09: Pathway [NORMAL], Mode: [train], Input's Shape: (?, 2, 25, 25, 25)
2022-3-24 8:31:33.09: 	Block [0], Mode: [train], Input's Shape: (?, 2, 25, 25, 25)
2022-3-24 8:31:33.11: 	Block [1], Mode: [train], Input's Shape: (?, 4, 23, 23, 23)
2022-3-24 8:31:33.14: 	Block [2], Mode: [train], Input's Shape: (?, 5, 21, 21, 21)
2022-3-24 8:31:33.16: Pathway [NORMAL], Mode: [train], Output's Shape: (?, 6, 19, 19, 19)
2022-3-24 8:31:33.16: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [train], Input's Shape: (?, 2, 13, 13, 13)
2022-3-24 8:31:33.16: 	Block [0], Mode: [train], Input's Shape: (?, 2, 13, 13, 13)
2022-3-24 8:31:33.17: 	Block [1], Mode: [train], Input's Shape: (?, 4, 11, 11, 11)
2022-3-24 8:31:33.18: 	Block [2], Mode: [train], Input's Shape: (?, 5, 9, 9, 9)
2022-3-24 8:31:33.20: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [train], Output's Shape: (?, 6, 7, 7, 7)
2022-3-24 8:31:33.36: Pathway [FC], Mode: [train], Input's Shape: (?, 12, 19, 19, 19)
2022-3-24 8:31:33.36: 	Block [0], Mode: [train], Input's Shape: (?, 12, 19, 19, 19)
2022-3-24 8:31:33.39: Pathway [FC], Mode: [train], Output's Shape: (?, 5, 19, 19, 19)
2022-3-24 8:31:33.45: Pathway [NORMAL], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:31:33.45: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:31:33.46: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 5, 5, 5)
2022-3-24 8:31:33.49: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 3, 3, 3)
2022-3-24 8:31:33.52: Pathway [NORMAL], Mode: [infer], Output's Shape: (?, 6, 1, 1, 1)
2022-3-24 8:31:33.52: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:31:33.52: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 7, 7, 7)
2022-3-24 8:31:33.53: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 5, 5, 5)
2022-3-24 8:31:33.55: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 3, 3, 3)
2022-3-24 8:31:33.57: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Output's Shape: (?, 6, 1, 1, 1)
2022-3-24 8:31:33.65: Pathway [FC], Mode: [infer], Input's Shape: (?, 12, 1, 1, 1)
2022-3-24 8:31:33.65: 	Block [0], Mode: [infer], Input's Shape: (?, 12, 1, 1, 1)
2022-3-24 8:31:33.67: Pathway [FC], Mode: [infer], Output's Shape: (?, 5, 1, 1, 1)
2022-3-24 8:31:33.69: Pathway [NORMAL], Mode: [infer], Input's Shape: (?, 2, 45, 45, 45)
2022-3-24 8:31:33.69: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 45, 45, 45)
2022-3-24 8:31:33.70: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 43, 43, 43)
2022-3-24 8:31:33.72: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 41, 41, 41)
2022-3-24 8:31:33.75: Pathway [NORMAL], Mode: [infer], Output's Shape: (?, 6, 39, 39, 39)
2022-3-24 8:31:33.75: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Input's Shape: (?, 2, 19, 19, 19)
2022-3-24 8:31:33.75: 	Block [0], Mode: [infer], Input's Shape: (?, 2, 19, 19, 19)
2022-3-24 8:31:33.76: 	Block [1], Mode: [infer], Input's Shape: (?, 4, 17, 17, 17)
2022-3-24 8:31:33.78: 	Block [2], Mode: [infer], Input's Shape: (?, 5, 15, 15, 15)
2022-3-24 8:31:33.80: Pathway [SUBSAMPLED[3, 3, 3]], Mode: [infer], Output's Shape: (?, 6, 13, 13, 13)
2022-3-24 8:31:33.91: Pathway [FC], Mode: [infer], Input's Shape: (?, 12, 39, 39, 39)
2022-3-24 8:31:33.91: 	Block [0], Mode: [infer], Input's Shape: (?, 12, 39, 39, 39)
2022-3-24 8:31:33.95: Pathway [FC], Mode: [infer], Output's Shape: (?, 5, 39, 39, 39)
2022-3-24 8:31:33.96: =========== Building Trainer ===========

2022-3-24 8:31:33.97: Building Trainer.
2022-3-24 8:31:33.97: COST: Using cross entropy with weight: 1.0
2022-3-24 8:31:34.02: ...Initializing state of the optimizer...
2022-3-24 8:31:34.42: ----------- Creating Tensorboard Loggers -----------
2022-3-24 8:31:34.90: Loggers created successfully
2022-3-24 8:31:34.90: -----------=============================-----------
2022-3-24 8:31:34.90: =========== Compiling the Training Function ===========
2022-3-24 8:31:34.90: =======================================================

2022-3-24 8:31:35.86: ...Building the training function...
2022-3-24 8:31:35.86: ...Collecting ops and feeds for training...
2022-3-24 8:31:35.91: Done.
2022-3-24 8:31:35.91: =========== Compiling the Validation Function =========
2022-3-24 8:31:35.91: ...Building the validation function...
2022-3-24 8:31:35.91: ...Collecting ops and feeds for validation...
2022-3-24 8:31:35.95: Done.
2022-3-24 8:31:35.95: =========== Compiling the Testing Function ============
2022-3-24 8:31:35.95: ...Building the function for testing and visualisation of FMs...
2022-3-24 8:31:35.95: ...Collecting ops and feeds for testing...
2022-3-24 8:31:35.95: Done.
2022-3-24 8:31:36.23: =========== Initializing network and trainer variables  ===============
2022-3-24 8:31:58.48: All variables were initialized.
2022-3-24 8:31:58.48: Saving the initial model at:/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny.initial.2022-03-24.08.31.58.481324
2022-3-24 8:31:58.74: 
2022-3-24 8:31:58.74: =======================================================
2022-3-24 8:31:58.74: ============== Training the CNN model =================
2022-3-24 8:31:58.74: =======================================================
2022-3-24 8:31:58.89: 
2022-3-24 8:31:58.89: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:31:58.89: ~~			 Starting new Epoch! Epoch #0/2  			~~
2022-3-24 8:31:58.89: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:31:58.89: 
2022-3-24 8:31:58.89: ***********************************************************************************
2022-3-24 8:31:58.89: *			 Starting new Subepoch: #0/2 			*
2022-3-24 8:31:58.89: ***********************************************************************************
2022-3-24 8:31:58.89: [MAIN|PID:599799] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [VALIDATION].
2022-3-24 8:31:58.89: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:
2022-3-24 8:31:58.90: [VAL|SAMPLER|PID:599799] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.
2022-3-24 8:31:58.90: [VAL|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [1, 0]
2022-3-24 8:31:58.93: [VAL|SAMPLER|PID:599799] Will sample from [2] subjects for next Validation...
2022-3-24 8:31:58.93: [VAL|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:31:58.93: [VAL|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:31:59.48: [VAL|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:31:59.62: [VAL|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:0.20: [VAL|JOB:0|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:32:0.20: [VAL|JOB:0|PID:599799] TIMING: [Load: 0.7] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.3] [Augm-Samples: 0.0] secs
2022-3-24 8:32:0.20: [VAL|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:32:0.20: [VAL|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:0.69: [VAL|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:0.84: [VAL|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:1.29: [VAL|JOB:1|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:32:1.29: [VAL|JOB:1|PID:599799] TIMING: [Load: 0.7] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.0] [Extract Sampl: 0.2] [Augm-Samples: 0.0] secs
2022-3-24 8:32:1.30: [VAL|SAMPLER|PID:599799] TIMING: Sampling for next [Validation] lasted: 2.4 secs.
2022-3-24 8:32:1.30: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Validation] =:=:=:=:=:=:
2022-3-24 8:32:1.32: [MAIN|PID:599799] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [TRAINING].
2022-3-24 8:32:1.32: V-V-V-V- Validating for subepoch before starting training iterations -V-V-V-V
2022-3-24 8:32:1.32: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:
2022-3-24 8:32:1.32: [VALIDATION] Processed 0/100 batches for this subepoch...
2022-3-24 8:32:1.32: [TRA|SAMPLER|PID:599799] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.
2022-3-24 8:32:1.32: [TRA|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [1, 0]
2022-3-24 8:32:1.33: [TRA|SAMPLER|PID:599799] Will sample from [2] subjects for next Training...
2022-3-24 8:32:1.33: [TRA|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:32:1.36: [TRA|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:1.79: [TRA|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:1.96: [TRA|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:2.19: [VALIDATION] Processed 20/100 batches for this subepoch...
2022-3-24 8:32:2.30: [VALIDATION] Processed 40/100 batches for this subepoch...
2022-3-24 8:32:2.41: [VALIDATION] Processed 60/100 batches for this subepoch...
2022-3-24 8:32:2.54: [VALIDATION] Processed 80/100 batches for this subepoch...
2022-3-24 8:32:2.65: [VALIDATION] Processed 100/100 batches for this subepoch...
2022-3-24 8:32:2.65: 
2022-3-24 8:32:2.65: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:32:2.65: VALIDATION: Epoch #0, Subepoch #0, Overall:	 mean accuracy:   	0.0310	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 155/5000
2022-3-24 8:32:2.65: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:32:2.65: VALIDATION: Epoch #0, Subepoch #0, Class-0:	 mean accuracy:   	0.1108	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 554/5000
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-0:	 mean sensitivity:	1.0000	=> TruePos/RealPos = 516/516
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-0:	 mean precision:	0.1040	=> TruePos/(TruePos+FalsePos) = 516/4962
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-0:	 mean specificity:	0.0085	=> TrueNeg/RealNeg = 38/4484
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-0:	 mean Dice:       	0.1884
2022-3-24 8:32:2.66: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-1:	 mean accuracy:   	0.9286	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4643/5000
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-1:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/27
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-1:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/330
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-1:	 mean specificity:	0.9336	=> TrueNeg/RealNeg = 4643/4973
2022-3-24 8:32:2.66: VALIDATION: Epoch #0, Subepoch #0, Class-1:	 mean Dice:       	0.0000
2022-3-24 8:32:2.66: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-2:	 mean accuracy:   	0.8310	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4155/5000
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-2:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/317
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-2:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/528
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-2:	 mean specificity:	0.8873	=> TrueNeg/RealNeg = 4155/4683
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-2:	 mean Dice:       	0.0000
2022-3-24 8:32:2.67: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-3:	 mean accuracy:   	0.5672	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 2836/5000
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-3:	 mean sensitivity:	0.8919	=> TruePos/RealPos = 99/111
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-3:	 mean precision:	0.0440	=> TruePos/(TruePos+FalsePos) = 99/2251
2022-3-24 8:32:2.67: VALIDATION: Epoch #0, Subepoch #0, Class-3:	 mean specificity:	0.5598	=> TrueNeg/RealNeg = 2737/4889
2022-3-24 8:32:2.69: VALIDATION: Epoch #0, Subepoch #0, Class-3:	 mean Dice:       	0.0838
2022-3-24 8:32:2.69: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:2.69: VALIDATION: Epoch #0, Subepoch #0, Class-4:	 mean accuracy:   	0.6244	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 3122/5000
2022-3-24 8:32:2.70: VALIDATION: Epoch #0, Subepoch #0, Class-4:	 mean sensitivity:	0.2951	=> TruePos/RealPos = 18/61
2022-3-24 8:32:2.70: VALIDATION: Epoch #0, Subepoch #0, Class-4:	 mean precision:	0.0097	=> TruePos/(TruePos+FalsePos) = 18/1853
2022-3-24 8:32:2.70: VALIDATION: Epoch #0, Subepoch #0, Class-4:	 mean specificity:	0.6285	=> TrueNeg/RealNeg = 3104/4939
2022-3-24 8:32:2.70: VALIDATION: Epoch #0, Subepoch #0, Class-4:	 mean Dice:       	0.0188
2022-3-24 8:32:2.70: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:32:2.70: Logging VALIDATION metrics
2022-3-24 8:32:2.70: Epoch: 0 | Subepoch 0
2022-3-24 8:32:2.70: Step number (index of subepoch since start): 0
2022-3-24 8:32:2.70: --- Logging per class metrics ---
2022-3-24 8:32:2.71: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:32:2.72: ======================================================
2022-3-24 8:32:2.72: TIMING: Validation on batches of subepoch #0 lasted: 1.4 secs.
2022-3-24 8:32:2.79: [TRA|JOB:0|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:32:2.79: [TRA|JOB:0|PID:599799] TIMING: [Load: 0.7] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.2] [Augm-Samples: 0.2] secs
2022-3-24 8:32:2.79: [TRA|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:32:2.79: [TRA|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:3.19: [TRA|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:3.32: [TRA|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:3.90: [TRA|JOB:1|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:32:3.90: [TRA|JOB:1|PID:599799] TIMING: [Load: 0.6] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.1] [Augm-Samples: 0.2] secs
2022-3-24 8:32:3.91: [TRA|SAMPLER|PID:599799] TIMING: Sampling for next [Training] lasted: 2.6 secs.
2022-3-24 8:32:3.91: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Training] =:=:=:=:=:=:
2022-3-24 8:32:3.99: [MAIN|PID:599799] MULTIPROC: Before Training in subepoch #0, submitting sampling job for next [VALIDATION].
2022-3-24 8:32:3.99: -T-T-T-T- Training for this subepoch... May take a few minutes... -T-T-T-T-
2022-3-24 8:32:3.99: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:
2022-3-24 8:32:3.99: [TRAINING] Processed 0/100 batches for this subepoch...
2022-3-24 8:32:3.99: [VAL|SAMPLER|PID:599799] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.
2022-3-24 8:32:3.99: [VAL|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [1, 0]
2022-3-24 8:32:4.00: [VAL|SAMPLER|PID:599799] Will sample from [2] subjects for next Validation...
2022-3-24 8:32:4.00: [VAL|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:32:4.00: [VAL|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:4.36: [VAL|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:4.59: [VAL|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:5.12: [VAL|JOB:0|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:32:5.13: [VAL|JOB:0|PID:599799] TIMING: [Load: 0.6] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.0] [Extract Sampl: 0.3] [Augm-Samples: 0.0] secs
2022-3-24 8:32:5.13: [VAL|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:32:5.13: [VAL|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:5.61: [VAL|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:5.82: [VAL|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:6.33: [VAL|JOB:1|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:32:6.33: [VAL|JOB:1|PID:599799] TIMING: [Load: 0.8] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.0] [Extract Sampl: 0.2] [Augm-Samples: 0.0] secs
2022-3-24 8:32:6.34: [VAL|SAMPLER|PID:599799] TIMING: Sampling for next [Validation] lasted: 2.3 secs.
2022-3-24 8:32:6.34: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Validation] =:=:=:=:=:=:
2022-3-24 8:32:7.94: [TRAINING] Processed 20/100 batches for this subepoch...
2022-3-24 8:32:9.49: [TRAINING] Processed 40/100 batches for this subepoch...
2022-3-24 8:32:11.25: [TRAINING] Processed 60/100 batches for this subepoch...
2022-3-24 8:32:13.21: [TRAINING] Processed 80/100 batches for this subepoch...
2022-3-24 8:32:15.05: [TRAINING] Processed 100/100 batches for this subepoch...
2022-3-24 8:32:15.05: 
2022-3-24 8:32:15.05: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Overall:	 mean accuracy:   	0.4826	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 3310123/6859000
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Overall:	 mean cost:      	1.38399
2022-3-24 8:32:15.06: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-0:	 mean accuracy:   	0.6806	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4668557/6859000
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-0:	 mean sensitivity:	0.8274	=> TruePos/RealPos = 2154652/2604138
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-0:	 mean precision:	0.5531	=> TruePos/(TruePos+FalsePos) = 2154652/3895609
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-0:	 mean specificity:	0.5908	=> TrueNeg/RealNeg = 2513905/4254862
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-0:	 mean Dice:       	0.6630
2022-3-24 8:32:15.06: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-1:	 mean accuracy:   	0.8636	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5923467/6859000
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-1:	 mean sensitivity:	0.0595	=> TruePos/RealPos = 41196/692275
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-1:	 mean precision:	0.1265	=> TruePos/(TruePos+FalsePos) = 41196/325650
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-1:	 mean specificity:	0.9539	=> TrueNeg/RealNeg = 5882271/6166725
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-1:	 mean Dice:       	0.0809
2022-3-24 8:32:15.06: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.06: TRAINING: Epoch #0, Subepoch #0, Class-2:	 mean accuracy:   	0.7764	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5325154/6859000
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-2:	 mean sensitivity:	0.4875	=> TruePos/RealPos = 520729/1068126
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-2:	 mean precision:	0.3455	=> TruePos/(TruePos+FalsePos) = 520729/1507178
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-2:	 mean specificity:	0.8297	=> TrueNeg/RealNeg = 4804425/5790874
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-2:	 mean Dice:       	0.4044
2022-3-24 8:32:15.07: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-3:	 mean accuracy:   	0.7534	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5167683/6859000
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-3:	 mean sensitivity:	0.2485	=> TruePos/RealPos = 55115/221805
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-3:	 mean precision:	0.0349	=> TruePos/(TruePos+FalsePos) = 55115/1579742
2022-3-24 8:32:15.07: TRAINING: Epoch #0, Subepoch #0, Class-3:	 mean specificity:	0.7703	=> TrueNeg/RealNeg = 5112568/6637195
2022-3-24 8:32:15.08: TRAINING: Epoch #0, Subepoch #0, Class-3:	 mean Dice:       	0.0612
2022-3-24 8:32:15.08: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.08: TRAINING: Epoch #0, Subepoch #0, Class-4:	 mean accuracy:   	0.8911	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6112385/6859000
2022-3-24 8:32:15.08: TRAINING: Epoch #0, Subepoch #0, Class-4:	 mean sensitivity:	0.2881	=> TruePos/RealPos = 179178/621932
2022-3-24 8:32:15.08: TRAINING: Epoch #0, Subepoch #0, Class-4:	 mean precision:	0.3709	=> TruePos/(TruePos+FalsePos) = 179178/483039
2022-3-24 8:32:15.08: TRAINING: Epoch #0, Subepoch #0, Class-4:	 mean specificity:	0.9513	=> TrueNeg/RealNeg = 5933207/6237068
2022-3-24 8:32:15.08: TRAINING: Epoch #0, Subepoch #0, Class-4:	 mean Dice:       	0.3243
2022-3-24 8:32:15.08: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:32:15.08: Logging TRAINING metrics
2022-3-24 8:32:15.08: Epoch: 0 | Subepoch 0
2022-3-24 8:32:15.08: Step number (index of subepoch since start): 0
2022-3-24 8:32:15.08: --- Logging average metrics for all classes ---
2022-3-24 8:32:15.08: Logged metrics: ['samples: accuracy', 'samples: cost']
2022-3-24 8:32:15.09: --- Logging per class metrics ---
2022-3-24 8:32:15.10: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:32:15.10: ======================================================
2022-3-24 8:32:15.10: TIMING: Training on batches of this subepoch #0 lasted: 11.1 secs.
2022-3-24 8:32:15.10: 
2022-3-24 8:32:15.10: ***********************************************************************************
2022-3-24 8:32:15.10: *			 Starting new Subepoch: #1/2 			*
2022-3-24 8:32:15.10: ***********************************************************************************
2022-3-24 8:32:15.10: [MAIN|PID:599799] MULTIPROC: Before Validation in subepoch #1, submitting sampling job for next [TRAINING].
2022-3-24 8:32:15.10: V-V-V-V- Validating for subepoch before starting training iterations -V-V-V-V
2022-3-24 8:32:15.10: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:
2022-3-24 8:32:15.11: [VALIDATION] Processed 0/100 batches for this subepoch...
2022-3-24 8:32:15.11: [TRA|SAMPLER|PID:599799] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.
2022-3-24 8:32:15.11: [TRA|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [0, 1]
2022-3-24 8:32:15.11: [TRA|SAMPLER|PID:599799] Will sample from [2] subjects for next Training...
2022-3-24 8:32:15.11: [TRA|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:32:15.11: [TRA|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:15.26: [VALIDATION] Processed 20/100 batches for this subepoch...
2022-3-24 8:32:15.37: [VALIDATION] Processed 40/100 batches for this subepoch...
2022-3-24 8:32:15.51: [VALIDATION] Processed 60/100 batches for this subepoch...
2022-3-24 8:32:15.59: [TRA|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:15.67: [VALIDATION] Processed 80/100 batches for this subepoch...
2022-3-24 8:32:15.79: [VALIDATION] Processed 100/100 batches for this subepoch...
2022-3-24 8:32:15.79: 
2022-3-24 8:32:15.79: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:32:15.79: VALIDATION: Epoch #0, Subepoch #1, Overall:	 mean accuracy:   	0.9040	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4520/5000
2022-3-24 8:32:15.79: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:32:15.79: VALIDATION: Epoch #0, Subepoch #1, Class-0:	 mean accuracy:   	0.9394	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4697/5000
2022-3-24 8:32:15.79: [TRA|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-0:	 mean sensitivity:	0.9862	=> TruePos/RealPos = 502/509
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-0:	 mean precision:	0.6291	=> TruePos/(TruePos+FalsePos) = 502/798
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-0:	 mean specificity:	0.9341	=> TrueNeg/RealNeg = 4195/4491
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-0:	 mean Dice:       	0.7682
2022-3-24 8:32:15.80: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-1:	 mean accuracy:   	0.9900	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4950/5000
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-1:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/28
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-1:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/22
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-1:	 mean specificity:	0.9956	=> TrueNeg/RealNeg = 4950/4972
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-1:	 mean Dice:       	0.0000
2022-3-24 8:32:15.80: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-2:	 mean accuracy:   	0.9434	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4717/5000
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-2:	 mean sensitivity:	0.8882	=> TruePos/RealPos = 286/322
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-2:	 mean precision:	0.5366	=> TruePos/(TruePos+FalsePos) = 286/533
2022-3-24 8:32:15.80: VALIDATION: Epoch #0, Subepoch #1, Class-2:	 mean specificity:	0.9472	=> TrueNeg/RealNeg = 4431/4678
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-2:	 mean Dice:       	0.6690
2022-3-24 8:32:15.81: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-3:	 mean accuracy:   	0.9762	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4881/5000
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-3:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/91
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-3:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/28
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-3:	 mean specificity:	0.9943	=> TrueNeg/RealNeg = 4881/4909
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-3:	 mean Dice:       	0.0000
2022-3-24 8:32:15.81: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-4:	 mean accuracy:   	0.9590	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4795/5000
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-4:	 mean sensitivity:	0.5735	=> TruePos/RealPos = 39/68
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-4:	 mean precision:	0.1814	=> TruePos/(TruePos+FalsePos) = 39/215
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-4:	 mean specificity:	0.9643	=> TrueNeg/RealNeg = 4756/4932
2022-3-24 8:32:15.81: VALIDATION: Epoch #0, Subepoch #1, Class-4:	 mean Dice:       	0.2756
2022-3-24 8:32:15.81: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:32:15.81: Logging VALIDATION metrics
2022-3-24 8:32:15.81: Epoch: 0 | Subepoch 1
2022-3-24 8:32:15.82: Step number (index of subepoch since start): 1
2022-3-24 8:32:15.82: --- Logging per class metrics ---
2022-3-24 8:32:15.85: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:32:15.85: ======================================================
2022-3-24 8:32:15.85: TIMING: Validation on batches of subepoch #1 lasted: 0.7 secs.
2022-3-24 8:32:21.19: [TRA|JOB:0|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:32:21.19: [TRA|JOB:0|PID:599799] TIMING: [Load: 0.8] [Preproc: 0.2] [Augm-Img: 4.7] [Sample Coords: 0.1] [Extract Sampl: 0.1] [Augm-Samples: 0.1] secs
2022-3-24 8:32:21.19: [TRA|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:32:21.19: [TRA|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:21.66: [TRA|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:22.10: [TRA|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:28.05: [TRA|JOB:1|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:32:28.05: [TRA|JOB:1|PID:599799] TIMING: [Load: 0.9] [Preproc: 0.6] [Augm-Img: 4.9] [Sample Coords: 0.1] [Extract Sampl: 0.1] [Augm-Samples: 0.1] secs
2022-3-24 8:32:28.06: [TRA|SAMPLER|PID:599799] TIMING: Sampling for next [Training] lasted: 13.0 secs.
2022-3-24 8:32:28.07: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Training] =:=:=:=:=:=:
2022-3-24 8:32:28.15: -T-T-T-T- Training for this subepoch... May take a few minutes... -T-T-T-T-
2022-3-24 8:32:28.16: [TRAINING] Processed 0/100 batches for this subepoch...
2022-3-24 8:32:29.65: [TRAINING] Processed 20/100 batches for this subepoch...
2022-3-24 8:32:31.56: [TRAINING] Processed 40/100 batches for this subepoch...
2022-3-24 8:32:33.31: [TRAINING] Processed 60/100 batches for this subepoch...
2022-3-24 8:32:35.15: [TRAINING] Processed 80/100 batches for this subepoch...
2022-3-24 8:32:36.68: [TRAINING] Processed 100/100 batches for this subepoch...
2022-3-24 8:32:36.68: 
2022-3-24 8:32:36.68: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:32:36.68: TRAINING: Epoch #0, Subepoch #1, Overall:	 mean accuracy:   	0.7078	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4854544/6859000
2022-3-24 8:32:36.68: TRAINING: Epoch #0, Subepoch #1, Overall:	 mean cost:      	1.07948
2022-3-24 8:32:36.68: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:32:36.68: TRAINING: Epoch #0, Subepoch #1, Class-0:	 mean accuracy:   	0.8328	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5712460/6859000
2022-3-24 8:32:36.68: TRAINING: Epoch #0, Subepoch #1, Class-0:	 mean sensitivity:	0.6885	=> TruePos/RealPos = 1730926/2514132
2022-3-24 8:32:36.68: TRAINING: Epoch #0, Subepoch #1, Class-0:	 mean precision:	0.8265	=> TruePos/(TruePos+FalsePos) = 1730926/2094260
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-0:	 mean specificity:	0.9164	=> TrueNeg/RealNeg = 3981534/4344868
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-0:	 mean Dice:       	0.7512
2022-3-24 8:32:36.69: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-1:	 mean accuracy:   	0.8894	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6100459/6859000
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-1:	 mean sensitivity:	0.0621	=> TruePos/RealPos = 43917/707697
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-1:	 mean precision:	0.3167	=> TruePos/(TruePos+FalsePos) = 43917/138678
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-1:	 mean specificity:	0.9846	=> TrueNeg/RealNeg = 6056542/6151303
2022-3-24 8:32:36.69: TRAINING: Epoch #0, Subepoch #1, Class-1:	 mean Dice:       	0.1038
2022-3-24 8:32:36.69: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:36.70: TRAINING: Epoch #0, Subepoch #1, Class-2:	 mean accuracy:   	0.8435	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5785516/6859000
2022-3-24 8:32:36.70: TRAINING: Epoch #0, Subepoch #1, Class-2:	 mean sensitivity:	0.5285	=> TruePos/RealPos = 535928/1014099
2022-3-24 8:32:36.70: TRAINING: Epoch #0, Subepoch #1, Class-2:	 mean precision:	0.4738	=> TruePos/(TruePos+FalsePos) = 535928/1131241
2022-3-24 8:32:36.70: TRAINING: Epoch #0, Subepoch #1, Class-2:	 mean specificity:	0.8981	=> TrueNeg/RealNeg = 5249588/5844901
2022-3-24 8:32:36.70: TRAINING: Epoch #0, Subepoch #1, Class-2:	 mean Dice:       	0.4996
2022-3-24 8:32:36.70: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:36.70: TRAINING: Epoch #0, Subepoch #1, Class-3:	 mean accuracy:   	0.9351	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6414081/6859000
2022-3-24 8:32:36.71: TRAINING: Epoch #0, Subepoch #1, Class-3:	 mean sensitivity:	0.0771	=> TruePos/RealPos = 16319/211605
2022-3-24 8:32:36.71: TRAINING: Epoch #0, Subepoch #1, Class-3:	 mean precision:	0.0614	=> TruePos/(TruePos+FalsePos) = 16319/265952
2022-3-24 8:32:36.71: TRAINING: Epoch #0, Subepoch #1, Class-3:	 mean specificity:	0.9624	=> TrueNeg/RealNeg = 6397762/6647395
2022-3-24 8:32:36.71: TRAINING: Epoch #0, Subepoch #1, Class-3:	 mean Dice:       	0.0683
2022-3-24 8:32:36.71: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:32:36.72: TRAINING: Epoch #0, Subepoch #1, Class-4:	 mean accuracy:   	0.9146	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6273572/6859000
2022-3-24 8:32:36.72: TRAINING: Epoch #0, Subepoch #1, Class-4:	 mean sensitivity:	0.4767	=> TruePos/RealPos = 276846/580731
2022-3-24 8:32:36.72: TRAINING: Epoch #0, Subepoch #1, Class-4:	 mean precision:	0.4958	=> TruePos/(TruePos+FalsePos) = 276846/558389
2022-3-24 8:32:36.72: TRAINING: Epoch #0, Subepoch #1, Class-4:	 mean specificity:	0.9552	=> TrueNeg/RealNeg = 5996726/6278269
2022-3-24 8:32:36.72: TRAINING: Epoch #0, Subepoch #1, Class-4:	 mean Dice:       	0.4861
2022-3-24 8:32:36.73: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:32:36.73: Logging TRAINING metrics
2022-3-24 8:32:36.73: Epoch: 0 | Subepoch 1
2022-3-24 8:32:36.73: Step number (index of subepoch since start): 1
2022-3-24 8:32:36.73: --- Logging average metrics for all classes ---
2022-3-24 8:32:36.77: Logged metrics: ['samples: accuracy', 'samples: cost']
2022-3-24 8:32:36.77: --- Logging per class metrics ---
2022-3-24 8:32:36.80: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:32:36.80: ======================================================
2022-3-24 8:32:36.80: TIMING: Training on batches of this subepoch #1 lasted: 8.6 secs.
2022-3-24 8:32:36.81: 
2022-3-24 8:32:36.81: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:36.81: ~~~~~~ Epoch #0 finished. Reporting Accuracy over whole epoch. ~~~~~~~
2022-3-24 8:32:36.81: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:36.81: ( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:32:36.82: VALIDATION: Epoch #0, Overall:	 mean accuracy of epoch:	0.4675	=> Correctly-Classified-Voxels/All-Predicted-Voxels
2022-3-24 8:32:36.82: VALIDATION: Epoch #0, Overall:	 mean accuracy of each subepoch:	[ 0.0310 0.9040 ]
2022-3-24 8:32:36.82: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:36.82: VALIDATION: Epoch #0, Class-0:	 mean accuracy of epoch:	0.5251	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:36.82: VALIDATION: Epoch #0, Class-0:	 mean sensitivity of epoch:	0.9931	=> TruePos/RealPos
2022-3-24 8:32:36.83: VALIDATION: Epoch #0, Class-0:	 mean precision of epoch:	0.3665	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:36.83: VALIDATION: Epoch #0, Class-0:	 mean specificity of epoch:	0.4713	=> TrueNeg/RealNeg
2022-3-24 8:32:36.83: VALIDATION: Epoch #0, Class-0:	 mean Dice of epoch:    	0.4783
2022-3-24 8:32:36.83: VALIDATION: Epoch #0, Class-0:	 mean accuracy of each subepoch:	[ 0.1108 0.9394 ]
2022-3-24 8:32:36.83: VALIDATION: Epoch #0, Class-0:	 mean sensitivity of each subepoch:	[ 1.0000 0.9862 ]
2022-3-24 8:32:36.84: VALIDATION: Epoch #0, Class-0:	 mean precision of each subepoch:	[ 0.1040 0.6291 ]
2022-3-24 8:32:36.84: VALIDATION: Epoch #0, Class-0:	 mean specificity of each subepoch:	[ 0.0085 0.9341 ]
2022-3-24 8:32:36.84: VALIDATION: Epoch #0, Class-0:	 mean Dice of each subepoch:    	[ 0.1884 0.7682 ]
2022-3-24 8:32:36.84: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:36.85: VALIDATION: Epoch #0, Class-1:	 mean accuracy of epoch:	0.9593	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:36.85: VALIDATION: Epoch #0, Class-1:	 mean sensitivity of epoch:	0.0000	=> TruePos/RealPos
2022-3-24 8:32:36.85: VALIDATION: Epoch #0, Class-1:	 mean precision of epoch:	0.0000	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:36.85: VALIDATION: Epoch #0, Class-1:	 mean specificity of epoch:	0.9646	=> TrueNeg/RealNeg
2022-3-24 8:32:36.85: VALIDATION: Epoch #0, Class-1:	 mean Dice of epoch:    	0.0000
2022-3-24 8:32:36.86: VALIDATION: Epoch #0, Class-1:	 mean accuracy of each subepoch:	[ 0.9286 0.9900 ]
2022-3-24 8:32:36.86: VALIDATION: Epoch #0, Class-1:	 mean sensitivity of each subepoch:	[ 0.0000 0.0000 ]
2022-3-24 8:32:36.86: VALIDATION: Epoch #0, Class-1:	 mean precision of each subepoch:	[ 0.0000 0.0000 ]
2022-3-24 8:32:36.86: VALIDATION: Epoch #0, Class-1:	 mean specificity of each subepoch:	[ 0.9336 0.9956 ]
2022-3-24 8:32:36.87: VALIDATION: Epoch #0, Class-1:	 mean Dice of each subepoch:    	[ 0.0000 0.0000 ]
2022-3-24 8:32:36.87: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:36.87: VALIDATION: Epoch #0, Class-2:	 mean accuracy of epoch:	0.8872	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:36.88: VALIDATION: Epoch #0, Class-2:	 mean sensitivity of epoch:	0.4441	=> TruePos/RealPos
2022-3-24 8:32:36.88: VALIDATION: Epoch #0, Class-2:	 mean precision of epoch:	0.2683	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:36.88: VALIDATION: Epoch #0, Class-2:	 mean specificity of epoch:	0.9172	=> TrueNeg/RealNeg
2022-3-24 8:32:36.88: VALIDATION: Epoch #0, Class-2:	 mean Dice of epoch:    	0.3345
2022-3-24 8:32:36.90: VALIDATION: Epoch #0, Class-2:	 mean accuracy of each subepoch:	[ 0.8310 0.9434 ]
2022-3-24 8:32:36.90: VALIDATION: Epoch #0, Class-2:	 mean sensitivity of each subepoch:	[ 0.0000 0.8882 ]
2022-3-24 8:32:36.91: VALIDATION: Epoch #0, Class-2:	 mean precision of each subepoch:	[ 0.0000 0.5366 ]
2022-3-24 8:32:36.91: VALIDATION: Epoch #0, Class-2:	 mean specificity of each subepoch:	[ 0.8873 0.9472 ]
2022-3-24 8:32:36.91: VALIDATION: Epoch #0, Class-2:	 mean Dice of each subepoch:    	[ 0.0000 0.6690 ]
2022-3-24 8:32:36.91: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:36.91: VALIDATION: Epoch #0, Class-3:	 mean accuracy of epoch:	0.7717	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:36.92: VALIDATION: Epoch #0, Class-3:	 mean sensitivity of epoch:	0.4459	=> TruePos/RealPos
2022-3-24 8:32:36.92: VALIDATION: Epoch #0, Class-3:	 mean precision of epoch:	0.0220	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:36.92: VALIDATION: Epoch #0, Class-3:	 mean specificity of epoch:	0.7771	=> TrueNeg/RealNeg
2022-3-24 8:32:36.92: VALIDATION: Epoch #0, Class-3:	 mean Dice of epoch:    	0.0419
2022-3-24 8:32:36.93: VALIDATION: Epoch #0, Class-3:	 mean accuracy of each subepoch:	[ 0.5672 0.9762 ]
2022-3-24 8:32:36.93: VALIDATION: Epoch #0, Class-3:	 mean sensitivity of each subepoch:	[ 0.8919 0.0000 ]
2022-3-24 8:32:36.93: VALIDATION: Epoch #0, Class-3:	 mean precision of each subepoch:	[ 0.0440 0.0000 ]
2022-3-24 8:32:36.93: VALIDATION: Epoch #0, Class-3:	 mean specificity of each subepoch:	[ 0.5598 0.9943 ]
2022-3-24 8:32:36.94: VALIDATION: Epoch #0, Class-3:	 mean Dice of each subepoch:    	[ 0.0838 0.0000 ]
2022-3-24 8:32:36.94: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:36.94: VALIDATION: Epoch #0, Class-4:	 mean accuracy of epoch:	0.7917	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:36.94: VALIDATION: Epoch #0, Class-4:	 mean sensitivity of epoch:	0.4343	=> TruePos/RealPos
2022-3-24 8:32:36.95: VALIDATION: Epoch #0, Class-4:	 mean precision of epoch:	0.0956	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:36.95: VALIDATION: Epoch #0, Class-4:	 mean specificity of epoch:	0.7964	=> TrueNeg/RealNeg
2022-3-24 8:32:36.95: VALIDATION: Epoch #0, Class-4:	 mean Dice of epoch:    	0.1472
2022-3-24 8:32:36.96: VALIDATION: Epoch #0, Class-4:	 mean accuracy of each subepoch:	[ 0.6244 0.9590 ]
2022-3-24 8:32:36.96: VALIDATION: Epoch #0, Class-4:	 mean sensitivity of each subepoch:	[ 0.2951 0.5735 ]
2022-3-24 8:32:36.96: VALIDATION: Epoch #0, Class-4:	 mean precision of each subepoch:	[ 0.0097 0.1814 ]
2022-3-24 8:32:36.97: VALIDATION: Epoch #0, Class-4:	 mean specificity of each subepoch:	[ 0.6285 0.9643 ]
2022-3-24 8:32:36.98: VALIDATION: Epoch #0, Class-4:	 mean Dice of each subepoch:    	[ 0.0188 0.2756 ]
2022-3-24 8:32:36.98: >>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:32:36.99: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:32:37.00: ( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:32:37.01: TRAINING: Epoch #0, Overall:	 mean accuracy of epoch:	0.5952	=> Correctly-Classified-Voxels/All-Predicted-Voxels
2022-3-24 8:32:37.02: TRAINING: Epoch #0, Overall:	 mean cost of epoch:    	1.23173
2022-3-24 8:32:37.03: TRAINING: Epoch #0, Overall:	 mean accuracy of each subepoch:	[ 0.4826 0.7078 ]
2022-3-24 8:32:37.04: TRAINING: Epoch #0, Overall:	 mean cost of each subepoch:    	[ 1.38399 1.07948 ]
2022-3-24 8:32:37.04: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:37.05: TRAINING: Epoch #0, Class-0:	 mean accuracy of epoch:	0.7567	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:37.06: TRAINING: Epoch #0, Class-0:	 mean sensitivity of epoch:	0.7579	=> TruePos/RealPos
2022-3-24 8:32:37.08: TRAINING: Epoch #0, Class-0:	 mean precision of epoch:	0.6898	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:37.09: TRAINING: Epoch #0, Class-0:	 mean specificity of epoch:	0.7536	=> TrueNeg/RealNeg
2022-3-24 8:32:37.10: TRAINING: Epoch #0, Class-0:	 mean Dice of epoch:    	0.7071
2022-3-24 8:32:37.11: TRAINING: Epoch #0, Class-0:	 mean accuracy of each subepoch:	[ 0.6806 0.8328 ]
2022-3-24 8:32:37.12: TRAINING: Epoch #0, Class-0:	 mean sensitivity of each subepoch:	[ 0.8274 0.6885 ]
2022-3-24 8:32:37.12: TRAINING: Epoch #0, Class-0:	 mean precision of each subepoch:	[ 0.5531 0.8265 ]
2022-3-24 8:32:37.13: TRAINING: Epoch #0, Class-0:	 mean specificity of each subepoch:	[ 0.5908 0.9164 ]
2022-3-24 8:32:37.14: TRAINING: Epoch #0, Class-0:	 mean Dice of each subepoch:    	[ 0.6630 0.7512 ]
2022-3-24 8:32:37.15: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:37.15: TRAINING: Epoch #0, Class-1:	 mean accuracy of epoch:	0.8765	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:37.16: TRAINING: Epoch #0, Class-1:	 mean sensitivity of epoch:	0.0608	=> TruePos/RealPos
2022-3-24 8:32:37.17: TRAINING: Epoch #0, Class-1:	 mean precision of epoch:	0.2216	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:37.17: TRAINING: Epoch #0, Class-1:	 mean specificity of epoch:	0.9692	=> TrueNeg/RealNeg
2022-3-24 8:32:37.18: TRAINING: Epoch #0, Class-1:	 mean Dice of epoch:    	0.0924
2022-3-24 8:32:37.19: TRAINING: Epoch #0, Class-1:	 mean accuracy of each subepoch:	[ 0.8636 0.8894 ]
2022-3-24 8:32:37.19: TRAINING: Epoch #0, Class-1:	 mean sensitivity of each subepoch:	[ 0.0595 0.0621 ]
2022-3-24 8:32:37.20: TRAINING: Epoch #0, Class-1:	 mean precision of each subepoch:	[ 0.1265 0.3167 ]
2022-3-24 8:32:37.21: TRAINING: Epoch #0, Class-1:	 mean specificity of each subepoch:	[ 0.9539 0.9846 ]
2022-3-24 8:32:37.21: TRAINING: Epoch #0, Class-1:	 mean Dice of each subepoch:    	[ 0.0809 0.1038 ]
2022-3-24 8:32:37.22: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:37.23: TRAINING: Epoch #0, Class-2:	 mean accuracy of epoch:	0.8099	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:37.23: TRAINING: Epoch #0, Class-2:	 mean sensitivity of epoch:	0.5080	=> TruePos/RealPos
2022-3-24 8:32:37.24: TRAINING: Epoch #0, Class-2:	 mean precision of epoch:	0.4096	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:37.25: TRAINING: Epoch #0, Class-2:	 mean specificity of epoch:	0.8639	=> TrueNeg/RealNeg
2022-3-24 8:32:37.25: TRAINING: Epoch #0, Class-2:	 mean Dice of epoch:    	0.4520
2022-3-24 8:32:37.26: TRAINING: Epoch #0, Class-2:	 mean accuracy of each subepoch:	[ 0.7764 0.8435 ]
2022-3-24 8:32:37.26: TRAINING: Epoch #0, Class-2:	 mean sensitivity of each subepoch:	[ 0.4875 0.5285 ]
2022-3-24 8:32:37.27: TRAINING: Epoch #0, Class-2:	 mean precision of each subepoch:	[ 0.3455 0.4738 ]
2022-3-24 8:32:37.28: TRAINING: Epoch #0, Class-2:	 mean specificity of each subepoch:	[ 0.8297 0.8981 ]
2022-3-24 8:32:37.28: TRAINING: Epoch #0, Class-2:	 mean Dice of each subepoch:    	[ 0.4044 0.4996 ]
2022-3-24 8:32:37.29: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:37.30: TRAINING: Epoch #0, Class-3:	 mean accuracy of epoch:	0.8443	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:37.30: TRAINING: Epoch #0, Class-3:	 mean sensitivity of epoch:	0.1628	=> TruePos/RealPos
2022-3-24 8:32:37.31: TRAINING: Epoch #0, Class-3:	 mean precision of epoch:	0.0481	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:37.31: TRAINING: Epoch #0, Class-3:	 mean specificity of epoch:	0.8664	=> TrueNeg/RealNeg
2022-3-24 8:32:37.32: TRAINING: Epoch #0, Class-3:	 mean Dice of epoch:    	0.0648
2022-3-24 8:32:37.33: TRAINING: Epoch #0, Class-3:	 mean accuracy of each subepoch:	[ 0.7534 0.9351 ]
2022-3-24 8:32:37.33: TRAINING: Epoch #0, Class-3:	 mean sensitivity of each subepoch:	[ 0.2485 0.0771 ]
2022-3-24 8:32:37.34: TRAINING: Epoch #0, Class-3:	 mean precision of each subepoch:	[ 0.0349 0.0614 ]
2022-3-24 8:32:37.35: TRAINING: Epoch #0, Class-3:	 mean specificity of each subepoch:	[ 0.7703 0.9624 ]
2022-3-24 8:32:37.35: TRAINING: Epoch #0, Class-3:	 mean Dice of each subepoch:    	[ 0.0612 0.0683 ]
2022-3-24 8:32:37.36: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:32:37.36: TRAINING: Epoch #0, Class-4:	 mean accuracy of epoch:	0.9029	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:32:37.37: TRAINING: Epoch #0, Class-4:	 mean sensitivity of epoch:	0.3824	=> TruePos/RealPos
2022-3-24 8:32:37.38: TRAINING: Epoch #0, Class-4:	 mean precision of epoch:	0.4334	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:32:37.38: TRAINING: Epoch #0, Class-4:	 mean specificity of epoch:	0.9532	=> TrueNeg/RealNeg
2022-3-24 8:32:37.39: TRAINING: Epoch #0, Class-4:	 mean Dice of epoch:    	0.4052
2022-3-24 8:32:37.39: TRAINING: Epoch #0, Class-4:	 mean accuracy of each subepoch:	[ 0.8911 0.9146 ]
2022-3-24 8:32:37.40: TRAINING: Epoch #0, Class-4:	 mean sensitivity of each subepoch:	[ 0.2881 0.4767 ]
2022-3-24 8:32:37.41: TRAINING: Epoch #0, Class-4:	 mean precision of each subepoch:	[ 0.3709 0.4958 ]
2022-3-24 8:32:37.41: TRAINING: Epoch #0, Class-4:	 mean specificity of each subepoch:	[ 0.9513 0.9552 ]
2022-3-24 8:32:37.42: TRAINING: Epoch #0, Class-4:	 mean Dice of each subepoch:    	[ 0.3243 0.4861 ]
2022-3-24 8:32:37.42: >>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:32:37.43: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:32:37.55: Trainer: Current learning rate: 0.0007718895
2022-3-24 8:32:37.61: Trainer: Current momentum: 0.6
2022-3-24 8:32:37.61: Trainer: Number of epochs the model has been trained: 1
2022-3-24 8:32:37.62: SAVING: Epoch #0 finished. Saving CNN model.
2022-3-24 8:32:37.71: TIMING: Whole Epoch #0 lasted: 38.8 secs.
2022-3-24 8:32:37.71: ~~~~~~~~~~~~~~~~~~~ End of Training Epoch. Model was Saved. ~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:37.71: ***Start validation by segmenting whole subjects for Epoch #0***
2022-3-24 8:32:37.72: 
2022-3-24 8:32:37.72: ##########################################################################################
2022-3-24 8:32:37.72: #		  Starting full Segmentation of Validation subjects   			#
2022-3-24 8:32:37.73: ##########################################################################################
2022-3-24 8:32:37.73: 
2022-3-24 8:32:37.74: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:37.74: ~~~~~~~~	 Segmenting subject with index #0 	~~~~~~~~
2022-3-24 8:32:37.75:  Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:38.24:  WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:38.42:  WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:38.58: Starting to (tile) extract Segments from the images of the subject for Segmentation...
2022-3-24 8:32:38.61: Finished (tiling) extracting Segments from the images of the subject for Segmentation.
2022-3-24 8:32:38.64: Ready to make predictions for all image segments (parts).
2022-3-24 8:32:38.65: Total number of Segments to process:90
2022-3-24 8:32:38.67: Processed 0/90 segments.
2022-3-24 8:32:39.02: Processed 10/90 segments.
2022-3-24 8:32:39.21: Processed 20/90 segments.
2022-3-24 8:32:39.40: Processed 30/90 segments.
2022-3-24 8:32:39.62: Processed 40/90 segments.
2022-3-24 8:32:39.85: Processed 50/90 segments.
2022-3-24 8:32:40.08: Processed 60/90 segments.
2022-3-24 8:32:40.34: Processed 70/90 segments.
2022-3-24 8:32:40.60: Processed 80/90 segments.
2022-3-24 8:32:40.85: Processed 90/90 segments.
2022-3-24 8:32:40.87: TIMING: Segmentation of subject: [Forward Pass:] 1.96 secs.
2022-3-24 8:32:41.77: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:32:42.46: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_Segm.nii.gz
2022-3-24 8:32:42.48: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:32:44.47: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass0.nii.gz
2022-3-24 8:32:44.48: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:32:46.04: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass1.nii.gz
2022-3-24 8:32:46.06: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:32:47.28: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass2.nii.gz
2022-3-24 8:32:47.28: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:32:48.23: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass3.nii.gz
2022-3-24 8:32:48.49: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:32:49.13: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass4.nii.gz
2022-3-24 8:32:50.44: +++++++++++ Reporting Segmentation Metrics for Subject #0 +++++++++++
2022-3-24 8:32:50.46: ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #0 equal: DICE1=[ 0.8416 0.0000 0.8447 0.0000 0.3750 ] DICE2=[ 0.8416 0.0000 0.8447 0.0000 0.3750 ] DICE3=[ 0.8419 0.0000 0.8450 0.0000 0.3750 ]
2022-3-24 8:32:50.46: EXPLANATION: DICE1/2/3 are lists with the DICE per class.
	 For Class-0, we calculate DICE for whole foreground: all labels merged except background, label=0.
	 Useful for multi-class problems.
2022-3-24 8:32:50.46: EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT).
	 DICE2 is the segmentation within the ROI vs GT.
	 DICE3 is segmentation within the ROI vs the GT within the ROI.
2022-3-24 8:32:50.46: EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.
2022-3-24 8:32:50.46: 
2022-3-24 8:32:50.46: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:50.47: ~~~~~~~~	 Segmenting subject with index #1 	~~~~~~~~
2022-3-24 8:32:50.47:  Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:50.82:  WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:50.96:  WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:51.09: Starting to (tile) extract Segments from the images of the subject for Segmentation...
2022-3-24 8:32:51.12: Finished (tiling) extracting Segments from the images of the subject for Segmentation.
2022-3-24 8:32:51.12: Ready to make predictions for all image segments (parts).
2022-3-24 8:32:51.12: Total number of Segments to process:80
2022-3-24 8:32:51.12: Processed 0/80 segments.
2022-3-24 8:32:51.28: Processed 10/80 segments.
2022-3-24 8:32:51.44: Processed 20/80 segments.
2022-3-24 8:32:51.58: Processed 30/80 segments.
2022-3-24 8:32:51.72: Processed 40/80 segments.
2022-3-24 8:32:51.88: Processed 50/80 segments.
2022-3-24 8:32:52.02: Processed 60/80 segments.
2022-3-24 8:32:52.16: Processed 70/80 segments.
2022-3-24 8:32:52.30: Processed 80/80 segments.
2022-3-24 8:32:52.30: TIMING: Segmentation of subject: [Forward Pass:] 1.10 secs.
2022-3-24 8:32:52.72: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:32:52.92: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_Segm.nii.gz
2022-3-24 8:32:52.92: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:32:53.29: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass0.nii.gz
2022-3-24 8:32:53.29: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:32:53.75: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass1.nii.gz
2022-3-24 8:32:53.76: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:32:54.29: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass2.nii.gz
2022-3-24 8:32:54.31: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:32:54.96: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass3.nii.gz
2022-3-24 8:32:54.98: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:32:55.42: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass4.nii.gz
2022-3-24 8:32:56.84: +++++++++++ Reporting Segmentation Metrics for Subject #1 +++++++++++
2022-3-24 8:32:56.86: ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #1 equal: DICE1=[ 0.9219 0.0053 0.4535 0.0000 0.4430 ] DICE2=[ 0.9219 0.0053 0.4535 0.0000 0.4430 ] DICE3=[ 0.9219 0.0053 0.4535 0.0000 0.4430 ]
2022-3-24 8:32:56.87: EXPLANATION: DICE1/2/3 are lists with the DICE per class.
	 For Class-0, we calculate DICE for whole foreground: all labels merged except background, label=0.
	 Useful for multi-class problems.
2022-3-24 8:32:56.89: EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT).
	 DICE2 is the segmentation within the ROI vs GT.
	 DICE3 is segmentation within the ROI vs the GT within the ROI.
2022-3-24 8:32:56.91: EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.
2022-3-24 8:32:56.92: 
2022-3-24 8:32:56.94: +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
2022-3-24 8:32:56.96: ++++++++++++++++++++++++ Segmentation of all subjects finished ++++++++++++++++++++++++++++
2022-3-24 8:32:56.98: ++++++++++++++ Reporting Average Segmentation Metrics over all subjects +++++++++++++++++++
2022-3-24 8:32:56.99: ACCURACY: (Validation) The Per-Class average DICE Coefficients over all subjects are: DICE1=[ 0.8817 0.0027 0.6491 0.0000 0.4090 ] DICE2=[ 0.8818 0.0027 0.6491 0.0000 0.4090 ] DICE3=[ 0.8819 0.0027 0.6493 0.0000 0.4090 ]
2022-3-24 8:32:57.01: EXPLANATION: DICE1/2/3 are lists with the DICE per class.
	 For Class-0, we calculate DICE for whole foreground: all labels merged except background, label=0.
	 Useful for multi-class problems.
2022-3-24 8:32:57.03: EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT).
	 DICE2 is the segmentation within the ROI vs GT.
	 DICE3 is segmentation within the ROI vs the GT within the ROI.
2022-3-24 8:32:57.04: EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.
2022-3-24 8:32:57.06: TIMING: Validation process lasted: 19.32 secs.
2022-3-24 8:32:57.08: ##########################################################################################
2022-3-24 8:32:57.09: #		  Finished full Segmentation of Validation subjects   			#
2022-3-24 8:32:57.11: ##########################################################################################
2022-3-24 8:32:57.15: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:32:57.17: Logging validation metrics from segmentation of whole validation volumes.
2022-3-24 8:32:57.18: Epoch: 0
2022-3-24 8:32:57.20: Step number (index of subepoch since start): 1
2022-3-24 8:32:57.34: Logged metrics: ['whole scans: Dice1 (Prediction VS Truth)', 'whole scans: Dice2 (Prediction within ROI mask VS Truth)', 'whole scans: Dice3 (Prediction VS Truth, both within ROI mask)']
2022-3-24 8:32:57.36: ======================================================
2022-3-24 8:32:57.38: 
2022-3-24 8:32:57.40: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:57.41: ~~			 Starting new Epoch! Epoch #1/2  			~~
2022-3-24 8:32:57.43: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:32:57.45: 
2022-3-24 8:32:57.47: ***********************************************************************************
2022-3-24 8:32:57.49: *			 Starting new Subepoch: #0/2 			*
2022-3-24 8:32:57.50: ***********************************************************************************
2022-3-24 8:32:57.52: [MAIN|PID:599799] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [VALIDATION].
2022-3-24 8:32:57.54: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:
2022-3-24 8:32:57.56: [VAL|SAMPLER|PID:599799] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.
2022-3-24 8:32:57.58: [VAL|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [0, 1]
2022-3-24 8:32:57.59: [VAL|SAMPLER|PID:599799] Will sample from [2] subjects for next Validation...
2022-3-24 8:32:57.61: [VAL|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:32:57.63: [VAL|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:58.04: [VAL|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:58.21: [VAL|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:58.69: [VAL|JOB:0|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:32:58.69: [VAL|JOB:0|PID:599799] TIMING: [Load: 0.6] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.0] [Extract Sampl: 0.2] [Augm-Samples: 0.0] secs
2022-3-24 8:32:58.70: [VAL|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:32:58.70: [VAL|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:59.10: [VAL|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:32:59.22: [VAL|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:32:59.68: [VAL|JOB:1|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:32:59.68: [VAL|JOB:1|PID:599799] TIMING: [Load: 0.6] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.0] [Extract Sampl: 0.2] [Augm-Samples: 0.0] secs
2022-3-24 8:32:59.78: [VAL|SAMPLER|PID:599799] TIMING: Sampling for next [Validation] lasted: 2.2 secs.
2022-3-24 8:32:59.78: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Validation] =:=:=:=:=:=:
2022-3-24 8:32:59.81: [MAIN|PID:599799] MULTIPROC: Before Validation in subepoch #0, submitting sampling job for next [TRAINING].
2022-3-24 8:32:59.81: V-V-V-V- Validating for subepoch before starting training iterations -V-V-V-V
2022-3-24 8:32:59.81: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:
2022-3-24 8:32:59.81: [VALIDATION] Processed 0/100 batches for this subepoch...
2022-3-24 8:32:59.81: [TRA|SAMPLER|PID:599799] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.
2022-3-24 8:32:59.82: [TRA|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [0, 1]
2022-3-24 8:32:59.82: [TRA|SAMPLER|PID:599799] Will sample from [2] subjects for next Training...
2022-3-24 8:32:59.82: [TRA|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:32:59.82: [TRA|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:32:59.99: [VALIDATION] Processed 20/100 batches for this subepoch...
2022-3-24 8:33:0.14: [VALIDATION] Processed 40/100 batches for this subepoch...
2022-3-24 8:33:0.22: [TRA|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:0.30: [VALIDATION] Processed 60/100 batches for this subepoch...
2022-3-24 8:33:0.38: [TRA|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:0.48: [VALIDATION] Processed 80/100 batches for this subepoch...
2022-3-24 8:33:0.64: [VALIDATION] Processed 100/100 batches for this subepoch...
2022-3-24 8:33:0.64: 
2022-3-24 8:33:0.64: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:33:0.64: VALIDATION: Epoch #1, Subepoch #0, Overall:	 mean accuracy:   	0.9384	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4692/5000
2022-3-24 8:33:0.65: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-0:	 mean accuracy:   	0.9780	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4890/5000
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-0:	 mean sensitivity:	0.9539	=> TruePos/RealPos = 517/542
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-0:	 mean precision:	0.8588	=> TruePos/(TruePos+FalsePos) = 517/602
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-0:	 mean specificity:	0.9809	=> TrueNeg/RealNeg = 4373/4458
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-0:	 mean Dice:       	0.9038
2022-3-24 8:33:0.65: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-1:	 mean accuracy:   	0.9952	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4976/5000
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-1:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/22
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-1:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/2
2022-3-24 8:33:0.65: VALIDATION: Epoch #1, Subepoch #0, Class-1:	 mean specificity:	0.9996	=> TrueNeg/RealNeg = 4976/4978
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-1:	 mean Dice:       	0.0000
2022-3-24 8:33:0.66: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-2:	 mean accuracy:   	0.9506	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4753/5000
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-2:	 mean sensitivity:	0.7749	=> TruePos/RealPos = 265/342
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-2:	 mean precision:	0.6092	=> TruePos/(TruePos+FalsePos) = 265/435
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-2:	 mean specificity:	0.9635	=> TrueNeg/RealNeg = 4488/4658
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-2:	 mean Dice:       	0.6821
2022-3-24 8:33:0.66: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-3:	 mean accuracy:   	0.9782	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4891/5000
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-3:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/108
2022-3-24 8:33:0.66: VALIDATION: Epoch #1, Subepoch #0, Class-3:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/1
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-3:	 mean specificity:	0.9998	=> TrueNeg/RealNeg = 4891/4892
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-3:	 mean Dice:       	0.0000
2022-3-24 8:33:0.67: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-4:	 mean accuracy:   	0.9748	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4874/5000
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-4:	 mean sensitivity:	0.7714	=> TruePos/RealPos = 54/70
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-4:	 mean precision:	0.3293	=> TruePos/(TruePos+FalsePos) = 54/164
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-4:	 mean specificity:	0.9777	=> TrueNeg/RealNeg = 4820/4930
2022-3-24 8:33:0.67: VALIDATION: Epoch #1, Subepoch #0, Class-4:	 mean Dice:       	0.4615
2022-3-24 8:33:0.67: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:33:0.67: Logging VALIDATION metrics
2022-3-24 8:33:0.67: Epoch: 1 | Subepoch 0
2022-3-24 8:33:0.67: Step number (index of subepoch since start): 2
2022-3-24 8:33:0.68: --- Logging per class metrics ---
2022-3-24 8:33:0.69: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:33:0.69: ======================================================
2022-3-24 8:33:0.69: TIMING: Validation on batches of subepoch #0 lasted: 0.9 secs.
2022-3-24 8:33:3.92: [TRA|JOB:0|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:33:3.92: [TRA|JOB:0|PID:599799] TIMING: [Load: 0.6] [Preproc: 0.1] [Augm-Img: 2.9] [Sample Coords: 0.1] [Extract Sampl: 0.2] [Augm-Samples: 0.2] secs
2022-3-24 8:33:3.92: [TRA|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:33:3.92: [TRA|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:4.26: [TRA|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:4.38: [TRA|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:4.94: [TRA|JOB:1|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:33:4.94: [TRA|JOB:1|PID:599799] TIMING: [Load: 0.5] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.1] [Augm-Samples: 0.1] secs
2022-3-24 8:33:4.94: [TRA|SAMPLER|PID:599799] TIMING: Sampling for next [Training] lasted: 5.1 secs.
2022-3-24 8:33:4.94: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Training] =:=:=:=:=:=:
2022-3-24 8:33:5.03: [MAIN|PID:599799] MULTIPROC: Before Training in subepoch #0, submitting sampling job for next [VALIDATION].
2022-3-24 8:33:5.08: -T-T-T-T- Training for this subepoch... May take a few minutes... -T-T-T-T-
2022-3-24 8:33:5.08: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Validation]... :=:=:=:=:=:=:
2022-3-24 8:33:5.10: [TRAINING] Processed 0/100 batches for this subepoch...
2022-3-24 8:33:5.12: [VAL|SAMPLER|PID:599799] Out of [2] subjects given for [Validation], we will sample from maximum [50] per subepoch.
2022-3-24 8:33:5.12: [VAL|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [0, 1]
2022-3-24 8:33:5.12: [VAL|SAMPLER|PID:599799] Will sample from [2] subjects for next Validation...
2022-3-24 8:33:5.13: [VAL|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:33:5.13: [VAL|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:5.69: [VAL|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:6.17: [VAL|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:7.22: [VAL|JOB:0|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:33:7.24: [VAL|JOB:0|PID:599799] TIMING: [Load: 1.2] [Preproc: 0.3] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.4] [Augm-Samples: 0.0] secs
2022-3-24 8:33:7.26: [VAL|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:33:7.27: [VAL|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:7.28: [TRAINING] Processed 20/100 batches for this subepoch...
2022-3-24 8:33:7.96: [VAL|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:8.18: [VAL|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:9.17: [VAL|JOB:1|PID:599799] Done. Samples per category: [Uniform: 2500/2500] 
2022-3-24 8:33:9.17: [VAL|JOB:1|PID:599799] TIMING: [Load: 1.0] [Preproc: 0.3] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.5] [Augm-Samples: 0.0] secs
2022-3-24 8:33:9.19: [VAL|SAMPLER|PID:599799] TIMING: Sampling for next [Validation] lasted: 4.1 secs.
2022-3-24 8:33:9.19: [VAL|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Validation] =:=:=:=:=:=:
2022-3-24 8:33:9.52: [TRAINING] Processed 40/100 batches for this subepoch...
2022-3-24 8:33:11.43: [TRAINING] Processed 60/100 batches for this subepoch...
2022-3-24 8:33:13.30: [TRAINING] Processed 80/100 batches for this subepoch...
2022-3-24 8:33:15.23: [TRAINING] Processed 100/100 batches for this subepoch...
2022-3-24 8:33:15.23: 
2022-3-24 8:33:15.23: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Overall:	 mean accuracy:   	0.7241	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4966730/6859000
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Overall:	 mean cost:      	0.96119
2022-3-24 8:33:15.24: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Class-0:	 mean accuracy:   	0.8217	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5635887/6859000
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Class-0:	 mean sensitivity:	0.6104	=> TruePos/RealPos = 1577032/2583506
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Class-0:	 mean precision:	0.8792	=> TruePos/(TruePos+FalsePos) = 1577032/1793671
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Class-0:	 mean specificity:	0.9493	=> TrueNeg/RealNeg = 4058855/4275494
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Class-0:	 mean Dice:       	0.7206
2022-3-24 8:33:15.24: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:15.24: TRAINING: Epoch #1, Subepoch #0, Class-1:	 mean accuracy:   	0.8939	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6131001/6859000
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-1:	 mean sensitivity:	0.0739	=> TruePos/RealPos = 52002/703984
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-1:	 mean precision:	0.4062	=> TruePos/(TruePos+FalsePos) = 52002/128019
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-1:	 mean specificity:	0.9876	=> TrueNeg/RealNeg = 6078999/6155016
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-1:	 mean Dice:       	0.1250
2022-3-24 8:33:15.26: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-2:	 mean accuracy:   	0.8538	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5856389/6859000
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-2:	 mean sensitivity:	0.5162	=> TruePos/RealPos = 557223/1079447
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-2:	 mean precision:	0.5370	=> TruePos/(TruePos+FalsePos) = 557223/1037610
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-2:	 mean specificity:	0.9169	=> TrueNeg/RealNeg = 5299166/5779553
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-2:	 mean Dice:       	0.5264
2022-3-24 8:33:15.26: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:15.26: TRAINING: Epoch #1, Subepoch #0, Class-3:	 mean accuracy:   	0.9568	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6562956/6859000
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-3:	 mean sensitivity:	0.0328	=> TruePos/RealPos = 7897/240930
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-3:	 mean precision:	0.1114	=> TruePos/(TruePos+FalsePos) = 7897/70908
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-3:	 mean specificity:	0.9905	=> TrueNeg/RealNeg = 6555059/6618070
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-3:	 mean Dice:       	0.0506
2022-3-24 8:33:15.27: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-4:	 mean accuracy:   	0.9220	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6324227/6859000
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-4:	 mean sensitivity:	0.5200	=> TruePos/RealPos = 290753/559145
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-4:	 mean precision:	0.5219	=> TruePos/(TruePos+FalsePos) = 290753/557134
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-4:	 mean specificity:	0.9577	=> TrueNeg/RealNeg = 6033474/6299855
2022-3-24 8:33:15.27: TRAINING: Epoch #1, Subepoch #0, Class-4:	 mean Dice:       	0.5209
2022-3-24 8:33:15.27: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:33:15.27: Logging TRAINING metrics
2022-3-24 8:33:15.27: Epoch: 1 | Subepoch 0
2022-3-24 8:33:15.27: Step number (index of subepoch since start): 2
2022-3-24 8:33:15.28: --- Logging average metrics for all classes ---
2022-3-24 8:33:15.28: Logged metrics: ['samples: accuracy', 'samples: cost']
2022-3-24 8:33:15.28: --- Logging per class metrics ---
2022-3-24 8:33:15.29: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:33:15.29: ======================================================
2022-3-24 8:33:15.29: TIMING: Training on batches of this subepoch #0 lasted: 10.2 secs.
2022-3-24 8:33:15.29: 
2022-3-24 8:33:15.30: ***********************************************************************************
2022-3-24 8:33:15.30: *			 Starting new Subepoch: #1/2 			*
2022-3-24 8:33:15.30: ***********************************************************************************
2022-3-24 8:33:15.30: [MAIN|PID:599799] MULTIPROC: Before Validation in subepoch #1, submitting sampling job for next [TRAINING].
2022-3-24 8:33:15.30: V-V-V-V- Validating for subepoch before starting training iterations -V-V-V-V
2022-3-24 8:33:15.30: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:=: Starting to sample for next [Training]... :=:=:=:=:=:=:
2022-3-24 8:33:15.30: [VALIDATION] Processed 0/100 batches for this subepoch...
2022-3-24 8:33:15.30: [TRA|SAMPLER|PID:599799] Out of [2] subjects given for [Training], we will sample from maximum [50] per subepoch.
2022-3-24 8:33:15.30: [TRA|SAMPLER|PID:599799] Shuffled indices of subjects that were randomly chosen: [0, 1]
2022-3-24 8:33:15.30: [TRA|SAMPLER|PID:599799] Will sample from [2] subjects for next Training...
2022-3-24 8:33:15.30: [TRA|JOB:0|PID:599799] Started. (#0/2) sampling job. Load & sample from subject of index (in user's list): 0
2022-3-24 8:33:15.30: [TRA|JOB:0|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0005_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:15.46: [VALIDATION] Processed 20/100 batches for this subepoch...
2022-3-24 8:33:15.59: [VALIDATION] Processed 40/100 batches for this subepoch...
2022-3-24 8:33:15.72: [VALIDATION] Processed 60/100 batches for this subepoch...
2022-3-24 8:33:15.86: [TRA|JOB:0|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:15.87: [VALIDATION] Processed 80/100 batches for this subepoch...
2022-3-24 8:33:16.01: [VALIDATION] Processed 100/100 batches for this subepoch...
2022-3-24 8:33:16.01: 
2022-3-24 8:33:16.01: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:33:16.02: VALIDATION: Epoch #1, Subepoch #1, Overall:	 mean accuracy:   	0.9454	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 4727/5000
2022-3-24 8:33:16.02: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:33:16.03: VALIDATION: Epoch #1, Subepoch #1, Class-0:	 mean accuracy:   	0.9778	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4889/5000
2022-3-24 8:33:16.03: VALIDATION: Epoch #1, Subepoch #1, Class-0:	 mean sensitivity:	0.9430	=> TruePos/RealPos = 480/509
2022-3-24 8:33:16.04: VALIDATION: Epoch #1, Subepoch #1, Class-0:	 mean precision:	0.8541	=> TruePos/(TruePos+FalsePos) = 480/562
2022-3-24 8:33:16.04: VALIDATION: Epoch #1, Subepoch #1, Class-0:	 mean specificity:	0.9817	=> TrueNeg/RealNeg = 4409/4491
2022-3-24 8:33:16.05: VALIDATION: Epoch #1, Subepoch #1, Class-0:	 mean Dice:       	0.8964
2022-3-24 8:33:16.05: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:16.06: VALIDATION: Epoch #1, Subepoch #1, Class-1:	 mean accuracy:   	0.9922	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4961/5000
2022-3-24 8:33:16.06: VALIDATION: Epoch #1, Subepoch #1, Class-1:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/33
2022-3-24 8:33:16.07: VALIDATION: Epoch #1, Subepoch #1, Class-1:	 mean precision:	0.0000	=> TruePos/(TruePos+FalsePos) = 0/6
2022-3-24 8:33:16.07: VALIDATION: Epoch #1, Subepoch #1, Class-1:	 mean specificity:	0.9988	=> TrueNeg/RealNeg = 4961/4967
2022-3-24 8:33:16.08: VALIDATION: Epoch #1, Subepoch #1, Class-1:	 mean Dice:       	0.0000
2022-3-24 8:33:16.09: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:16.09: VALIDATION: Epoch #1, Subepoch #1, Class-2:	 mean accuracy:   	0.9578	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4789/5000
2022-3-24 8:33:16.10: VALIDATION: Epoch #1, Subepoch #1, Class-2:	 mean sensitivity:	0.8089	=> TruePos/RealPos = 254/314
2022-3-24 8:33:16.10: VALIDATION: Epoch #1, Subepoch #1, Class-2:	 mean precision:	0.6272	=> TruePos/(TruePos+FalsePos) = 254/405
2022-3-24 8:33:16.11: VALIDATION: Epoch #1, Subepoch #1, Class-2:	 mean specificity:	0.9678	=> TrueNeg/RealNeg = 4535/4686
2022-3-24 8:33:16.12: VALIDATION: Epoch #1, Subepoch #1, Class-2:	 mean Dice:       	0.7065
2022-3-24 8:33:16.12: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:16.12: [TRA|JOB:0|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:16.13: VALIDATION: Epoch #1, Subepoch #1, Class-3:	 mean accuracy:   	0.9830	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4915/5000
2022-3-24 8:33:16.13: VALIDATION: Epoch #1, Subepoch #1, Class-3:	 mean sensitivity:	0.0000	=> TruePos/RealPos = 0/85
2022-3-24 8:33:16.14: VALIDATION: Epoch #1, Subepoch #1, Class-3:	 mean precision:	N/A	=> TruePos/(TruePos+FalsePos) = 0/0
2022-3-24 8:33:16.14: VALIDATION: Epoch #1, Subepoch #1, Class-3:	 mean specificity:	1.0000	=> TrueNeg/RealNeg = 4915/4915
2022-3-24 8:33:16.15: VALIDATION: Epoch #1, Subepoch #1, Class-3:	 mean Dice:       	0.0000
2022-3-24 8:33:16.15: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:16.16: VALIDATION: Epoch #1, Subepoch #1, Class-4:	 mean accuracy:   	0.9800	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 4900/5000
2022-3-24 8:33:16.16: VALIDATION: Epoch #1, Subepoch #1, Class-4:	 mean sensitivity:	0.8312	=> TruePos/RealPos = 64/77
2022-3-24 8:33:16.17: VALIDATION: Epoch #1, Subepoch #1, Class-4:	 mean precision:	0.4238	=> TruePos/(TruePos+FalsePos) = 64/151
2022-3-24 8:33:16.17: VALIDATION: Epoch #1, Subepoch #1, Class-4:	 mean specificity:	0.9823	=> TrueNeg/RealNeg = 4836/4923
2022-3-24 8:33:16.18: VALIDATION: Epoch #1, Subepoch #1, Class-4:	 mean Dice:       	0.5614
2022-3-24 8:33:16.18: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:33:16.18: Logging VALIDATION metrics
2022-3-24 8:33:16.18: Epoch: 1 | Subepoch 1
2022-3-24 8:33:16.18: Step number (index of subepoch since start): 3
2022-3-24 8:33:16.18: --- Logging per class metrics ---
2022-3-24 8:33:16.20: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:33:16.20: ======================================================
2022-3-24 8:33:16.20: TIMING: Validation on batches of subepoch #1 lasted: 0.9 secs.
2022-3-24 8:33:20.96: [TRA|JOB:0|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:33:20.97: [TRA|JOB:0|PID:599799] TIMING: [Load: 0.9] [Preproc: 0.1] [Augm-Img: 4.3] [Sample Coords: 0.1] [Extract Sampl: 0.1] [Augm-Samples: 0.1] secs
2022-3-24 8:33:20.97: [TRA|JOB:1|PID:599799] Started. (#1/2) sampling job. Load & sample from subject of index (in user's list): 1
2022-3-24 8:33:20.97: [TRA|JOB:1|PID:599799] Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/train/brats_2013_pat0006_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:21.30: [TRA|JOB:1|PID:599799] WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:21.42: [TRA|JOB:1|PID:599799] WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:22.01: [TRA|JOB:1|PID:599799] Done. Samples per category: [Foreground: 250/250] [Background: 250/250] 
2022-3-24 8:33:22.01: [TRA|JOB:1|PID:599799] TIMING: [Load: 0.5] [Preproc: 0.1] [Augm-Img: 0.0] [Sample Coords: 0.1] [Extract Sampl: 0.2] [Augm-Samples: 0.1] secs
2022-3-24 8:33:22.02: [TRA|SAMPLER|PID:599799] TIMING: Sampling for next [Training] lasted: 6.7 secs.
2022-3-24 8:33:22.02: [TRA|SAMPLER|PID:599799] :=:=:=:=:=:= Finished sampling for next [Training] =:=:=:=:=:=:
2022-3-24 8:33:22.10: -T-T-T-T- Training for this subepoch... May take a few minutes... -T-T-T-T-
2022-3-24 8:33:22.11: [TRAINING] Processed 0/100 batches for this subepoch...
2022-3-24 8:33:24.09: [TRAINING] Processed 20/100 batches for this subepoch...
2022-3-24 8:33:26.00: [TRAINING] Processed 40/100 batches for this subepoch...
2022-3-24 8:33:27.90: [TRAINING] Processed 60/100 batches for this subepoch...
2022-3-24 8:33:29.69: [TRAINING] Processed 80/100 batches for this subepoch...
2022-3-24 8:33:31.47: [TRAINING] Processed 100/100 batches for this subepoch...
2022-3-24 8:33:31.47: 
2022-3-24 8:33:31.47: +++++++++++++++++++++++ Reporting Accuracy over whole subepoch +++++++++++++++++++++++
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Overall:	 mean accuracy:   	0.7388	=> Correctly-Classified-Voxels/All-Predicted-Voxels = 5067136/6859000
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Overall:	 mean cost:      	0.85169
2022-3-24 8:33:31.47: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-0 ++++++++ [Whole Foreground (Pos) Vs Background (Neg)] ++++++++++++++++
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Class-0:	 mean accuracy:   	0.8294	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5689050/6859000
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Class-0:	 mean sensitivity:	0.6166	=> TruePos/RealPos = 1588555/2576209
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Class-0:	 mean precision:	0.8971	=> TruePos/(TruePos+FalsePos) = 1588555/1770851
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Class-0:	 mean specificity:	0.9574	=> TrueNeg/RealNeg = 4100495/4282791
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Class-0:	 mean Dice:       	0.7309
2022-3-24 8:33:31.47: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-1 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:31.47: TRAINING: Epoch #1, Subepoch #1, Class-1:	 mean accuracy:   	0.8895	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6100895/6859000
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-1:	 mean sensitivity:	0.1041	=> TruePos/RealPos = 80572/773833
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-1:	 mean precision:	0.5541	=> TruePos/(TruePos+FalsePos) = 80572/145416
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-1:	 mean specificity:	0.9893	=> TrueNeg/RealNeg = 6020323/6085167
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-1:	 mean Dice:       	0.1753
2022-3-24 8:33:31.48: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-2 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-2:	 mean accuracy:   	0.8611	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 5906247/6859000
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-2:	 mean sensitivity:	0.5529	=> TruePos/RealPos = 573590/1037330
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-2:	 mean precision:	0.5398	=> TruePos/(TruePos+FalsePos) = 573590/1062603
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-2:	 mean specificity:	0.9160	=> TrueNeg/RealNeg = 5332657/5821670
2022-3-24 8:33:31.48: TRAINING: Epoch #1, Subepoch #1, Class-2:	 mean Dice:       	0.5463
2022-3-24 8:33:31.48: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-3 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-3:	 mean accuracy:   	0.9660	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6625820/6859000
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-3:	 mean sensitivity:	0.0149	=> TruePos/RealPos = 3132/210039
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-3:	 mean precision:	0.1065	=> TruePos/(TruePos+FalsePos) = 3132/29405
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-3:	 mean specificity:	0.9960	=> TrueNeg/RealNeg = 6622688/6648961
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-3:	 mean Dice:       	0.0262
2022-3-24 8:33:31.49: +++++++++++++++ Reporting Accuracy over whole subepoch for Class-4 ++++++++ [This Class (Pos) Vs All Others (Neg)] ++++++++++++++++
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-4:	 mean accuracy:   	0.9315	=> (TruePos+TrueNeg)/All-Predicted-Voxels = 6389260/6859000
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-4:	 mean sensitivity:	0.5574	=> TruePos/RealPos = 309347/555007
2022-3-24 8:33:31.49: TRAINING: Epoch #1, Subepoch #1, Class-4:	 mean precision:	0.5799	=> TruePos/(TruePos+FalsePos) = 309347/533427
2022-3-24 8:33:31.52: TRAINING: Epoch #1, Subepoch #1, Class-4:	 mean specificity:	0.9645	=> TrueNeg/RealNeg = 6079913/6303993
2022-3-24 8:33:31.52: TRAINING: Epoch #1, Subepoch #1, Class-4:	 mean Dice:       	0.5684
2022-3-24 8:33:31.52: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:33:31.52: Logging TRAINING metrics
2022-3-24 8:33:31.52: Epoch: 1 | Subepoch 1
2022-3-24 8:33:31.52: Step number (index of subepoch since start): 3
2022-3-24 8:33:31.52: --- Logging average metrics for all classes ---
2022-3-24 8:33:31.53: Logged metrics: ['samples: accuracy', 'samples: cost']
2022-3-24 8:33:31.53: --- Logging per class metrics ---
2022-3-24 8:33:31.58: Logged metrics: ['samples: accuracy', 'samples: sensitivity', 'samples: precision', 'samples: specificity', 'samples: Dice']
2022-3-24 8:33:31.58: ======================================================
2022-3-24 8:33:31.58: TIMING: Training on batches of this subepoch #1 lasted: 9.5 secs.
2022-3-24 8:33:31.58: 
2022-3-24 8:33:31.59: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:33:31.59: ~~~~~~ Epoch #1 finished. Reporting Accuracy over whole epoch. ~~~~~~~
2022-3-24 8:33:31.59: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:33:31.59: ( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Overall:	 mean accuracy of epoch:	0.9419	=> Correctly-Classified-Voxels/All-Predicted-Voxels
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Overall:	 mean accuracy of each subepoch:	[ 0.9384 0.9454 ]
2022-3-24 8:33:31.59: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean accuracy of epoch:	0.9779	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean sensitivity of epoch:	0.9485	=> TruePos/RealPos
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean precision of epoch:	0.8564	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean specificity of epoch:	0.9813	=> TrueNeg/RealNeg
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean Dice of epoch:    	0.9001
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean accuracy of each subepoch:	[ 0.9780 0.9778 ]
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean sensitivity of each subepoch:	[ 0.9539 0.9430 ]
2022-3-24 8:33:31.59: VALIDATION: Epoch #1, Class-0:	 mean precision of each subepoch:	[ 0.8588 0.8541 ]
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-0:	 mean specificity of each subepoch:	[ 0.9809 0.9817 ]
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-0:	 mean Dice of each subepoch:    	[ 0.9038 0.8964 ]
2022-3-24 8:33:31.60: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean accuracy of epoch:	0.9937	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean sensitivity of epoch:	0.0000	=> TruePos/RealPos
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean precision of epoch:	0.0000	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean specificity of epoch:	0.9992	=> TrueNeg/RealNeg
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean Dice of epoch:    	0.0000
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean accuracy of each subepoch:	[ 0.9952 0.9922 ]
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean sensitivity of each subepoch:	[ 0.0000 0.0000 ]
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean precision of each subepoch:	[ 0.0000 0.0000 ]
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean specificity of each subepoch:	[ 0.9996 0.9988 ]
2022-3-24 8:33:31.60: VALIDATION: Epoch #1, Class-1:	 mean Dice of each subepoch:    	[ 0.0000 0.0000 ]
2022-3-24 8:33:31.61: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean accuracy of epoch:	0.9542	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean sensitivity of epoch:	0.7919	=> TruePos/RealPos
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean precision of epoch:	0.6182	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean specificity of epoch:	0.9656	=> TrueNeg/RealNeg
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean Dice of epoch:    	0.6943
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean accuracy of each subepoch:	[ 0.9506 0.9578 ]
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean sensitivity of each subepoch:	[ 0.7749 0.8089 ]
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean precision of each subepoch:	[ 0.6092 0.6272 ]
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean specificity of each subepoch:	[ 0.9635 0.9678 ]
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-2:	 mean Dice of each subepoch:    	[ 0.6821 0.7065 ]
2022-3-24 8:33:31.61: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-3:	 mean accuracy of epoch:	0.9806	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-3:	 mean sensitivity of epoch:	0.0000	=> TruePos/RealPos
2022-3-24 8:33:31.61: VALIDATION: Epoch #1, Class-3:	 mean precision of epoch:	0.0000	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean specificity of epoch:	0.9999	=> TrueNeg/RealNeg
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean Dice of epoch:    	0.0000
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean accuracy of each subepoch:	[ 0.9782 0.9830 ]
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean sensitivity of each subepoch:	[ 0.0000 0.0000 ]
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean precision of each subepoch:	[ 0.0000 N/A ]
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean specificity of each subepoch:	[ 0.9998 1.0000 ]
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-3:	 mean Dice of each subepoch:    	[ 0.0000 0.0000 ]
2022-3-24 8:33:31.62: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-4:	 mean accuracy of epoch:	0.9774	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-4:	 mean sensitivity of epoch:	0.8013	=> TruePos/RealPos
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-4:	 mean precision of epoch:	0.3766	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.62: VALIDATION: Epoch #1, Class-4:	 mean specificity of epoch:	0.9800	=> TrueNeg/RealNeg
2022-3-24 8:33:31.63: VALIDATION: Epoch #1, Class-4:	 mean Dice of epoch:    	0.5115
2022-3-24 8:33:31.63: VALIDATION: Epoch #1, Class-4:	 mean accuracy of each subepoch:	[ 0.9748 0.9800 ]
2022-3-24 8:33:31.63: VALIDATION: Epoch #1, Class-4:	 mean sensitivity of each subepoch:	[ 0.7714 0.8312 ]
2022-3-24 8:33:31.63: VALIDATION: Epoch #1, Class-4:	 mean precision of each subepoch:	[ 0.3293 0.4238 ]
2022-3-24 8:33:31.63: VALIDATION: Epoch #1, Class-4:	 mean specificity of each subepoch:	[ 0.9777 0.9823 ]
2022-3-24 8:33:31.63: VALIDATION: Epoch #1, Class-4:	 mean Dice of each subepoch:    	[ 0.4615 0.5614 ]
2022-3-24 8:33:31.63: >>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:33:31.63: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:33:31.63: ( >>>>>>>>>>>>>>>>>>>> Reporting Accuracy over whole epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:33:31.63: TRAINING: Epoch #1, Overall:	 mean accuracy of epoch:	0.7314	=> Correctly-Classified-Voxels/All-Predicted-Voxels
2022-3-24 8:33:31.64: TRAINING: Epoch #1, Overall:	 mean cost of epoch:    	0.90644
2022-3-24 8:33:31.64: TRAINING: Epoch #1, Overall:	 mean accuracy of each subepoch:	[ 0.7241 0.7388 ]
2022-3-24 8:33:31.64: TRAINING: Epoch #1, Overall:	 mean cost of each subepoch:    	[ 0.96119 0.85169 ]
2022-3-24 8:33:31.64: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-0 >>>>>>>>> [Whole Foreground (Pos) Vs Background (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.64: TRAINING: Epoch #1, Class-0:	 mean accuracy of epoch:	0.8256	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.64: TRAINING: Epoch #1, Class-0:	 mean sensitivity of epoch:	0.6135	=> TruePos/RealPos
2022-3-24 8:33:31.64: TRAINING: Epoch #1, Class-0:	 mean precision of epoch:	0.8881	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean specificity of epoch:	0.9534	=> TrueNeg/RealNeg
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean Dice of epoch:    	0.7257
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean accuracy of each subepoch:	[ 0.8217 0.8294 ]
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean sensitivity of each subepoch:	[ 0.6104 0.6166 ]
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean precision of each subepoch:	[ 0.8792 0.8971 ]
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean specificity of each subepoch:	[ 0.9493 0.9574 ]
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-0:	 mean Dice of each subepoch:    	[ 0.7206 0.7309 ]
2022-3-24 8:33:31.65: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-1 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-1:	 mean accuracy of epoch:	0.8917	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-1:	 mean sensitivity of epoch:	0.0890	=> TruePos/RealPos
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-1:	 mean precision of epoch:	0.4801	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-1:	 mean specificity of epoch:	0.9885	=> TrueNeg/RealNeg
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-1:	 mean Dice of epoch:    	0.1502
2022-3-24 8:33:31.65: TRAINING: Epoch #1, Class-1:	 mean accuracy of each subepoch:	[ 0.8939 0.8895 ]
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-1:	 mean sensitivity of each subepoch:	[ 0.0739 0.1041 ]
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-1:	 mean precision of each subepoch:	[ 0.4062 0.5541 ]
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-1:	 mean specificity of each subepoch:	[ 0.9876 0.9893 ]
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-1:	 mean Dice of each subepoch:    	[ 0.1250 0.1753 ]
2022-3-24 8:33:31.66: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-2 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-2:	 mean accuracy of epoch:	0.8575	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-2:	 mean sensitivity of epoch:	0.5346	=> TruePos/RealPos
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-2:	 mean precision of epoch:	0.5384	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-2:	 mean specificity of epoch:	0.9164	=> TrueNeg/RealNeg
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-2:	 mean Dice of epoch:    	0.5364
2022-3-24 8:33:31.66: TRAINING: Epoch #1, Class-2:	 mean accuracy of each subepoch:	[ 0.8538 0.8611 ]
2022-3-24 8:33:31.67: TRAINING: Epoch #1, Class-2:	 mean sensitivity of each subepoch:	[ 0.5162 0.5529 ]
2022-3-24 8:33:31.67: TRAINING: Epoch #1, Class-2:	 mean precision of each subepoch:	[ 0.5370 0.5398 ]
2022-3-24 8:33:31.67: TRAINING: Epoch #1, Class-2:	 mean specificity of each subepoch:	[ 0.9169 0.9160 ]
2022-3-24 8:33:31.67: TRAINING: Epoch #1, Class-2:	 mean Dice of each subepoch:    	[ 0.5264 0.5463 ]
2022-3-24 8:33:31.67: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-3 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.67: TRAINING: Epoch #1, Class-3:	 mean accuracy of epoch:	0.9614	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.67: TRAINING: Epoch #1, Class-3:	 mean sensitivity of epoch:	0.0238	=> TruePos/RealPos
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean precision of epoch:	0.1089	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean specificity of epoch:	0.9933	=> TrueNeg/RealNeg
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean Dice of epoch:    	0.0384
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean accuracy of each subepoch:	[ 0.9568 0.9660 ]
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean sensitivity of each subepoch:	[ 0.0328 0.0149 ]
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean precision of each subepoch:	[ 0.1114 0.1065 ]
2022-3-24 8:33:31.68: TRAINING: Epoch #1, Class-3:	 mean specificity of each subepoch:	[ 0.9905 0.9960 ]
2022-3-24 8:33:31.69: TRAINING: Epoch #1, Class-3:	 mean Dice of each subepoch:    	[ 0.0506 0.0262 ]
2022-3-24 8:33:31.69: >>>>>>>>>>>> Reporting Accuracy over whole epoch for Class-4 >>>>>>>>> [This Class (Pos) Vs All Others (Neg)] <<<<<<<<<<<<<
2022-3-24 8:33:31.69: TRAINING: Epoch #1, Class-4:	 mean accuracy of epoch:	0.9268	=> (TruePos+TrueNeg)/All-Predicted-Voxels
2022-3-24 8:33:31.69: TRAINING: Epoch #1, Class-4:	 mean sensitivity of epoch:	0.5387	=> TruePos/RealPos
2022-3-24 8:33:31.69: TRAINING: Epoch #1, Class-4:	 mean precision of epoch:	0.5509	=> TruePos/(TruePos+FalsePos)
2022-3-24 8:33:31.69: TRAINING: Epoch #1, Class-4:	 mean specificity of epoch:	0.9611	=> TrueNeg/RealNeg
2022-3-24 8:33:31.70: TRAINING: Epoch #1, Class-4:	 mean Dice of epoch:    	0.5447
2022-3-24 8:33:31.70: TRAINING: Epoch #1, Class-4:	 mean accuracy of each subepoch:	[ 0.9220 0.9315 ]
2022-3-24 8:33:31.70: TRAINING: Epoch #1, Class-4:	 mean sensitivity of each subepoch:	[ 0.5200 0.5574 ]
2022-3-24 8:33:31.70: TRAINING: Epoch #1, Class-4:	 mean precision of each subepoch:	[ 0.5219 0.5799 ]
2022-3-24 8:33:31.70: TRAINING: Epoch #1, Class-4:	 mean specificity of each subepoch:	[ 0.9577 0.9645 ]
2022-3-24 8:33:31.70: TRAINING: Epoch #1, Class-4:	 mean Dice of each subepoch:    	[ 0.5209 0.5684 ]
2022-3-24 8:33:31.71: >>>>>>>>>>>>>>>>>>>>>>>>> End Of Accuracy Report at the end of Epoch <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:33:31.71: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
2022-3-24 8:33:31.71: Trainer: Current learning rate: 3.1459535e-10
2022-3-24 8:33:31.71: Trainer: Current momentum: 0.6
2022-3-24 8:33:31.72: Trainer: Number of epochs the model has been trained: 2
2022-3-24 8:33:31.72: SAVING: Epoch #1 finished. Saving CNN model.
2022-3-24 8:33:31.76: TIMING: Whole Epoch #1 lasted: 34.3 secs.
2022-3-24 8:33:31.76: ~~~~~~~~~~~~~~~~~~~ End of Training Epoch. Model was Saved. ~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:33:31.77: ***Start validation by segmenting whole subjects for Epoch #1***
2022-3-24 8:33:31.77: 
2022-3-24 8:33:31.77: ##########################################################################################
2022-3-24 8:33:31.78: #		  Starting full Segmentation of Validation subjects   			#
2022-3-24 8:33:31.78: ##########################################################################################
2022-3-24 8:33:31.78: 
2022-3-24 8:33:31.78: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:33:31.79: ~~~~~~~~	 Segmenting subject with index #0 	~~~~~~~~
2022-3-24 8:33:31.79:  Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0003_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:32.18:  WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:32.61:  WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:33.17: Starting to (tile) extract Segments from the images of the subject for Segmentation...
2022-3-24 8:33:33.18: Finished (tiling) extracting Segments from the images of the subject for Segmentation.
2022-3-24 8:33:33.19: Ready to make predictions for all image segments (parts).
2022-3-24 8:33:33.19: Total number of Segments to process:90
2022-3-24 8:33:33.19: Processed 0/90 segments.
2022-3-24 8:33:33.41: Processed 10/90 segments.
2022-3-24 8:33:33.64: Processed 20/90 segments.
2022-3-24 8:33:33.87: Processed 30/90 segments.
2022-3-24 8:33:34.10: Processed 40/90 segments.
2022-3-24 8:33:34.35: Processed 50/90 segments.
2022-3-24 8:33:34.58: Processed 60/90 segments.
2022-3-24 8:33:34.79: Processed 70/90 segments.
2022-3-24 8:33:35.01: Processed 80/90 segments.
2022-3-24 8:33:35.22: Processed 90/90 segments.
2022-3-24 8:33:35.22: TIMING: Segmentation of subject: [Forward Pass:] 1.92 secs.
2022-3-24 8:33:35.63: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:33:35.87: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_Segm.nii.gz
2022-3-24 8:33:35.87: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:33:36.56: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass0.nii.gz
2022-3-24 8:33:36.57: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:33:37.25: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass1.nii.gz
2022-3-24 8:33:37.26: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:33:37.95: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass2.nii.gz
2022-3-24 8:33:37.95: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:33:38.64: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass3.nii.gz
2022-3-24 8:33:38.66: Saving the new label (segmentation) image for the subject #0
2022-3-24 8:33:39.27: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0003_1_ProbMapClass4.nii.gz
2022-3-24 8:33:40.71: +++++++++++ Reporting Segmentation Metrics for Subject #0 +++++++++++
2022-3-24 8:33:40.71: ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #0 equal: DICE1=[ 0.8799 0.0000 0.8664 0.0000 0.5613 ] DICE2=[ 0.8799 0.0000 0.8664 0.0000 0.5613 ] DICE3=[ 0.8802 0.0000 0.8668 0.0000 0.5613 ]
2022-3-24 8:33:40.71: EXPLANATION: DICE1/2/3 are lists with the DICE per class.
	 For Class-0, we calculate DICE for whole foreground: all labels merged except background, label=0.
	 Useful for multi-class problems.
2022-3-24 8:33:40.71: EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT).
	 DICE2 is the segmentation within the ROI vs GT.
	 DICE3 is segmentation within the ROI vs the GT within the ROI.
2022-3-24 8:33:40.71: EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.
2022-3-24 8:33:40.72: 
2022-3-24 8:33:40.72: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2022-3-24 8:33:40.72: ~~~~~~~~	 Segmenting subject with index #1 	~~~~~~~~
2022-3-24 8:33:40.72:  Loading subject with 1st channel at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/dataForExamples/brats2015TrainingData/validation/brats_2013_pat0004_1/Flair_subtrMeanDivStd.nii.gz
2022-3-24 8:33:41.12:  WARN: Loaded labels are dtype [float32]. Rounding and casting to [int16]!
2022-3-24 8:33:41.25:  WARN: Loaded ROI-mask is dtype [float64]. Rounding and casting to [int16]!
2022-3-24 8:33:41.37: Starting to (tile) extract Segments from the images of the subject for Segmentation...
2022-3-24 8:33:41.38: Finished (tiling) extracting Segments from the images of the subject for Segmentation.
2022-3-24 8:33:41.38: Ready to make predictions for all image segments (parts).
2022-3-24 8:33:41.38: Total number of Segments to process:80
2022-3-24 8:33:41.39: Processed 0/80 segments.
2022-3-24 8:33:41.58: Processed 10/80 segments.
2022-3-24 8:33:41.77: Processed 20/80 segments.
2022-3-24 8:33:41.97: Processed 30/80 segments.
2022-3-24 8:33:42.19: Processed 40/80 segments.
2022-3-24 8:33:42.39: Processed 50/80 segments.
2022-3-24 8:33:42.59: Processed 60/80 segments.
2022-3-24 8:33:42.79: Processed 70/80 segments.
2022-3-24 8:33:42.99: Processed 80/80 segments.
2022-3-24 8:33:42.99: TIMING: Segmentation of subject: [Forward Pass:] 1.52 secs.
2022-3-24 8:33:43.77: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:33:44.09: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_Segm.nii.gz
2022-3-24 8:33:44.09: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:33:44.67: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass0.nii.gz
2022-3-24 8:33:44.68: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:33:45.29: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass1.nii.gz
2022-3-24 8:33:45.30: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:33:45.85: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass2.nii.gz
2022-3-24 8:33:45.85: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:33:46.45: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass3.nii.gz
2022-3-24 8:33:46.46: Saving the new label (segmentation) image for the subject #1
2022-3-24 8:33:47.20: Image saved at: /homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/predictions/trainSessionWithValidTiny/predictions/pred_brats_2013_pat0004_1_ProbMapClass4.nii.gz
2022-3-24 8:33:49.31: +++++++++++ Reporting Segmentation Metrics for Subject #1 +++++++++++
2022-3-24 8:33:49.31: ACCURACY: (Validation) The Per-Class DICE Coefficients for subject with index #1 equal: DICE1=[ 0.9345 0.0092 0.4575 0.0000 0.4808 ] DICE2=[ 0.9345 0.0092 0.4575 0.0000 0.4809 ] DICE3=[ 0.9346 0.0092 0.4575 0.0000 0.4809 ]
2022-3-24 8:33:49.31: EXPLANATION: DICE1/2/3 are lists with the DICE per class.
	 For Class-0, we calculate DICE for whole foreground: all labels merged except background, label=0.
	 Useful for multi-class problems.
2022-3-24 8:33:49.31: EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT).
	 DICE2 is the segmentation within the ROI vs GT.
	 DICE3 is segmentation within the ROI vs the GT within the ROI.
2022-3-24 8:33:49.31: EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.
2022-3-24 8:33:49.31: 
2022-3-24 8:33:49.31: +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
2022-3-24 8:33:49.31: ++++++++++++++++++++++++ Segmentation of all subjects finished ++++++++++++++++++++++++++++
2022-3-24 8:33:49.32: ++++++++++++++ Reporting Average Segmentation Metrics over all subjects +++++++++++++++++++
2022-3-24 8:33:49.32: ACCURACY: (Validation) The Per-Class average DICE Coefficients over all subjects are: DICE1=[ 0.9072 0.0046 0.6619 0.0000 0.5211 ] DICE2=[ 0.9072 0.0046 0.6619 0.0000 0.5211 ] DICE3=[ 0.9074 0.0046 0.6621 0.0000 0.5211 ]
2022-3-24 8:33:49.32: EXPLANATION: DICE1/2/3 are lists with the DICE per class.
	 For Class-0, we calculate DICE for whole foreground: all labels merged except background, label=0.
	 Useful for multi-class problems.
2022-3-24 8:33:49.33: EXPLANATION: DICE1 is calculated as segmentation over whole volume VS whole Ground Truth (GT).
	 DICE2 is the segmentation within the ROI vs GT.
	 DICE3 is segmentation within the ROI vs the GT within the ROI.
2022-3-24 8:33:49.33: EXPLANATION: If an ROI mask has been provided, you should be consulting DICE2 or DICE3.
2022-3-24 8:33:49.33: TIMING: Validation process lasted: 17.55 secs.
2022-3-24 8:33:49.33: ##########################################################################################
2022-3-24 8:33:49.33: #		  Finished full Segmentation of Validation subjects   			#
2022-3-24 8:33:49.33: ##########################################################################################
2022-3-24 8:33:49.34: =============== LOGGING TO TENSORBOARD ===============
2022-3-24 8:33:49.34: Logging validation metrics from segmentation of whole validation volumes.
2022-3-24 8:33:49.34: Epoch: 1
2022-3-24 8:33:49.35: Step number (index of subepoch since start): 3
2022-3-24 8:33:49.35: Logged metrics: ['whole scans: Dice1 (Prediction VS Truth)', 'whole scans: Dice2 (Prediction within ROI mask VS Truth)', 'whole scans: Dice3 (Prediction VS Truth, both within ROI mask)']
2022-3-24 8:33:49.35: ======================================================
2022-3-24 8:33:49.35: TIMING: Training process lasted: 110.6 secs.
2022-3-24 8:33:49.35: Closing worker pool.
2022-3-24 8:33:49.36: Saving the final model at:/homes/kovacs/project_scripts/hnc_segmentation/deep_medic/deepmedic/examples/output/saved_models//trainSessionWithValidTiny//tinyCnn.trainSessionWithValidTiny.final.2022-03-24.08.33.49.357830
2022-3-24 8:33:49.37: The whole do_training() function has finished.
2022-3-24 8:33:49.48: 
=======================================================
2022-3-24 8:33:49.48: =========== Training session finished =================
2022-3-24 8:33:49.48: =======================================================
2022-3-24 8:33:49.48: Finished.
